---
title: "Untitled"
author: "Ruth Kristianingsih"
date: "17/02/2020"
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_dir = here::here("reports", stringr::str_remove(getwd(), here::here("scripts/r-scripts/"))))})
output:
  md_document:
    variant: markdown_github
---
 
# Manually tuning model for All datasets together

## Load library

```{r setup, include = FALSE}
library(tidyverse)
library(patchwork)
source("../../../r-functions/plot_training_vs_validation.R")
```



## Hyperparameter Scan 

```{r}
all_data_cnn_gru_pred_res <-  data.table::fread("../../../../../data/secreted_data/training-results/all/df_pred_results_cnn_gru_all.csv")
all_data_cnn_gru <-  data.table::fread("../../../../../data/secreted_data/training-results/all/all_scan_results_cnn_gru_all.csv") %>% 
  dplyr::select(params, mean_test_score)

all_data_cnn_gru_pred_res %>% 
  dplyr::arrange(desc(Accuracy)) %>% 
  head(5) %>% 
  knitr::kable()

all_data_cnn_gru %>% 
  dplyr::arrange(desc(mean_test_score)) %>% 
  head(10) %>% 
  knitr::kable()
```

### All data-CNN-GRU

```{r}
all_cnn_gru_train <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_train_cnn_gru_best_all.csv")
all_cnn_gru_val <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_val_cnn_gru_best_all.csv")
all_cnn_gru_test <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_test_cnn_gru_best_all.csv")

# Adding the average of the accuracy of each training and validation data
all_cnn_gru_train<- all_cnn_gru_train %>% 
  dplyr::mutate(AVG_CV = rowMeans(.[,2:6]))

all_cnn_gru_val <- all_cnn_gru_val %>% 
  dplyr::mutate(AVG_CV =rowMeans(.[,2:6]))
```

```{r}
get_gg_acc(all_cnn_gru_train, all_cnn_gru_val, plot_title = "") +
  facet_wrap(~CV, nrow = 2) + 
  theme_light() +
  ggsave(filename = "running_best_model_all_new.pdf", width = 6.5, height = 4, device = cairo_pdf)
  #ggsave("running_best_model_all.pdf")
```

Slighty, we can see that the model is a lil bit overfitting, we can change some parameters and see how it changes the accuracy results of the model. 

### Change the regularization rate from 0.001 to 0.01

```{r}
all_cnn_gru_train_regrate001 <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_train_cnn_gru_best_all_regrate001.csv")
all_cnn_gru_val_regrate001 <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_val_cnn_gru_best_all_regrate001.csv")
all_cnn_gru_test_regrate001 <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_test_cnn_gru_best_all_regrate001.csv")

# Adding the average of the accuracy of each training and validation data
all_cnn_gru_train_regrate001 <- all_cnn_gru_train_regrate001 %>% 
  dplyr::mutate(AVG_CV = rowMeans(.[,2:6]))

all_cnn_gru_val_regrate001 <- all_cnn_gru_val_regrate001 %>% 
  dplyr::mutate(AVG_CV =rowMeans(.[,2:6]))

get_gg_acc(all_cnn_gru_train_regrate001, all_cnn_gru_val_regrate001,  plot_title = "") +
  facet_wrap(~CV, nrow = 2 ) +
  theme_light() +
  ggsave(filename = "tuning_regrate_to_001.pdf", width = 6.5, height = 4, device = cairo_pdf)
```

### Change to different convolution filter and number of kernel

As we can see from the performance above, changing the regularization rate from 0.001 to 0.01 did not really help on tackling the overfitting, instead the accuracy a little bit droppped. Therefore now, we are going to find another paramameter we can tune. 


```{r}
all_cnn_gru_train_convfilter16_kernel1 <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_train_cnn_gru_best_all_convfilter16_kernel1.csv")
all_cnn_gru_val_convfilter16_kernel1 <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_val_cnn_gru_best_all_convfilter16_kernel1.csv")
all_cnn_gru_test_convfilter16_kernel1 <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_test_cnn_gru_best_all_convfilter16_kernel1.csv")

# Adding the average of the accuracy of each training and validation data
all_cnn_gru_train_convfilter16_kernel1 <- all_cnn_gru_train_convfilter16_kernel1 %>% 
  dplyr::mutate(AVG_CV = rowMeans(.[,2:6]))

all_cnn_gru_val_convfilter16_kernel1 <- all_cnn_gru_val_convfilter16_kernel1 %>% 
  dplyr::mutate(AVG_CV =rowMeans(.[,2:6]))
```


```{r}
get_gg_acc(all_cnn_gru_train_convfilter16_kernel1, all_cnn_gru_val_convfilter16_kernel1, plot_title = "") + 
  facet_wrap(~CV, nrow = 2) + 
  #ggsave("turning_kernel_all.pdf")
  theme_light() +
  ggsave(filename = "tuning_kernel_and_filter.pdf", width = 6.5, height = 4, device = cairo_pdf)
```

```{r}
# Compare the testing prediction results between models with model with kernel 1 and kernel 2 or conv filter 16 and 32
diff_tuning <- rbind(all_cnn_gru_test  %>% 
  dplyr::select(V1, acc) %>% 
    dplyr::mutate(tuning = "original"),
   all_cnn_gru_test_regrate001  %>% 
  dplyr::select(V1, acc)  %>% 
    dplyr::mutate(tuning = "reg_rate"),
  all_cnn_gru_test_convfilter16_kernel1 %>% 
    dplyr::select(V1, acc) %>% 
    dplyr::mutate(tuning = "filter_kernel")
  ) %>% 
  mutate(V1 = V1 + 1)

diff_tuning  <- diff_tuning %>% 
  `colnames<-`(c("CV", "Accuracy", "Tuning"))

plot_comparison(diff_tuning, CV, Accuracy, Tuning , show_label = TRUE, label_digits = 3) + 
  theme_light() +
  ggsave(filename = "comparison_diff_tuning.pdf", width = 7, height = 3.5, device = cairo_pdf)
```
  

```{r}
# Compare the testing prediction results between models with model with kernel 1 and kernel 2 or conv filter 16 and 32
diff_kernel_filter <- rbind(all_cnn_gru_test  %>% 
  dplyr::select(V1, acc) %>% 
    dplyr::mutate(kernel_filter = "2 and 32"),
   all_cnn_gru_test_convfilter16_kernel1  %>% 
  dplyr::select(V1, acc)  %>% 
    dplyr::mutate(kernel_filter = "1 and 16"))

plot_comparison(diff_kernel_filter, V1, acc, kernel_filter , show_label = TRUE, label_digits = 3) 
```

## CNN-LSTM

Due to HPC service disruption, the process of hyper paramter scan was stopped, and now I am reading the logs (6/3/2020):

```{r}
all_cnn_lstm_file <- "../../../../../data/secreted_data/training-results/all/0001-cnn-lstm-scan-all.log"
all_cnn_lstm_params_list <- c(
  "strides", "padding", "optimizers", "number_hidden_units",
  "filters_LSTM", "filters", 
  "batch_size", "activation_convolution", "activation_LSTM", "epochs"
)
all_cnn_lstm_numeric_params <- c(
  "strides", "number_hidden_units", "filters_LSTM",
  "filters", "epochs", "batch_size"
)
```


```{r}
all_cnn_lstm_log_data_raw <- all_cnn_lstm_file %>%
  parscanlogreader::read_raw_log() %>%
  parscanlogreader::clean_log_data()

all_cnn_lstm_log_data <- all_cnn_lstm_log_data_raw %>%
  parscanlogreader::summarise_log_data() %>% 
  dplyr::arrange(desc(acc_mean)) %>% 
  tidyr::drop_na()
```


```{r}
all_cnn_lstm_log_data %>%
  head(4) %>% 
  knitr::kable()
```
The manual tuning will be experimented on the model 8, while the filters are less big than the first. 

Now we can see the results of the manual tunning of the CNN-LSTM on all pathogen datasets:
```{r}
all_cnn_lstm_train <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_train_cnn_lstm_best_all.csv")
all_cnn_lstm_val <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_val_cnn_lstm_best_all.csv")
all_cnn_lstm_test <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_test_cnn_lstm_best_all.csv")
```


```{r}
all_cnn_lstm_train <- all_cnn_lstm_train %>% 
  dplyr::mutate(AVG_CV = rowMeans(.[,2:6]))

all_cnn_lstm_val  <- all_cnn_lstm_val  %>% 
  dplyr::mutate(AVG_CV = rowMeans(.[,2:6]))

get_gg_acc(all_cnn_lstm_train, all_cnn_lstm_val, plot_title = "") + 
  facet_wrap(~CV, nrow = 2)
```


```{r}
all_cnn_lstm_test
```

```bash
model = build_model_conv1D_lstm(filters = 16,
                                    filters_LSTM = 8,
                                    strides = 1,
                                    padding = "valid",
                                    activation_convolution = None,
                                    activation_LSTM = 'tanh',
                                    optimizers = 'Adadelta',
                                    number_hidden_units = 8)
    # Fit the model
    history_fit = model.fit(x_train[train], y_train[train], epochs = 60, batch_size = 8, verbose = 1, shuffle = 1, validation_data = (x_train[test], y_train[test]))
```

Now we can try to increase the batch size to 32 and see how it goes. 


```{r}
all_cnn_lstm_train_batch32 <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_train_cnn_lstm_best_all_epochs60.csv")
all_cnn_lstm_val_batch32 <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_val_cnn_lstm_best_all_epochs60.csv")
all_cnn_lstm_test_batch32 <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_test_cnn_lstm_best_all_epochs60.csv")
```

```{r}
all_cnn_lstm_train_batch32 <- all_cnn_lstm_train_batch32 %>% 
  dplyr::mutate(AVG_CV = rowMeans(.[,2:6]))

all_cnn_lstm_val_batch32  <- all_cnn_lstm_val_batch32  %>% 
  dplyr::mutate(AVG_CV = rowMeans(.[,2:6]))

get_gg_acc(all_cnn_lstm_train_batch32, all_cnn_lstm_val_batch32, plot_title = "") + 
  facet_wrap(~CV, nrow = 2) +
  theme_bw()
```

### Comparing two results

```{r}
compare_cnn_lstm_all <- all_cnn_lstm_test %>% 
  dplyr::select(V1, acc) %>% 
  mutate(batch = 32) %>% 
  rbind(all_cnn_lstm_test_batch32 %>% 
          dplyr::select(V1, acc) %>% 
          mutate(batch = 8)) %>% 
  `colnames<-` (c("CV", "Acc", "Batch"))
```


```{r}
plot_comparison(
  data = compare_cnn_lstm_all,
  x_var = CV,
  y_var = Acc,
  group_var = Batch
)
```



## GRU-Embedding

```{r}
all_gru_emb_file <- "../../../../../data/secreted_data/training-results/all/0004-gru-embedding_scan_all.log"
all_gru_emb_params_list <- c(
  "reg_rate", "outputdim", "optimizers", "opt_go_backwards", 
  "opt_dropout_recurrent", "opt_dropout", "gru_hidden_units", "epochs", 
  "batch_size" 
)

all_gru_emb_numeric_params <- c(
  "reg_rate", "outputdim", "opt_dropout_recurrent", 
  "opt_dropout", "gru_hidden_units", "epochs", "batch_size" 
)
```


```{r}
all_gru_emb_log_data_raw <- all_gru_emb_file %>%
  parscanlogreader::read_raw_log() %>%
  parscanlogreader::clean_log_data()

all_gru_emb_log_data_data <- all_gru_emb_log_data_raw %>%
  parscanlogreader::summarise_log_data() %>% 
  dplyr::arrange(desc(acc_mean)) %>% 
  tidyr::drop_na()
```


```{r}
all_gru_emb_log_data_data %>%
  head(10) %>% 
  knitr::kable()
```

Now, we can check the results of manual training of manually checking of the model GRU-Embedding

```{r}
all_gru_emb_train <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_train_gru_emb_all.csv")
all_gru_emb_val <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_val_gru_emb_all.csv")
all_gru_emb_test <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_test_gru_emb_all.csv")

# Adding the average of the accuracy of each training and validation data
all_gru_emb_train <- all_gru_emb_train %>% 
  dplyr::mutate(AVG_CV = rowMeans(.[,2:6]))

all_gru_emb_val <- all_gru_emb_val %>% 
  dplyr::mutate(AVG_CV =rowMeans(.[,2:6]))


get_gg_acc(all_gru_emb_train, all_gru_emb_val, plot_title = "Acc for All Pathogens for GRU Embedding Models") + 
  facet_wrap(~CV, nrow = 2) + 
  #ggsave("turning_kernel_all.pdf")
  theme_light() 

# +
#   ggsave(filename = "turning_kernel_all_new.pdf", width = 4, height = 5, dpi = 192, device = cairo_pdf)
```

```{r}
all_gru_emb_test
```



## LSTM-Embedding

```{r}
all_lstm_emb_train <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_train_lstm_emb_all.csv")
all_lstm_emb_val <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_val_lstm_emb_all.csv")
all_lstm_emb_test <- data.table::fread("../../../../../results/secreted_data_run_manually/all/df_results_test_lstm_emb_all.csv")

# Adding the average of the accuracy of each training and validation data
all_lstm_emb_train <- all_lstm_emb_train %>% 
  dplyr::mutate(AVG_CV = rowMeans(.[,2:6]))

all_lstm_emb_val <- all_lstm_emb_val %>% 
  dplyr::mutate(AVG_CV =rowMeans(.[,2:6]))


get_gg_acc(all_lstm_emb_train, all_lstm_emb_val, plot_title = "Acc for All Pathogens for LSTM Embedding Models") + 
  facet_wrap(~CV, nrow = 2) + 
  #ggsave("turning_kernel_all.pdf")
  theme_light() 
```

```{r}
all_lstm_emb_test
```

