{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import tensor_array_ops, control_flow_ops\n",
    "\n",
    "\n",
    "class Generator(object):\n",
    "    def __init__(self, num_emb, batch_size, emb_dim, hidden_dim,\n",
    "                 sequence_length, start_token,\n",
    "                 learning_rate=0.01, reward_gamma=0.95):\n",
    "        self.num_emb = num_emb\n",
    "        self.batch_size = batch_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.start_token = tf.constant([start_token] * self.batch_size, dtype=tf.int32)\n",
    "        self.learning_rate = tf.Variable(float(learning_rate), trainable=False)\n",
    "        self.reward_gamma = reward_gamma\n",
    "        self.g_params = []\n",
    "        self.d_params = []\n",
    "        self.temperature = 1.0\n",
    "        self.grad_clip = 5.0\n",
    "\n",
    "        self.expected_reward = tf.Variable(tf.zeros([self.sequence_length]))\n",
    "\n",
    "        with tf.variable_scope('generator'):\n",
    "            self.g_embeddings = tf.Variable(self.init_matrix([self.num_emb, self.emb_dim]))\n",
    "            self.g_params.append(self.g_embeddings)\n",
    "            self.g_recurrent_unit = self.create_recurrent_unit(self.g_params)  # maps h_tm1 to h_t for generator\n",
    "            self.g_output_unit = self.create_output_unit(self.g_params)  # maps h_t to o_t (output token logits)\n",
    "\n",
    "        # placeholder definition\n",
    "        self.x = tf.placeholder(tf.int32, shape=[self.batch_size, self.sequence_length]) # sequence of tokens generated by generator\n",
    "        self.rewards = tf.placeholder(tf.float32, shape=[self.batch_size, self.sequence_length]) # get from rollout policy and discriminator\n",
    "\n",
    "        # processed for batch\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.processed_x = tf.transpose(tf.nn.embedding_lookup(self.g_embeddings, self.x), perm=[1, 0, 2])  # seq_length x batch_size x emb_dim\n",
    "\n",
    "        # Initial states\n",
    "        self.h0 = tf.zeros([self.batch_size, self.hidden_dim])\n",
    "        self.h0 = tf.stack([self.h0, self.h0])\n",
    "\n",
    "        gen_o = tensor_array_ops.TensorArray(dtype=tf.float32, size=self.sequence_length,\n",
    "                                             dynamic_size=False, infer_shape=True)\n",
    "        gen_x = tensor_array_ops.TensorArray(dtype=tf.int32, size=self.sequence_length,\n",
    "                                             dynamic_size=False, infer_shape=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
