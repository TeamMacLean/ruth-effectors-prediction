{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../../data/images/creative_commons_elephant.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img(img_path, target_size = (224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.expand_dims(x, axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = preprocess_input(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the position of largest value\n",
    "np.argmax(preds[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the Grad-Cam algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_elephant_output = model.output[:, 386]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer = model.get_layer('block5_conv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(512)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads = K.mean(grads, axis = (0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate = K.function([model.input], \n",
    "                    [pooled_grads, last_conv_layer.output[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads_value, conv_layer_output_value = iterate([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_grads_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, 512)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_output_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(512):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    \n",
    "heatmap = np.mean(conv_layer_output_value, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb3ee0deb8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD3xJREFUeJzt3XuMXOV5x/Hfb2d37fXagIEAhiU1NASCUFqiVUUgTaI4kShQkz+iiKhUbhPJVW8hUaQEyh+o6h+tlChKpFZJXSBBDYJKjtMglAsWBKU3UJZLXINNTAgYB4MdMDb4trenf+z4rXHYC+eZOWccfz+StTuz88zzzuzsz+fMnPc9jggBgCT1NT0AAL2DQABQEAgACgIBQEEgACgIBABFTwSC7SttP2X7ads31tz7XNs/sr3F9hO2b6iz/1HjaNl+zPa9DfQ+xfZ621vbz8N7a+7/2fZzv9n2XbYXd7nf7bZ32d581HWn2t5oe1v76/Ka+3+x/fxvsv0d26d0q/9cGg8E2y1J/yTpDyRdLOkTti+ucQiTkj4XEe+SdJmkv6y5/xE3SNrSQF9J+qqkH0TERZJ+p85x2D5H0qcljUbEJZJakq7rcttvSrrymOtulHR/RFwg6f725Tr7b5R0SUS8W9LPJN3Uxf6zajwQJP2epKcj4pmIGJd0t6Rr62oeETsj4tH2969p5o/hnLr6S5LtEUlXS7q1zr7t3idJer+k2yQpIsYj4tWah9Evach2v6Qlkl7oZrOI+LGkV465+lpJd7S/v0PSR+vsHxH3RcRk++JDkka61X8uvRAI50h6/qjLO1TzH+QRtldKulTSwzW3/oqkz0uarrmvJJ0vabekb7R3WW61PVxX84j4paQvSdouaaekvRFxX139j3JmROxsj2mnpDMaGMMRn5T0/SYa90Ig+E2uq/14attLJX1b0mciYl+Nfa+RtCsiHqmr5zH6Jb1H0tci4lJJ+9XdzeU3aO+rXyvpPElnSxq2fX1d/XuN7Zs1sxt7ZxP9eyEQdkg696jLI+ryJuOxbA9oJgzujIgNdfaWdIWk1baf1czu0odsf6vG/jsk7YiII1tF6zUTEHX5sKRfRMTuiJiQtEHS5TX2P+Il2yskqf11V90DsL1G0jWS/igammTUC4HwE0kX2D7P9qBm3lC6p67mtq2Z/ectEfHluvoeERE3RcRIRKzUzGN/ICJq+x8yIl6U9LztC9tXrZL0ZF39NbOrcJntJe3fxSo18+bqPZLWtL9fI+m7dTa3faWkL0haHREH6uz9BhHR+D9JV2nmndWfS7q55t7v08wuyiZJj7f/XdXQ8/BBSfc20Pd3JY21n4N/l7S85v5/K2mrpM2S/lXSoi73u0sz71dMaGYL6VOSTtPMpwvb2l9Prbn/05p5L+3Ia/Drdb8OIkJuDxAAemKXAUCPIBAAFAQCgIJAAFAQCACKngoE22vpf2L2P5Efey/0P6KnAkFS008K/U/M3vRv67VAANCgWg9MGuwbiqH+ZbP+fHz6oAb7hmb9eUxMzvqzhXB/a86fj08f0mDfXGtzvNk8rM6Z7/HLyf59c9ePTx3QYGtJrkdF41MHNdia47FLUva1Ojk1e/84pMH51mVJ9p/rb21ChzWgRXPWe6j6ujEHx1/V+OSBeV9A/ZU7VDDUv0yXn/7xyvWTL+Xmm7ROSS6C01/r0/VrPDCQu4PBXH20mt2g9PhEqn76V8cugfAWTc0eKAvqf/hwqr7vondVrn1o678srEflDgB+4xAIAIpUIDS5OCqAzqscCD2wOCqADstsITS6OCqAzssEQs8sjgqgMzKfoy1ocdT2IZlrJWlxa2miHYBuy2whLGhx1IhYFxGjETE650E3ABqXCYRGF0cF0HmVdxkiYtL2X0n6oWZOv3V7RDzRsZEBqF3qWNyI+J6k73VoLAAaxpGKAAoCAUBR6/S9mJjMzVhMTj+dejk52y2rb+7p1/OWD+emJjs72/HgoVT99MGDqfrWstmnzi9EZvqwJMWB3Pizr9/pn1Y/oVVML+x3xxYCgIJAAFAQCAAKAgFAQSAAKAgEAAWBAKAgEAAUBAKAgkAAUBAIAAoCAUBBIAAoCAQABYEAoKh1PQQPLVbfhRdVru/btSc3gMVzn257PjHP6eTnrV80mKo/NJJbD2DRy7n1DF69cDhV/46/2JqqH+jLnX35oefPTtUffim3HsVFf1N9PQNJivHxyrU+NO+Z4CWxhQDgKAQCgIJAAFAQCACKzOngz7X9I9tbbD9h+4ZODgxA/TKfMkxK+lxEPGp7maRHbG+MiCc7NDYANau8hRAROyPi0fb3r0naIk4HDxzXOvIegu2Vki6V9HAn7g9AM9KBYHuppG9L+kxE7HuTn6+1PWZ7bHzyQLYdgC5KBYLtAc2EwZ0RseHNbhMR6yJiNCJGB/tzR3oB6K7MpwyWdJukLRHx5c4NCUBTMlsIV0j6Y0kfsv14+99VHRoXgAZU/tgxIv5T0sJmTAA4LnCkIoCCQABQ1LoeQrSsyWXV1yQYeO5gbgAHk/X9uacrVq5I1e97e67/5EW59RQmh1LlWn36Y6n6jy/dm6q/e/nmVP3q4ZdS9X+44c9T9X1T05VrY+yBhfWo3AHAbxwCAUBBIAAoCAQABYEAoCAQABQEAoCCQABQEAgACgIBQEEgACgIBAAFgQCgIBAAFAQCgKLW9RBkK/qbyyAPD6fqp85Ynqrf+86lqfoDK3Ir1p33wWdz/ScGU/X/vP0Dqfpb9pycqj+8Pzf+De94NlU/+HLuNAQvfKj6629iy8L+7thCAFAQCAAKAgFAQSAAKDpxbseW7cds39uJAQFoTie2EG7QzKngARznsid7HZF0taRbOzMcAE3KbiF8RdLnJVVfMB5Az8ic/fkaSbsi4pF5brfW9pjtsfHx/VXbAahB9uzPq20/K+luzZwF+lvH3igi1kXEaESMDg7mjhQE0F2VAyEiboqIkYhYKek6SQ9ExPUdGxmA2nEcAoCiI5ObIuJBSQ924r4ANIctBAAFgQCgqHc9hKlp9e89XL3+7DNz7YcXpeqf+rNc/d///r+l6m/b8b5U/XTk1lM4Y8lrqfqPnTGWqv+7165O1cf23HoIP//vd6bqz9r3Qqp+ZH3153/7nvEF3Y4tBAAFgQCgIBAAFAQCgIJAAFAQCAAKAgFAQSAAKAgEAAWBAKAgEAAUBAKAgkAAUBAIAAoCAUBR63oI0d+nQ2ctqVw/fnIr1f/gabn8u+LiJ1P1b+vfl6pffdamVP0Pd1+cqv/JlvNT9ZseyK0nsHxrpOpP3vZ6qn7/SPXXriRNDw+l6vteP5CoXthaGGwhACgIBAAFgQCgIBAAFNmzP59ie73trba32H5vpwYGoH7ZTxm+KukHEfEx24OScm/DAmhU5UCwfZKk90v6E0mKiHFJC1vrGUBPyuwynC9pt6Rv2H7M9q22Ob0zcBzLBEK/pPdI+lpEXCppv6Qbj72R7bW2x2yPTYzvT7QD0G2ZQNghaUdEPNy+vF4zAfEGEbEuIkYjYnRgkA0IoJdVDoSIeFHS87YvbF+1SlLu2F4Ajcp+yvDXku5sf8LwjKQ/zQ8JQFNSgRARj0sa7dBYADSMIxUBFAQCgKLW9RA8Oa3Fuw9Wrl+0J5dffRO5+ej/9dRv5+o35dYDWLat1l/XrznnualU/aI9uePWFm3anqrPOmnX4twdHM49/jh5WfXiPtZDAPAWEQgACgIBQEEgACgIBAAFgQCgIBAAFAQCgIJAAFAQCAAKAgFAQSAAKAgEAAWBAKAgEAAU9U6wtxX91TOotfW5VPuTn8uthzDw+kiqfujZV1L1U8tzJ8aaGsr9ugf2HErV9734cqp+en9uGf+Yyq3n4GT/rFhxevVa1kMA8FYRCAAKAgFAQSAAKFKBYPuztp+wvdn2XbaTq1ACaFLlQLB9jqRPSxqNiEsktSRd16mBAahfdpehX9KQ7X5JSyS9kB8SgKZkTvb6S0lfkrRd0k5JeyPivk4NDED9MrsMyyVdK+k8SWdLGrZ9/Zvcbq3tMdtjExPNHtgBYG6ZXYYPS/pFROyOiAlJGyRdfuyNImJdRIxGxOjAwHCiHYBuywTCdkmX2V5i25JWSdrSmWEBaELmPYSHJa2X9Kik/23f17oOjQtAA1KzXSLiFkm3dGgsABrGkYoACgIBQFHregiemlZrX/U59dOvJz+2TNYvenBPqj5arVR9a2fu19Va4Jz42cT4RKp+anw81386UvVpyfUUslq7X61c64mFjZ0tBAAFgQCgIBAAFAQCgIJAAFAQCAAKAgFAQSAAKAgEAAWBAKAgEAAUBAKAgkAAUBAIAAoCAUBR63oImpySdldfU6Dp+fBWbj58JOfTR3I9gaz08x/TnRlIY3LrWci5/38nR06rXBuvLOxPnS0EAAWBAKAgEAAUBAKAYt5AsH277V22Nx913am2N9re1v66vLvDBFCHhWwhfFPSlcdcd6Ok+yPiAkn3ty8DOM7NGwgR8WNJrxxz9bWS7mh/f4ekj3Z4XAAaUPU9hDMjYqcktb+e0bkhAWhK1w9Msr1W0lpJWty3tNvtACRU3UJ4yfYKSWp/3TXbDSNiXUSMRsToYN9QxXYA6lA1EO6RtKb9/RpJ3+3McAA0aSEfO94l6X8kXWh7h+1PSfoHSR+xvU3SR9qXARzn5n0PISI+McuPVnV4LAAaxpGKAAoCAUBR63oIMTWl6X37EnfQ7Hz6mG44P4/79QQallyPIC35++s7UH09DC9wLQu2EAAUBAKAgkAAUBAIAAoCAUBBIAAoCAQABYEAoCAQABQEAoCCQABQEAgACgIBQEEgACgIBABFreshKEIxXn1Od9pxPh8ezYoFrinQtf6bt1WvnTq0oNuxhQCgIBAAFAQCgKLq6eC/aHur7U22v2P7lO4OE0Adqp4OfqOkSyLi3ZJ+JummDo8LQAMqnQ4+Iu6LiMn2xYckjXRhbABq1on3ED4p6fsduB8ADUsdh2D7ZkmTku6c4zb/fzp4Lcm0A9BllQPB9hpJ10haFRGzHrEREeskrZOkk3xqs0d2AJhTpUCwfaWkL0j6QEQc6OyQADSl6ung/1HSMkkbbT9u++tdHieAGlQ9HfxtXRgLgIZxpCKAgkAAUBAIAIpa10PwokG13r6ycv3UM9tT/VtLh1P12bUc5vh0dkH6kuNXXytXn1zPwQMDuf79uZdrLEr270v+/7n3tVT55Pkrqhf/9D8WdDO2EAAUBAKAgkAAUBAIAAoCAUBBIAAoCAQABYEAoCAQABQEAoCCQABQEAgACgIBQEEgACgIBACFs3P031Ize7ek5+a4yemSflXTcOjfW/1P5MdeR//fioi3zXejWgNhPrbHImKU/ide/xP5sfdC/yPYZQBQEAgAil4LhHX0P2H7n8iPvRf6S+qx9xAANKvXthAANIhAAFAQCAAKAgFAQSAAKP4PTmGRKXbsrPEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
