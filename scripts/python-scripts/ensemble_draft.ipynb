{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all of the libraries\n",
    "\n",
    "# Import package to scan hyperparameter\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Import package to reprocess the data\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Import keras item\n",
    "import keras\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import *\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "from keras.callbacks import History\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.engine import training\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from typing import Tuple, List\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fucntion to ensemble \n",
    "def compile_and_train(model: training.Model, num_epochs: int) -> Tuple [History, str]: \n",
    "    \n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['acc']) \n",
    "    filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True, save_best_only=True, mode='auto', period=1)\n",
    "    tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n",
    "    history = model.fit(x=x_train, y=y_train, batch_size=32, \n",
    "                     epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board], validation_split=0.2)\n",
    "    weight_files = glob.glob(os.path.join(os.getcwd(), 'weights/*'))\n",
    "    weight_file = max(weight_files, key=os.path.getctime) # most recent file\n",
    "    return history, weight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to evaluate error\n",
    "def evaluate_error(model: training.Model) -> np.float64:\n",
    "    pred = model.predict(x_test, batch_size = 32)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n",
    "    error = np.sum(np.not_equal(pred, y_test)) / y_test.shape[0]   \n",
    " \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(models: List [training.Model], model_input: Tensor) -> training.Model:\n",
    "    \n",
    "    outputs = [model.outputs[0] for model in models]\n",
    "    y = Average()(outputs)\n",
    "    \n",
    "    model = Model(model_input, y, name='ensemble')\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
