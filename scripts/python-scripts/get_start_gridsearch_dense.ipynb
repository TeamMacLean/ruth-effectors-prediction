{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all packages and library\n",
    "\n",
    "# Import package to scan hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Import package to reprocess the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Import properties from keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "\n",
    "# Import keras items\n",
    "from keras.optimizers import Adam, Adadelta, SGD\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of the data and reprocess them\n",
    "\n",
    "# Get the reprocessed data from .npy file\n",
    "x_train = np.load('../r-scripts/getting-data-current/data-sets/x_train.npy')\n",
    "y_train = np.load('../r-scripts/getting-data-current/data-sets/y_train.npy')\n",
    "\n",
    "x_dev = np.load('../r-scripts/getting-data-current/data-sets/x_val.npy')\n",
    "y_dev = np.load('../r-scripts/getting-data-current/data-sets/y_val.npy')\n",
    "\n",
    "x_test = np.load('../r-scripts/getting-data-current/data-sets/x_test.npy')\n",
    "y_test = np.load('../r-scripts/getting-data-current/data-sets/y_test.npy')\n",
    "\n",
    "# This Section is used to shuffle the data\n",
    "\n",
    "# This Section is used to shuffle the data\n",
    "\n",
    "# Aggregates elements\n",
    "data_training = list(zip(x_train, y_train))\n",
    "data_development = list(zip(x_dev, y_dev))\n",
    "data_testing = list(zip(x_test, y_test))\n",
    "\n",
    "# Shuffle the aggragated element on the list\n",
    "random.shuffle(data_training)\n",
    "random.shuffle(data_development)\n",
    "random.shuffle(data_testing)\n",
    "\n",
    "# Combine data training dan data development become one list of data train\n",
    "\n",
    "data_train = data_training + data_development\n",
    "\n",
    "# Split the shuffled data\n",
    "x_train, y_train = zip(*data_train)\n",
    "x_test, y_test = zip(*data_testing)\n",
    "\n",
    "# Unpack the tuples\n",
    "x_train = np.array(list(x_train))\n",
    "y_train = np.array(list(y_train))\n",
    "x_test = np.array(list(x_test))\n",
    "y_test = np.array(list(y_test))\n",
    "\n",
    "# Reshape the datasets\n",
    "# x_train = x_train.reshape(615, 4034 * 20)\n",
    "# x_test = x_test.reshape(150, 4034 * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615, 4034, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, activation=\"relu\", input_shape=(None, 20))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, None, 32)          1952      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, None, 32)          3104      \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 15,649\n",
      "Trainable params: 15,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 492 samples, validate on 123 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(32, 3, activation = \"relu\", input_dim =  20))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(32, 3, activation = \"relu\"))\n",
    "model.add(GRU(32, dropout = 0.1, recurrent_dropout = 0.5))\n",
    "# model.add(layers.GRU(32, dropout = 0.1, recurrent_dropout = 0.5))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = 'sgd',\n",
    "                    loss = 'binary_crossentropy',\n",
    "                    metrics = ['accuracy'])\n",
    "history = model.fit(x = x_train, \n",
    "                          y = y_train, \n",
    "                          epochs = 20, \n",
    "                          batch_size = 32, \n",
    "                          validation_split = 0.2, \n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6979 - acc: 0.5163\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.6092 - acc: 0.6037\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5276 - acc: 0.6829\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4307 - acc: 0.7683\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3525 - acc: 0.8069\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3132 - acc: 0.8049\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2873 - acc: 0.8191\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2876 - acc: 0.8089\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2678 - acc: 0.8028\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2295 - acc: 0.8455\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2474 - acc: 0.8150\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2343 - acc: 0.8537\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2235 - acc: 0.8333\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2311 - acc: 0.8272\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2187 - acc: 0.8415\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2354 - acc: 0.8272\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2043 - acc: 0.8476\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1968 - acc: 0.8659\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2246 - acc: 0.8069\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1929 - acc: 0.8598\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2110 - acc: 0.8293\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2015 - acc: 0.8516\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2247 - acc: 0.8313\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1902 - acc: 0.8598\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2097 - acc: 0.8435\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1981 - acc: 0.8638\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1840 - acc: 0.8638\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2220 - acc: 0.8455\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2150 - acc: 0.8598\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2018 - acc: 0.8537\n",
      "123/123 [==============================] - 0s 2ms/step\n",
      "492/492 [==============================] - 0s 796us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7154471544715447, total=  51.5s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   51.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.6956 - acc: 0.5630\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6005 - acc: 0.7053\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5022 - acc: 0.7419\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4525 - acc: 0.7520\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3942 - acc: 0.8049\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3757 - acc: 0.8171\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3633 - acc: 0.8130\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3192 - acc: 0.8415\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3057 - acc: 0.8272\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2907 - acc: 0.8354\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2611 - acc: 0.8598\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2702 - acc: 0.8374\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2404 - acc: 0.8618\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2569 - acc: 0.8354\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2490 - acc: 0.8537\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2668 - acc: 0.8313\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2269 - acc: 0.8313\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2150 - acc: 0.8679\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2149 - acc: 0.8557\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2251 - acc: 0.8496\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2123 - acc: 0.8699\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2178 - acc: 0.8537\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1963 - acc: 0.8821\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2176 - acc: 0.8415\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2438 - acc: 0.8232\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1999 - acc: 0.8638\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2157 - acc: 0.8211\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1902 - acc: 0.8455\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2111 - acc: 0.8577\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1924 - acc: 0.8638\n",
      "123/123 [==============================] - 0s 2ms/step\n",
      "492/492 [==============================] - 0s 744us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6504065045496312, total=  50.2s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.6938 - acc: 0.5488\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5989 - acc: 0.6565\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4819 - acc: 0.7561\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4029 - acc: 0.7703\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3401 - acc: 0.8293\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3059 - acc: 0.8191\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2720 - acc: 0.8455\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2749 - acc: 0.8394\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2474 - acc: 0.8272\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2467 - acc: 0.8435\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2380 - acc: 0.8374\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2461 - acc: 0.8191\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2295 - acc: 0.8516\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2211 - acc: 0.8435\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2117 - acc: 0.8496\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2218 - acc: 0.8313\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2180 - acc: 0.8557\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2250 - acc: 0.8476\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2420 - acc: 0.8191\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2283 - acc: 0.8435\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2135 - acc: 0.8394\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2234 - acc: 0.8415\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2108 - acc: 0.8394\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1920 - acc: 0.8618\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1948 - acc: 0.8557\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1898 - acc: 0.8720\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2062 - acc: 0.8537\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2043 - acc: 0.8455\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2089 - acc: 0.8577\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1898 - acc: 0.8516\n",
      "123/123 [==============================] - 0s 2ms/step\n",
      "492/492 [==============================] - 0s 773us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7723577240618263, total=  48.6s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.6942 - acc: 0.5407\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6377 - acc: 0.6321\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5535 - acc: 0.7297\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5021 - acc: 0.8028\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4747 - acc: 0.8394\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4505 - acc: 0.8293\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4157 - acc: 0.8760\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3962 - acc: 0.9024\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3873 - acc: 0.8923\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3516 - acc: 0.9329\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3330 - acc: 0.9329\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3306 - acc: 0.9289\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3192 - acc: 0.9350\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2888 - acc: 0.9533\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2864 - acc: 0.9431\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2816 - acc: 0.9411\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2574 - acc: 0.9593\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2700 - acc: 0.9370\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2810 - acc: 0.9289\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2445 - acc: 0.9553\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2339 - acc: 0.9614\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2433 - acc: 0.9451\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2189 - acc: 0.9614\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2180 - acc: 0.9573\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2231 - acc: 0.9512\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2310 - acc: 0.9492\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2200 - acc: 0.9472\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2106 - acc: 0.9512\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2073 - acc: 0.9472\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1930 - acc: 0.9593\n",
      "123/123 [==============================] - 0s 2ms/step\n",
      "492/492 [==============================] - 0s 846us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6260162604048969, total=  48.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6928 - acc: 0.5772\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6130 - acc: 0.6748\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4965 - acc: 0.7602\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3941 - acc: 0.8049\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3528 - acc: 0.8130\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3186 - acc: 0.8130\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2878 - acc: 0.8313\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2869 - acc: 0.8110\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2260 - acc: 0.8679\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2381 - acc: 0.8516\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2458 - acc: 0.8455\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2333 - acc: 0.8516\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2233 - acc: 0.8435\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2316 - acc: 0.8333\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2268 - acc: 0.8394\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2095 - acc: 0.8618\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2083 - acc: 0.8476\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2172 - acc: 0.8415\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2096 - acc: 0.8577\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2013 - acc: 0.8577\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1965 - acc: 0.8374\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1965 - acc: 0.8496\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1915 - acc: 0.8516\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2042 - acc: 0.8577\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1958 - acc: 0.8354\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2077 - acc: 0.8394\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2064 - acc: 0.8557\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2331 - acc: 0.8211\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2035 - acc: 0.8598\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1988 - acc: 0.8516\n",
      "123/123 [==============================] - 0s 3ms/step\n",
      "492/492 [==============================] - 0s 691us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6829268292682927, total=  47.2s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.6857 - acc: 0.5508\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6088 - acc: 0.6423\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5381 - acc: 0.7439\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4652 - acc: 0.7398\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4455 - acc: 0.7724\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4165 - acc: 0.7825\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3778 - acc: 0.8171\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3723 - acc: 0.8211\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3311 - acc: 0.8476\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3315 - acc: 0.8699\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3291 - acc: 0.8720\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3246 - acc: 0.8659\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3237 - acc: 0.8963\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2975 - acc: 0.9268\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2802 - acc: 0.9146\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2646 - acc: 0.9106\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2848 - acc: 0.9167\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2775 - acc: 0.9106\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2588 - acc: 0.9106\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2411 - acc: 0.9289\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2476 - acc: 0.9472\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2412 - acc: 0.9411\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2508 - acc: 0.9370\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2239 - acc: 0.9411\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2386 - acc: 0.9329\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2522 - acc: 0.9146\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2270 - acc: 0.9472\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2179 - acc: 0.9370\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2268 - acc: 0.9309\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2092 - acc: 0.9492\n",
      "123/123 [==============================] - 0s 3ms/step\n",
      "492/492 [==============================] - 0s 727us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7073170736553224, total=  28.0s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  4.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.6979 - acc: 0.5467\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6642 - acc: 0.6016\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6280 - acc: 0.6565\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5623 - acc: 0.7520\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5277 - acc: 0.7825\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4846 - acc: 0.8476\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4526 - acc: 0.8780\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4291 - acc: 0.8882\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3985 - acc: 0.9085\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3768 - acc: 0.9248\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3405 - acc: 0.9472\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3568 - acc: 0.9309\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3184 - acc: 0.9573\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3001 - acc: 0.9573\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2992 - acc: 0.9451\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2875 - acc: 0.9553\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2633 - acc: 0.9634\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2644 - acc: 0.9614\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2543 - acc: 0.9573\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2587 - acc: 0.9472\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2480 - acc: 0.9553\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2399 - acc: 0.9614\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2245 - acc: 0.9654\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2346 - acc: 0.9573\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2048 - acc: 0.9736\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2077 - acc: 0.9654\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2217 - acc: 0.9573\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1968 - acc: 0.9675\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2080 - acc: 0.9614\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1967 - acc: 0.9675\n",
      "123/123 [==============================] - 0s 3ms/step\n",
      "492/492 [==============================] - 0s 800us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.6585365858504443, total=  28.6s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  5.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.7012 - acc: 0.5264\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6582 - acc: 0.5711\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5954 - acc: 0.6362\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5326 - acc: 0.7236\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4744 - acc: 0.7581\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4202 - acc: 0.7724\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3878 - acc: 0.8191\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3590 - acc: 0.8150\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3550 - acc: 0.8069\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3144 - acc: 0.8476\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2955 - acc: 0.8293\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2775 - acc: 0.8415\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2570 - acc: 0.8720\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2704 - acc: 0.8496\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2489 - acc: 0.8720\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2576 - acc: 0.8455\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2577 - acc: 0.8557\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2349 - acc: 0.8760\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2461 - acc: 0.8374\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2354 - acc: 0.8699\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2361 - acc: 0.8516\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2351 - acc: 0.8476\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2141 - acc: 0.8720\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2149 - acc: 0.8679\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2110 - acc: 0.8638\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2235 - acc: 0.8780\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2269 - acc: 0.8476\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2218 - acc: 0.8720\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2264 - acc: 0.8496\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2280 - acc: 0.8740\n",
      "123/123 [==============================] - 0s 3ms/step\n",
      "492/492 [==============================] - 0s 727us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7560975612179051, total=  27.5s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  5.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.7009 - acc: 0.5305\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6822 - acc: 0.5874\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6556 - acc: 0.6199\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6149 - acc: 0.6565\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5836 - acc: 0.6606\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5450 - acc: 0.6850\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5073 - acc: 0.7175\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4751 - acc: 0.7419\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4477 - acc: 0.7500\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4333 - acc: 0.7439\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4060 - acc: 0.7825\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4147 - acc: 0.7886\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3855 - acc: 0.7866\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3776 - acc: 0.8171\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3735 - acc: 0.8069\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3726 - acc: 0.8232\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3493 - acc: 0.8313\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3160 - acc: 0.8476\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2999 - acc: 0.8211\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3118 - acc: 0.8577\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3115 - acc: 0.8272\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3118 - acc: 0.8293\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2568 - acc: 0.8598\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2728 - acc: 0.8374\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2822 - acc: 0.8354\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2456 - acc: 0.8618\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2598 - acc: 0.8394\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2464 - acc: 0.8415\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2433 - acc: 0.8394\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2392 - acc: 0.8415\n",
      "123/123 [==============================] - 0s 3ms/step\n",
      "492/492 [==============================] - 0s 707us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7804878048780488, total=  28.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  6.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.7018 - acc: 0.5000\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6682 - acc: 0.6240\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6067 - acc: 0.7053\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5442 - acc: 0.7541\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4751 - acc: 0.7927\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4530 - acc: 0.7846\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3967 - acc: 0.8354\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3852 - acc: 0.8110\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3498 - acc: 0.8211\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3344 - acc: 0.8232\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3201 - acc: 0.8211\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3000 - acc: 0.8394\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2700 - acc: 0.8577\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2805 - acc: 0.8455\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2806 - acc: 0.8211\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2556 - acc: 0.8455\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2638 - acc: 0.8415\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2298 - acc: 0.8638\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2592 - acc: 0.8496\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2594 - acc: 0.8394\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2167 - acc: 0.8659\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2161 - acc: 0.8638\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2251 - acc: 0.8699\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2038 - acc: 0.8780\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2045 - acc: 0.8740\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2168 - acc: 0.8740\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2194 - acc: 0.8740\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2068 - acc: 0.8882\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2174 - acc: 0.8699\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2004 - acc: 0.8679\n",
      "123/123 [==============================] - 0s 4ms/step\n",
      "492/492 [==============================] - 0s 783us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.6747967479674797, total=  28.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.6942 - acc: 0.5467\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.6125 - acc: 0.6748\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.4667 - acc: 0.7480\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3892 - acc: 0.7866\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3345 - acc: 0.7947\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2996 - acc: 0.8496\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2552 - acc: 0.8394\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2547 - acc: 0.8313\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2480 - acc: 0.8455\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2392 - acc: 0.8272\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2155 - acc: 0.8720\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2218 - acc: 0.8496\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2029 - acc: 0.8699\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2051 - acc: 0.8455\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2212 - acc: 0.8618\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2116 - acc: 0.8516\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1863 - acc: 0.8679\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2114 - acc: 0.8659\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2040 - acc: 0.8760\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1994 - acc: 0.8699\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1902 - acc: 0.8720\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2121 - acc: 0.8496\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2035 - acc: 0.8699\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1903 - acc: 0.8720\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2029 - acc: 0.8537\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2102 - acc: 0.8740\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1935 - acc: 0.8496\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1875 - acc: 0.8801\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1774 - acc: 0.8862\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1903 - acc: 0.8557\n",
      "123/123 [==============================] - 0s 3ms/step\n",
      "492/492 [==============================] - 0s 752us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.7235772357723578, total=  56.0s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6918 - acc: 0.5467\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5970 - acc: 0.7053\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4806 - acc: 0.8008\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3719 - acc: 0.8598\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3173 - acc: 0.8740\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2889 - acc: 0.8882\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2601 - acc: 0.9045\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2717 - acc: 0.9106\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2613 - acc: 0.9085\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2341 - acc: 0.9228\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2483 - acc: 0.9085\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1945 - acc: 0.9411\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2308 - acc: 0.9146\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1932 - acc: 0.9329\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2250 - acc: 0.9146\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1773 - acc: 0.9451\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1865 - acc: 0.9329\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1796 - acc: 0.9370\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1811 - acc: 0.9390\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1897 - acc: 0.9268\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2020 - acc: 0.9187\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1754 - acc: 0.9329\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1916 - acc: 0.9309\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1796 - acc: 0.9329\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1914 - acc: 0.9268\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1813 - acc: 0.9309\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1785 - acc: 0.9350\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1689 - acc: 0.9431\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1961 - acc: 0.9187\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2126 - acc: 0.9146\n",
      "123/123 [==============================] - 0s 4ms/step\n",
      "492/492 [==============================] - 0s 860us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6585365858504443, total=  54.3s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.6989 - acc: 0.5000\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.6324 - acc: 0.6382\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5432 - acc: 0.7175\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.4472 - acc: 0.7988\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3703 - acc: 0.8354\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3219 - acc: 0.8821\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2804 - acc: 0.9167\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2582 - acc: 0.9085\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2482 - acc: 0.9167\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2289 - acc: 0.9228\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2096 - acc: 0.9350\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2186 - acc: 0.9248\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2280 - acc: 0.9167\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1811 - acc: 0.9411\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1873 - acc: 0.9350\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1864 - acc: 0.9370\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2005 - acc: 0.9268\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1840 - acc: 0.9309\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1911 - acc: 0.9248\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1672 - acc: 0.9431\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1986 - acc: 0.9228\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1972 - acc: 0.9228\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1839 - acc: 0.9329\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1452 - acc: 0.9492\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1755 - acc: 0.9370\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2091 - acc: 0.9228\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1781 - acc: 0.9329\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1873 - acc: 0.9289\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2056 - acc: 0.9146\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1912 - acc: 0.9268\n",
      "123/123 [==============================] - 1s 6ms/step\n",
      "492/492 [==============================] - 0s 983us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.682926829510588, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 7ms/step - loss: 0.6972 - acc: 0.5610\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.6331 - acc: 0.6565\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5500 - acc: 0.7500\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.4655 - acc: 0.8415\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.4018 - acc: 0.8862\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3441 - acc: 0.9248\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3006 - acc: 0.9289\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2725 - acc: 0.9329\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2343 - acc: 0.9533\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2484 - acc: 0.9329\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1753 - acc: 0.9695\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1882 - acc: 0.9553\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1822 - acc: 0.9492\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1523 - acc: 0.9695\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1584 - acc: 0.9654\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1487 - acc: 0.9654\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1472 - acc: 0.9654\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1581 - acc: 0.9634\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1837 - acc: 0.9492\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1542 - acc: 0.9573\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1517 - acc: 0.9614\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1374 - acc: 0.9654\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1029 - acc: 0.9797\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1497 - acc: 0.9634\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1296 - acc: 0.9675\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1567 - acc: 0.9593\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1376 - acc: 0.9675\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1424 - acc: 0.9634\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1781 - acc: 0.9512\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1494 - acc: 0.9634\n",
      "123/123 [==============================] - 0s 4ms/step\n",
      "492/492 [==============================] - 0s 757us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6829268297528833, total=  58.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 7ms/step - loss: 0.6996 - acc: 0.5264\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.6570 - acc: 0.6098\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5841 - acc: 0.7276\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.4654 - acc: 0.8394\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3802 - acc: 0.8618\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2742 - acc: 0.9126\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2424 - acc: 0.9248\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2450 - acc: 0.9146\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1955 - acc: 0.9370\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1999 - acc: 0.9411\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1814 - acc: 0.9370\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2135 - acc: 0.9268\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2001 - acc: 0.9309\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1801 - acc: 0.9411\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2108 - acc: 0.9228\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1950 - acc: 0.9289\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1994 - acc: 0.9289\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1957 - acc: 0.9309\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1756 - acc: 0.9390\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2137 - acc: 0.9187\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1826 - acc: 0.9329\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1934 - acc: 0.9309\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2050 - acc: 0.9228\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2009 - acc: 0.9248\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1703 - acc: 0.9411\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1594 - acc: 0.9492\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1716 - acc: 0.9431\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1784 - acc: 0.9370\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1675 - acc: 0.9451\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1862 - acc: 0.9350\n",
      "123/123 [==============================] - 1s 4ms/step\n",
      "492/492 [==============================] - 0s 938us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6341463414634146, total=  58.2s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6910 - acc: 0.5569\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6194 - acc: 0.6606\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5492 - acc: 0.7195\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4823 - acc: 0.7683\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4668 - acc: 0.7785\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4181 - acc: 0.8008\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3852 - acc: 0.8089\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3326 - acc: 0.8598\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3200 - acc: 0.8293\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2894 - acc: 0.8496\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2957 - acc: 0.8354\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2951 - acc: 0.8272\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2560 - acc: 0.8618\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2507 - acc: 0.8476\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2650 - acc: 0.8354\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2068 - acc: 0.8740\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2323 - acc: 0.8476\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2257 - acc: 0.8679\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1937 - acc: 0.8801\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2075 - acc: 0.8699\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2025 - acc: 0.8618\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1930 - acc: 0.8760\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2132 - acc: 0.8557\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2055 - acc: 0.8455\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2206 - acc: 0.8333\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1956 - acc: 0.8516\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1921 - acc: 0.8577\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1843 - acc: 0.8618\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2086 - acc: 0.8598\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2097 - acc: 0.8415\n",
      "123/123 [==============================] - 1s 5ms/step\n",
      "492/492 [==============================] - 0s 828us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.7317073175577613, total=  35.8s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.7017 - acc: 0.5305\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6955 - acc: 0.5813\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6811 - acc: 0.6606\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6658 - acc: 0.6707\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6433 - acc: 0.7195\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6172 - acc: 0.7581\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5903 - acc: 0.8008\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5475 - acc: 0.8455\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5066 - acc: 0.8679\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4775 - acc: 0.8821\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4462 - acc: 0.8862\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4211 - acc: 0.8821\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3900 - acc: 0.9146\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3729 - acc: 0.9004\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3638 - acc: 0.9004\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3533 - acc: 0.9106\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3286 - acc: 0.9146\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3054 - acc: 0.9228\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2895 - acc: 0.9248\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2819 - acc: 0.9248\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2690 - acc: 0.9329\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2384 - acc: 0.9411\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2174 - acc: 0.9512\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2457 - acc: 0.9329\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2369 - acc: 0.9350\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2369 - acc: 0.9329\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2469 - acc: 0.9268\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2609 - acc: 0.9187\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2169 - acc: 0.9390\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2179 - acc: 0.9390\n",
      "123/123 [==============================] - 1s 5ms/step\n",
      "492/492 [==============================] - 0s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6422764232488183, total=  35.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6989 - acc: 0.5325\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6479 - acc: 0.6850\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5955 - acc: 0.7459\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5615 - acc: 0.7805\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5205 - acc: 0.8150\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4938 - acc: 0.8211\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4826 - acc: 0.8049\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4256 - acc: 0.8598\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3907 - acc: 0.8780\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3525 - acc: 0.8821\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3592 - acc: 0.8801\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3025 - acc: 0.9106\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2776 - acc: 0.9248\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2793 - acc: 0.9065\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2620 - acc: 0.9167\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2672 - acc: 0.9106\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2327 - acc: 0.9309\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2302 - acc: 0.9248\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2342 - acc: 0.9207\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2020 - acc: 0.9370\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2011 - acc: 0.9390\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2042 - acc: 0.9329\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1809 - acc: 0.9431\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2214 - acc: 0.9167\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2170 - acc: 0.9187\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2024 - acc: 0.9289\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2116 - acc: 0.9228\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1910 - acc: 0.9289\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1581 - acc: 0.9553\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1821 - acc: 0.9370\n",
      "123/123 [==============================] - 1s 5ms/step\n",
      "492/492 [==============================] - 0s 768us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.699186992112214, total=  36.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.7019 - acc: 0.4898\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6958 - acc: 0.5732\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6835 - acc: 0.6138\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6644 - acc: 0.6321\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6316 - acc: 0.6524\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5911 - acc: 0.6667\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5611 - acc: 0.6911\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5117 - acc: 0.7154\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4950 - acc: 0.6829\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4287 - acc: 0.7967\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4216 - acc: 0.7866\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4003 - acc: 0.8049\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3739 - acc: 0.8618\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3527 - acc: 0.8902\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3385 - acc: 0.8780\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3434 - acc: 0.8740\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3110 - acc: 0.9004\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3060 - acc: 0.9309\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2838 - acc: 0.9187\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2771 - acc: 0.9106\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2760 - acc: 0.9106\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2273 - acc: 0.9431\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2451 - acc: 0.9390\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2254 - acc: 0.9411\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2565 - acc: 0.9187\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2349 - acc: 0.9329\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2244 - acc: 0.9370\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2205 - acc: 0.9350\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1839 - acc: 0.9553\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1713 - acc: 0.9634\n",
      "123/123 [==============================] - 1s 5ms/step\n",
      "492/492 [==============================] - 0s 923us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.7560975614602004, total=  35.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6979 - acc: 0.5427\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6509 - acc: 0.6077\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5889 - acc: 0.7154\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5401 - acc: 0.7825\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4727 - acc: 0.8415\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4442 - acc: 0.8659\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4023 - acc: 0.8821\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3832 - acc: 0.8780\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3002 - acc: 0.9370\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2921 - acc: 0.9207\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2728 - acc: 0.9228\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2684 - acc: 0.9248\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2427 - acc: 0.9329\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2511 - acc: 0.9187\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2608 - acc: 0.9106\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2214 - acc: 0.9268\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2282 - acc: 0.9268\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2184 - acc: 0.9309\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1816 - acc: 0.9492\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1831 - acc: 0.9451\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1776 - acc: 0.9451\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1857 - acc: 0.9431\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1869 - acc: 0.9390\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1901 - acc: 0.9350\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1912 - acc: 0.9309\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1838 - acc: 0.9309\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1752 - acc: 0.9411\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1827 - acc: 0.9370\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1779 - acc: 0.9411\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1419 - acc: 0.9553\n",
      "123/123 [==============================] - 1s 5ms/step\n",
      "492/492 [==============================] - 0s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6341463419480052, total=  35.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.6912 - acc: 0.5305\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5844 - acc: 0.7114\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.4438 - acc: 0.7785\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3632 - acc: 0.8049\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3433 - acc: 0.7947\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2873 - acc: 0.8069\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2776 - acc: 0.8272\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2332 - acc: 0.8577\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2608 - acc: 0.8232\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2368 - acc: 0.8415\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2198 - acc: 0.8354\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2348 - acc: 0.8272\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2338 - acc: 0.8191\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2266 - acc: 0.8333\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2161 - acc: 0.8313\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2128 - acc: 0.8476\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2159 - acc: 0.8415\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2166 - acc: 0.8354\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2379 - acc: 0.8354\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2035 - acc: 0.8394\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2215 - acc: 0.8516\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1843 - acc: 0.8618\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1849 - acc: 0.8679\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2029 - acc: 0.8415\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2138 - acc: 0.8313\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1842 - acc: 0.8862\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2012 - acc: 0.8496\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1970 - acc: 0.8516\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1897 - acc: 0.8760\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1660 - acc: 0.8801\n",
      "123/123 [==============================] - 1s 7ms/step\n",
      "492/492 [==============================] - 0s 988us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7317073170731707, total=  59.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.6910 - acc: 0.5488\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5940 - acc: 0.6870\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5017 - acc: 0.7541\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3971 - acc: 0.8313\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3170 - acc: 0.8740\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3191 - acc: 0.8577\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2904 - acc: 0.8882\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2521 - acc: 0.9106\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2433 - acc: 0.9187\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2359 - acc: 0.9207\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2088 - acc: 0.9329\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2097 - acc: 0.9268\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2164 - acc: 0.9228\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1957 - acc: 0.9390\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2095 - acc: 0.9126\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2112 - acc: 0.9207\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2208 - acc: 0.9106\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1562 - acc: 0.9553\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1883 - acc: 0.9248\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2016 - acc: 0.9228\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1880 - acc: 0.9289\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1799 - acc: 0.9289\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2008 - acc: 0.9167\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1889 - acc: 0.9268\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1952 - acc: 0.9187\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1927 - acc: 0.9228\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1732 - acc: 0.9431\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1767 - acc: 0.9309\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1694 - acc: 0.9390\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1513 - acc: 0.9512\n",
      "123/123 [==============================] - 1s 7ms/step\n",
      "492/492 [==============================] - 0s 971us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.6504065045496312, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.6867 - acc: 0.5467\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5820 - acc: 0.6809\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.4453 - acc: 0.7602\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3911 - acc: 0.7886\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3218 - acc: 0.8333\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2923 - acc: 0.8191\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2693 - acc: 0.8516\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2705 - acc: 0.8008\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2447 - acc: 0.8211\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2516 - acc: 0.8272\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2090 - acc: 0.8476\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2167 - acc: 0.8577\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2313 - acc: 0.8455\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1928 - acc: 0.8862\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2204 - acc: 0.8455\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1979 - acc: 0.8577\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2011 - acc: 0.8496\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2013 - acc: 0.8557\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2278 - acc: 0.8354\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2009 - acc: 0.8496\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1748 - acc: 0.8638\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2155 - acc: 0.8516\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2160 - acc: 0.8455\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2012 - acc: 0.8618\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1762 - acc: 0.8679\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1918 - acc: 0.8435\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1904 - acc: 0.8882\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1752 - acc: 0.8496\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2336 - acc: 0.8272\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2033 - acc: 0.8435\n",
      "123/123 [==============================] - 1s 8ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7479674796747967, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 9ms/step - loss: 0.6802 - acc: 0.5874\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5711 - acc: 0.6504\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.4326 - acc: 0.7907\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3959 - acc: 0.8049\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3403 - acc: 0.8537\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2870 - acc: 0.8902\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2948 - acc: 0.8821\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2648 - acc: 0.8984\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2455 - acc: 0.9268\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2304 - acc: 0.9289\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2358 - acc: 0.9187\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2133 - acc: 0.9228\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1900 - acc: 0.9370\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1819 - acc: 0.9309\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1851 - acc: 0.9350\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1892 - acc: 0.9329\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1960 - acc: 0.9289\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1755 - acc: 0.9451\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1939 - acc: 0.9187\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1936 - acc: 0.9248\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1835 - acc: 0.9329\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1497 - acc: 0.9492\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1829 - acc: 0.9370\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1894 - acc: 0.9228\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1667 - acc: 0.9390\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1820 - acc: 0.9329\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1577 - acc: 0.9411\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1890 - acc: 0.9309\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2006 - acc: 0.9228\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1464 - acc: 0.9512\n",
      "123/123 [==============================] - 1s 8ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7154471549561353, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 5s 10ms/step - loss: 0.6906 - acc: 0.5447\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5768 - acc: 0.7114\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.4543 - acc: 0.7927\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3809 - acc: 0.8272\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3419 - acc: 0.8394\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2928 - acc: 0.8963\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2996 - acc: 0.8862\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2695 - acc: 0.8923\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2412 - acc: 0.8984\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2393 - acc: 0.8943\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2158 - acc: 0.9248\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2125 - acc: 0.9228\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2089 - acc: 0.9289\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2035 - acc: 0.9248\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2170 - acc: 0.9187\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1884 - acc: 0.9248\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1991 - acc: 0.9248\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1742 - acc: 0.9329\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1698 - acc: 0.9370\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2018 - acc: 0.9146\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1728 - acc: 0.9472\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2140 - acc: 0.9106\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1740 - acc: 0.9350\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1969 - acc: 0.9248\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1793 - acc: 0.9350\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1727 - acc: 0.9370\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1670 - acc: 0.9350\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1709 - acc: 0.9431\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1777 - acc: 0.9329\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1640 - acc: 0.9472\n",
      "123/123 [==============================] - 1s 8ms/step\n",
      "492/492 [==============================] - 0s 934us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.6991869918699187, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.7013 - acc: 0.5508\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6562 - acc: 0.6077\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5913 - acc: 0.6585\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5283 - acc: 0.7439\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4776 - acc: 0.7459\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4257 - acc: 0.8130\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4057 - acc: 0.8171\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3793 - acc: 0.8272\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3865 - acc: 0.8171\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3411 - acc: 0.8313\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3257 - acc: 0.8537\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3076 - acc: 0.8760\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2933 - acc: 0.8557\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2927 - acc: 0.8455\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2530 - acc: 0.8841\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2669 - acc: 0.8821\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2825 - acc: 0.8638\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2826 - acc: 0.8659\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2550 - acc: 0.8862\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2804 - acc: 0.8638\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2371 - acc: 0.8923\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2571 - acc: 0.8699\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2801 - acc: 0.8496\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2926 - acc: 0.8516\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2829 - acc: 0.8537\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2417 - acc: 0.8841\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2632 - acc: 0.8598\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2798 - acc: 0.8557\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2660 - acc: 0.8557\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2519 - acc: 0.8720\n",
      "123/123 [==============================] - 1s 9ms/step\n",
      "492/492 [==============================] - 0s 898us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.6422764232488183, total=  38.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.6994 - acc: 0.5041\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6465 - acc: 0.6524\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5795 - acc: 0.7154\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4972 - acc: 0.7622\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4488 - acc: 0.7846\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3967 - acc: 0.8374\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3572 - acc: 0.8516\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3053 - acc: 0.8943\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2691 - acc: 0.9065\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2631 - acc: 0.9004\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2556 - acc: 0.9085\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2329 - acc: 0.9167\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2601 - acc: 0.9065\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2446 - acc: 0.9187\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2193 - acc: 0.9309\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1932 - acc: 0.9350\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1990 - acc: 0.9370\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1945 - acc: 0.9350\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2136 - acc: 0.9228\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1923 - acc: 0.9309\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1823 - acc: 0.9411\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2213 - acc: 0.9106\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2112 - acc: 0.9228\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1840 - acc: 0.9370\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1763 - acc: 0.9370\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2189 - acc: 0.9167\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1928 - acc: 0.9248\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1936 - acc: 0.9268\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2046 - acc: 0.9126\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1920 - acc: 0.9350\n",
      "123/123 [==============================] - 1s 8ms/step\n",
      "492/492 [==============================] - 0s 904us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.6910569110536963, total=  38.8s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.6949 - acc: 0.5589\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5991 - acc: 0.6809\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5078 - acc: 0.7541\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4460 - acc: 0.7683\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3895 - acc: 0.8008\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3634 - acc: 0.8394\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3274 - acc: 0.8354\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3108 - acc: 0.8516\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3221 - acc: 0.8537\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2880 - acc: 0.8638\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2715 - acc: 0.9004\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3076 - acc: 0.8537\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2928 - acc: 0.8598\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2836 - acc: 0.8659\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2892 - acc: 0.8638\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2678 - acc: 0.8821\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2274 - acc: 0.9085\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2264 - acc: 0.9024\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2524 - acc: 0.8821\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3035 - acc: 0.8415\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2681 - acc: 0.8760\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2830 - acc: 0.8577\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2720 - acc: 0.8699\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2391 - acc: 0.8821\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2387 - acc: 0.8902\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2760 - acc: 0.8577\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2378 - acc: 0.8780\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2674 - acc: 0.8618\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2748 - acc: 0.8557\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2665 - acc: 0.8618\n",
      "123/123 [==============================] - 1s 9ms/step\n",
      "492/492 [==============================] - 0s 754us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7398373986162791, total=  39.4s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.7008 - acc: 0.5081\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6658 - acc: 0.5772\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6006 - acc: 0.6768\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5450 - acc: 0.6789\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4686 - acc: 0.7541\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4284 - acc: 0.8049\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4079 - acc: 0.7703\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3700 - acc: 0.8211\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3665 - acc: 0.8110\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2982 - acc: 0.8496\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2847 - acc: 0.8354\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2609 - acc: 0.8598\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2603 - acc: 0.8415\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2587 - acc: 0.8476\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2372 - acc: 0.8557\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2439 - acc: 0.8557\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2272 - acc: 0.8659\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2377 - acc: 0.8699\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2333 - acc: 0.8638\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1875 - acc: 0.8902\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2052 - acc: 0.8720\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2103 - acc: 0.8760\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2142 - acc: 0.8496\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2162 - acc: 0.8659\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2102 - acc: 0.8557\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2124 - acc: 0.8618\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2059 - acc: 0.8659\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1989 - acc: 0.8679\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2065 - acc: 0.8679\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1975 - acc: 0.8618\n",
      "123/123 [==============================] - 1s 10ms/step\n",
      "492/492 [==============================] - 0s 999us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7560975609756098, total=  39.8s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.6969 - acc: 0.5183\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6335 - acc: 0.6118\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5762 - acc: 0.6707\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5125 - acc: 0.6870\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4722 - acc: 0.7541\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4263 - acc: 0.7744\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4345 - acc: 0.7622\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3902 - acc: 0.7846\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3670 - acc: 0.7825\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3297 - acc: 0.8211\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3422 - acc: 0.7846\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3194 - acc: 0.8435\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3064 - acc: 0.8150\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2858 - acc: 0.8191\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2671 - acc: 0.8598\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2596 - acc: 0.8537\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2282 - acc: 0.8760\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2223 - acc: 0.8679\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2317 - acc: 0.8577\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2172 - acc: 0.8780\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2212 - acc: 0.8598\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2207 - acc: 0.8659\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2048 - acc: 0.8801\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2005 - acc: 0.8801\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2103 - acc: 0.8598\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2011 - acc: 0.8394\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2380 - acc: 0.8496\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2046 - acc: 0.8699\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1996 - acc: 0.8496\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1732 - acc: 0.8923\n",
      "123/123 [==============================] - 1s 10ms/step\n",
      "492/492 [==============================] - 0s 994us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.6666666666666666, total=  40.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 7s 15ms/step - loss: 0.6830 - acc: 0.6037\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 4s 7ms/step - loss: 0.5186 - acc: 0.7561\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.3865 - acc: 0.8252\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3001 - acc: 0.8882\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2560 - acc: 0.8963\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1993 - acc: 0.9350\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1915 - acc: 0.9431\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1421 - acc: 0.9654\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1447 - acc: 0.9492\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1494 - acc: 0.9533\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1152 - acc: 0.9654\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1202 - acc: 0.9654\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1286 - acc: 0.9553\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1019 - acc: 0.9797\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0903 - acc: 0.9776\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1188 - acc: 0.9614\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0968 - acc: 0.9695\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0980 - acc: 0.9756\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1006 - acc: 0.9695\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0999 - acc: 0.9695\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0958 - acc: 0.9675\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0837 - acc: 0.9715\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1026 - acc: 0.9573\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0854 - acc: 0.9756\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0738 - acc: 0.9817\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0781 - acc: 0.9817\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0853 - acc: 0.9654\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0888 - acc: 0.9654\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0834 - acc: 0.9756\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0949 - acc: 0.9756\n",
      "123/123 [==============================] - 1s 9ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7235772357723578, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_83 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 6s 13ms/step - loss: 0.6998 - acc: 0.5041\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6035 - acc: 0.6768\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4653 - acc: 0.7846\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3476 - acc: 0.8577\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2946 - acc: 0.8780\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2346 - acc: 0.9004\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1814 - acc: 0.9309\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1822 - acc: 0.9289\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.1810 - acc: 0.9187\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.1475 - acc: 0.9512\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1400 - acc: 0.9431\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1247 - acc: 0.9695\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1236 - acc: 0.9512\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1189 - acc: 0.9634\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1255 - acc: 0.9472\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0910 - acc: 0.9776\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1182 - acc: 0.9634\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1075 - acc: 0.9715\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0966 - acc: 0.9715\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0958 - acc: 0.9634\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0923 - acc: 0.9736\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0900 - acc: 0.9797\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0890 - acc: 0.9776\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0821 - acc: 0.9736\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0994 - acc: 0.9675\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0867 - acc: 0.9756\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1000 - acc: 0.9593\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0922 - acc: 0.9817\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0776 - acc: 0.9837\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0877 - acc: 0.9776\n",
      "123/123 [==============================] - 1s 9ms/step\n",
      "492/492 [==============================] - 0s 888us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6341463419480052, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.6920 - acc: 0.5874\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5272 - acc: 0.7602\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3816 - acc: 0.8496\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3062 - acc: 0.8902\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2452 - acc: 0.9146\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2123 - acc: 0.9248\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1798 - acc: 0.9573\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1451 - acc: 0.9614\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1470 - acc: 0.9492\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1218 - acc: 0.9533\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1282 - acc: 0.9472\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1176 - acc: 0.9533\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1023 - acc: 0.9593\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1083 - acc: 0.9512\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1019 - acc: 0.9533\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0908 - acc: 0.9715\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1072 - acc: 0.9573\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0980 - acc: 0.9553\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0955 - acc: 0.9675\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1048 - acc: 0.9573\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0938 - acc: 0.9634\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0901 - acc: 0.9593\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0836 - acc: 0.9695\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1003 - acc: 0.9512\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1031 - acc: 0.9370\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0709 - acc: 0.9756\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0911 - acc: 0.9472\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0838 - acc: 0.9573\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0780 - acc: 0.9634\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0749 - acc: 0.9675\n",
      "123/123 [==============================] - 1s 10ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7560975612179051, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 7s 13ms/step - loss: 0.6898 - acc: 0.5894\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5305 - acc: 0.7520\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4121 - acc: 0.8049\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3025 - acc: 0.8740\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2412 - acc: 0.9146\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2122 - acc: 0.9126\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1860 - acc: 0.9085\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1561 - acc: 0.9207\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1527 - acc: 0.9289\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1249 - acc: 0.9533\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1350 - acc: 0.9329\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1281 - acc: 0.9451\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1091 - acc: 0.9533\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1073 - acc: 0.9451\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1012 - acc: 0.9472\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1032 - acc: 0.9329\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0978 - acc: 0.9573\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0976 - acc: 0.9472\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0982 - acc: 0.9492\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0979 - acc: 0.9451\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0921 - acc: 0.9533\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0894 - acc: 0.9451\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.0846 - acc: 0.9614\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.0839 - acc: 0.9614\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 4s 7ms/step - loss: 0.0796 - acc: 0.9492\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 4s 7ms/step - loss: 0.0855 - acc: 0.9553\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0787 - acc: 0.9593\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 4s 7ms/step - loss: 0.1112 - acc: 0.9289\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 4s 7ms/step - loss: 0.0783 - acc: 0.9492\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 4s 8ms/step - loss: 0.0760 - acc: 0.9614\n",
      "123/123 [==============================] - 2s 13ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7723577235772358, total= 1.7min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_89 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 7s 14ms/step - loss: 0.6946 - acc: 0.5752\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5161 - acc: 0.7419\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3963 - acc: 0.8232\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2994 - acc: 0.8984\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2242 - acc: 0.9329\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2023 - acc: 0.9390\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1652 - acc: 0.9614\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1561 - acc: 0.9390\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1363 - acc: 0.9573\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1367 - acc: 0.9512\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.1161 - acc: 0.9593\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1178 - acc: 0.9593\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0950 - acc: 0.9756\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1111 - acc: 0.9736\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1002 - acc: 0.9837\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0952 - acc: 0.9776\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1071 - acc: 0.9675\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0794 - acc: 0.9858\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0792 - acc: 0.9797\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0825 - acc: 0.9776\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0963 - acc: 0.9675\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0731 - acc: 0.9939\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0799 - acc: 0.9675\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0847 - acc: 0.9776\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0898 - acc: 0.9817\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0947 - acc: 0.9695\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0801 - acc: 0.9715\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0861 - acc: 0.9756\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0691 - acc: 0.9776\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0769 - acc: 0.9715\n",
      "123/123 [==============================] - 1s 11ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6666666666666666, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 5s 10ms/step - loss: 0.6926 - acc: 0.5793\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6117 - acc: 0.7033\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5266 - acc: 0.7398\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4686 - acc: 0.7805\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3969 - acc: 0.8354\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3717 - acc: 0.8394\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3291 - acc: 0.8699\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3140 - acc: 0.8659\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2823 - acc: 0.8821\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2705 - acc: 0.8801\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2861 - acc: 0.8902\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2687 - acc: 0.8862\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2570 - acc: 0.9065\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2375 - acc: 0.9248\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2237 - acc: 0.9146\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2283 - acc: 0.9085\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2283 - acc: 0.9187\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2253 - acc: 0.9146\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2078 - acc: 0.9370\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1981 - acc: 0.9309\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1965 - acc: 0.9268\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1869 - acc: 0.9533\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1857 - acc: 0.9411\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1773 - acc: 0.9512\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1693 - acc: 0.9350\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1694 - acc: 0.9593\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1785 - acc: 0.9492\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1794 - acc: 0.9472\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1576 - acc: 0.9593\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1621 - acc: 0.9614\n",
      "123/123 [==============================] - 1s 9ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7398373983739838, total=  48.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 5s 9ms/step - loss: 0.7070 - acc: 0.5142\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6382 - acc: 0.7154\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5543 - acc: 0.7785\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4788 - acc: 0.8150\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4224 - acc: 0.8557\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3789 - acc: 0.8943\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3145 - acc: 0.9106\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2802 - acc: 0.9268\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2762 - acc: 0.9451\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2658 - acc: 0.9146\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2416 - acc: 0.9492\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2236 - acc: 0.9411\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2169 - acc: 0.9411\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1919 - acc: 0.9492\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1974 - acc: 0.9370\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1842 - acc: 0.9370\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1631 - acc: 0.9533\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1574 - acc: 0.9675\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1558 - acc: 0.9553\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1715 - acc: 0.9390\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1558 - acc: 0.9553\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1371 - acc: 0.9614\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1387 - acc: 0.9654\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1366 - acc: 0.9634\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1257 - acc: 0.9593\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1392 - acc: 0.9411\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1144 - acc: 0.9654\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1204 - acc: 0.9533\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1357 - acc: 0.9573\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1128 - acc: 0.9593\n",
      "123/123 [==============================] - 1s 10ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.6504065045496312, total=  49.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 5s 10ms/step - loss: 0.7070 - acc: 0.5122\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.6592 - acc: 0.6890\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6029 - acc: 0.7337\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5234 - acc: 0.8354\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4601 - acc: 0.8476\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4289 - acc: 0.8780\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3752 - acc: 0.9126\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3409 - acc: 0.9309\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3149 - acc: 0.9431\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2785 - acc: 0.9553\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2695 - acc: 0.9390\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2527 - acc: 0.9472\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2409 - acc: 0.9533\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2408 - acc: 0.9512\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2184 - acc: 0.9715\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2124 - acc: 0.9695\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1920 - acc: 0.9675\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1822 - acc: 0.9736\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1724 - acc: 0.9878\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1794 - acc: 0.9736\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1845 - acc: 0.9654\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1701 - acc: 0.9837\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1529 - acc: 0.9878\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1630 - acc: 0.9756\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1580 - acc: 0.9736\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1577 - acc: 0.9736\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1257 - acc: 0.9858\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1382 - acc: 0.9817\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1552 - acc: 0.9756\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1273 - acc: 0.9858\n",
      "123/123 [==============================] - 1s 11ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.682926829510588, total=  49.6s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 5s 10ms/step - loss: 0.7019 - acc: 0.5102\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6122 - acc: 0.7053\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5294 - acc: 0.8049\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4313 - acc: 0.8841\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3816 - acc: 0.8923\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3672 - acc: 0.9126\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3107 - acc: 0.9431\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2787 - acc: 0.9411\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2587 - acc: 0.9593\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2429 - acc: 0.9593\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2214 - acc: 0.9715\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2174 - acc: 0.9715\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2000 - acc: 0.9797\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1939 - acc: 0.9695\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1667 - acc: 0.9858\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1783 - acc: 0.9797\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1796 - acc: 0.9858\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1740 - acc: 0.9776\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1641 - acc: 0.9858\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1509 - acc: 0.9878\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1606 - acc: 0.9837\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1398 - acc: 0.9919\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1351 - acc: 0.9858\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1272 - acc: 0.9858\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1286 - acc: 0.9878\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1419 - acc: 0.9858\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1196 - acc: 0.9939\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1325 - acc: 0.9858\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1241 - acc: 0.9817\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1118 - acc: 0.9939\n",
      "123/123 [==============================] - 1s 11ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7235772357723578, total=  49.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 5s 10ms/step - loss: 0.7049 - acc: 0.5305\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6101 - acc: 0.7114\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5308 - acc: 0.7866\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4475 - acc: 0.8415\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4200 - acc: 0.8618\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3762 - acc: 0.8882\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3312 - acc: 0.9146\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3246 - acc: 0.9309\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2531 - acc: 0.9329\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2418 - acc: 0.9512\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2426 - acc: 0.9451\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2367 - acc: 0.9634\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2185 - acc: 0.9573\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2019 - acc: 0.9654\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1789 - acc: 0.9817\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1735 - acc: 0.9797\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1653 - acc: 0.9695\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1481 - acc: 0.9776\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1674 - acc: 0.9695\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1603 - acc: 0.9715\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1470 - acc: 0.9715\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1395 - acc: 0.9817\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1245 - acc: 0.9817\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1397 - acc: 0.9756\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1460 - acc: 0.9797\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1327 - acc: 0.9695\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1238 - acc: 0.9858\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1193 - acc: 0.9837\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1282 - acc: 0.9715\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1242 - acc: 0.9797\n",
      "123/123 [==============================] - 1s 11ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.6829268292682927, total=  49.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_101 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 7s 14ms/step - loss: 0.7005 - acc: 0.5488\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5781 - acc: 0.7459\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4005 - acc: 0.8333\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2533 - acc: 0.9126\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2046 - acc: 0.9309\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1619 - acc: 0.9451\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1600 - acc: 0.9370\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1423 - acc: 0.9350\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1196 - acc: 0.9533\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1030 - acc: 0.9654\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1126 - acc: 0.9492\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1048 - acc: 0.9634\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0852 - acc: 0.9654\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0982 - acc: 0.9675\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1016 - acc: 0.9654\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0848 - acc: 0.9675\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0779 - acc: 0.9654\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0843 - acc: 0.9756\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0807 - acc: 0.9695\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0719 - acc: 0.9776\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0841 - acc: 0.9715\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0718 - acc: 0.9756\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0709 - acc: 0.9756\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0783 - acc: 0.9776\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0826 - acc: 0.9675\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0686 - acc: 0.9817\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0742 - acc: 0.9817\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0834 - acc: 0.9695\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0664 - acc: 0.9858\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0621 - acc: 0.9858\n",
      "123/123 [==============================] - 1s 11ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.7235772357723578, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_104 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 7s 15ms/step - loss: 0.6987 - acc: 0.5427\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5300 - acc: 0.7561\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3734 - acc: 0.8476\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2723 - acc: 0.8821\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2065 - acc: 0.9228\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1723 - acc: 0.9268\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1559 - acc: 0.9268\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1364 - acc: 0.9451\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1154 - acc: 0.9350\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1212 - acc: 0.9451\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1091 - acc: 0.9553\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1104 - acc: 0.9451\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0851 - acc: 0.9593\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1095 - acc: 0.9411\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0812 - acc: 0.9614\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0715 - acc: 0.9533\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0817 - acc: 0.9593\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0837 - acc: 0.9593\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0912 - acc: 0.9350\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0752 - acc: 0.9634\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0690 - acc: 0.9472\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0792 - acc: 0.9492\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0795 - acc: 0.9573\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0673 - acc: 0.9675\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0856 - acc: 0.9492\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0844 - acc: 0.9492\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0709 - acc: 0.9553\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0639 - acc: 0.9614\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0749 - acc: 0.9573\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0665 - acc: 0.9512\n",
      "123/123 [==============================] - 1s 12ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6260162606471922, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 7s 15ms/step - loss: 0.6945 - acc: 0.5549\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5659 - acc: 0.7602\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4020 - acc: 0.8455\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2829 - acc: 0.8882\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2302 - acc: 0.9289\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1912 - acc: 0.9146\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1622 - acc: 0.9472\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1298 - acc: 0.9472\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1360 - acc: 0.9431\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1080 - acc: 0.9573\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0990 - acc: 0.9614\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0971 - acc: 0.9573\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0985 - acc: 0.9492\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0933 - acc: 0.9593\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1088 - acc: 0.9451\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0846 - acc: 0.9573\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0706 - acc: 0.9675\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0844 - acc: 0.9553\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0892 - acc: 0.9472\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0865 - acc: 0.9533\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0767 - acc: 0.9634\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0776 - acc: 0.9451\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0733 - acc: 0.9614\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0734 - acc: 0.9715\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0947 - acc: 0.9451\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0915 - acc: 0.9370\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0785 - acc: 0.9472\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0729 - acc: 0.9533\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0775 - acc: 0.9553\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0729 - acc: 0.9492\n",
      "123/123 [==============================] - 2s 13ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.7398373986162791, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 8s 16ms/step - loss: 0.7069 - acc: 0.5000\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.6392 - acc: 0.6951\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4958 - acc: 0.7703\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2794 - acc: 0.8963\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2050 - acc: 0.9207\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1700 - acc: 0.9248\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1490 - acc: 0.9411\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1296 - acc: 0.9553\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1057 - acc: 0.9797\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1266 - acc: 0.9654\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1064 - acc: 0.9715\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0982 - acc: 0.9776\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0852 - acc: 0.9675\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0918 - acc: 0.9715\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0914 - acc: 0.9634\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0941 - acc: 0.9736\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0874 - acc: 0.9695\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0671 - acc: 0.9858\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0789 - acc: 0.9776\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0643 - acc: 0.9858\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0886 - acc: 0.9736\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0812 - acc: 0.9715\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0766 - acc: 0.9797\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0826 - acc: 0.9695\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0697 - acc: 0.9817\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0603 - acc: 0.9858\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0770 - acc: 0.9797\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0690 - acc: 0.9797\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0748 - acc: 0.9837\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0469 - acc: 0.9939\n",
      "123/123 [==============================] - 1s 12ms/step\n",
      "492/492 [==============================] - 0s 911us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.7723577235772358, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_113 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 7s 15ms/step - loss: 0.6974 - acc: 0.5650\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4820 - acc: 0.7886\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3504 - acc: 0.8516\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2587 - acc: 0.8923\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1855 - acc: 0.9309\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1560 - acc: 0.9451\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1424 - acc: 0.9492\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1258 - acc: 0.9553\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1052 - acc: 0.9634\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0987 - acc: 0.9675\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1020 - acc: 0.9614\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1032 - acc: 0.9593\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0934 - acc: 0.9634\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0748 - acc: 0.9776\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0843 - acc: 0.9675\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0804 - acc: 0.9837\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0624 - acc: 0.9919\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0633 - acc: 0.9817\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0676 - acc: 0.9837\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0660 - acc: 0.9715\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0716 - acc: 0.9797\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0624 - acc: 0.9878\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0711 - acc: 0.9695\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0512 - acc: 0.9898\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0536 - acc: 0.9878\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0767 - acc: 0.9797\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0504 - acc: 0.9898\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0589 - acc: 0.9858\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0699 - acc: 0.9756\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0618 - acc: 0.9797\n",
      "123/123 [==============================] - 1s 12ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6747967479674797, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_116 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.6930 - acc: 0.5427\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6042 - acc: 0.7154\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5044 - acc: 0.7744\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4323 - acc: 0.8171\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3689 - acc: 0.8638\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3214 - acc: 0.8740\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2707 - acc: 0.8943\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2399 - acc: 0.9350\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2290 - acc: 0.9146\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1984 - acc: 0.9167\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1941 - acc: 0.9350\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1557 - acc: 0.9411\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1598 - acc: 0.9309\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1709 - acc: 0.9309\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1618 - acc: 0.9370\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1371 - acc: 0.9512\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1187 - acc: 0.9614\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1319 - acc: 0.9451\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1262 - acc: 0.9553\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1251 - acc: 0.9736\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1238 - acc: 0.9593\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1142 - acc: 0.9614\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1187 - acc: 0.9614\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1290 - acc: 0.9492\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1059 - acc: 0.9573\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1150 - acc: 0.9593\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1151 - acc: 0.9573\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1077 - acc: 0.9654\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1016 - acc: 0.9715\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1004 - acc: 0.9675\n",
      "123/123 [==============================] - 2s 14ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.682926829510588, total=  50.8s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_119 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.6976 - acc: 0.5752\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5529 - acc: 0.7276\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4220 - acc: 0.8028\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3667 - acc: 0.8516\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2774 - acc: 0.9024\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2649 - acc: 0.9024\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2354 - acc: 0.9085\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2341 - acc: 0.9126\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2094 - acc: 0.9146\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1910 - acc: 0.9289\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1752 - acc: 0.9268\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1712 - acc: 0.9228\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1733 - acc: 0.9228\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1285 - acc: 0.9533\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1590 - acc: 0.9187\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1508 - acc: 0.9390\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1474 - acc: 0.9248\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1345 - acc: 0.9431\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1235 - acc: 0.9492\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1184 - acc: 0.9553\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1151 - acc: 0.9593\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1259 - acc: 0.9451\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1166 - acc: 0.9533\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1299 - acc: 0.9329\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1162 - acc: 0.9533\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1130 - acc: 0.9492\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1264 - acc: 0.9390\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1077 - acc: 0.9512\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1085 - acc: 0.9451\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1064 - acc: 0.9533\n",
      "123/123 [==============================] - 2s 13ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6504065045496312, total=  52.2s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_122 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.6926 - acc: 0.5650\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5793 - acc: 0.7154\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4941 - acc: 0.8028\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3903 - acc: 0.8394\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3636 - acc: 0.8638\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2981 - acc: 0.8923\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2747 - acc: 0.8943\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2407 - acc: 0.9167\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2172 - acc: 0.9248\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2033 - acc: 0.9370\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1853 - acc: 0.9228\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1866 - acc: 0.9268\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1579 - acc: 0.9329\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1617 - acc: 0.9350\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1502 - acc: 0.9370\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1486 - acc: 0.9289\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1323 - acc: 0.9350\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1307 - acc: 0.9289\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1227 - acc: 0.9350\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1203 - acc: 0.9289\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1337 - acc: 0.9512\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1167 - acc: 0.9593\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1185 - acc: 0.9492\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1001 - acc: 0.9736\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0989 - acc: 0.9654\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0983 - acc: 0.9756\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0881 - acc: 0.9776\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0785 - acc: 0.9817\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1146 - acc: 0.9614\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0957 - acc: 0.9756\n",
      "123/123 [==============================] - 2s 14ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.747967479917092, total=  52.0s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.7072 - acc: 0.5122\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6991 - acc: 0.6098\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.6870 - acc: 0.6728\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6650 - acc: 0.7134\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.6440 - acc: 0.7195\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6171 - acc: 0.7358\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5676 - acc: 0.7602\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5181 - acc: 0.8049\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4578 - acc: 0.8577\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4013 - acc: 0.8598\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3548 - acc: 0.8780\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3470 - acc: 0.8821\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2924 - acc: 0.9207\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2696 - acc: 0.9228\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2344 - acc: 0.9512\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2110 - acc: 0.9553\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1825 - acc: 0.9675\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1920 - acc: 0.9573\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1785 - acc: 0.9736\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1691 - acc: 0.9776\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1722 - acc: 0.9472\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1491 - acc: 0.9654\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1411 - acc: 0.9634\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1308 - acc: 0.9837\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1421 - acc: 0.9654\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1314 - acc: 0.9756\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1396 - acc: 0.9736\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1179 - acc: 0.9756\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1141 - acc: 0.9878\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1154 - acc: 0.9776\n",
      "123/123 [==============================] - 2s 14ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.7642276422764228, total=  50.6s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_128 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.7037 - acc: 0.5752\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6511 - acc: 0.7093\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5663 - acc: 0.8150\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4931 - acc: 0.8272\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4171 - acc: 0.8476\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3531 - acc: 0.8740\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2963 - acc: 0.8943\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2433 - acc: 0.9268\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2137 - acc: 0.9248\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1921 - acc: 0.9187\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1770 - acc: 0.9207\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1544 - acc: 0.9350\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1467 - acc: 0.9329\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1442 - acc: 0.9309\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1295 - acc: 0.9472\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1167 - acc: 0.9492\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1133 - acc: 0.9553\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1231 - acc: 0.9553\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1168 - acc: 0.9634\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1121 - acc: 0.9756\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1253 - acc: 0.9492\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1073 - acc: 0.9695\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1085 - acc: 0.9695\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0955 - acc: 0.9654\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1090 - acc: 0.9593\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0990 - acc: 0.9675\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0857 - acc: 0.9817\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0955 - acc: 0.9715\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1021 - acc: 0.9776\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1076 - acc: 0.9695\n",
      "123/123 [==============================] - 2s 14ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6585365853658537, total=  50.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 8s 16ms/step - loss: 0.6961 - acc: 0.5894\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5436 - acc: 0.7459\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3945 - acc: 0.8455\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2967 - acc: 0.8862\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2416 - acc: 0.9309\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2119 - acc: 0.9268\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1604 - acc: 0.9451\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1803 - acc: 0.9370\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1246 - acc: 0.9614\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1288 - acc: 0.9675\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1042 - acc: 0.9756\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0969 - acc: 0.9776\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1122 - acc: 0.9695\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0956 - acc: 0.9817\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0888 - acc: 0.9776\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0608 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0861 - acc: 0.9736\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0752 - acc: 0.9797\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0790 - acc: 0.9776\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0809 - acc: 0.9736\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0655 - acc: 0.9817\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0739 - acc: 0.9797\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0707 - acc: 0.9858\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0738 - acc: 0.9776\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0867 - acc: 0.9736\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0519 - acc: 0.9837\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0569 - acc: 0.9878\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0576 - acc: 0.9878\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0494 - acc: 0.9898\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0597 - acc: 0.9858\n",
      "123/123 [==============================] - 2s 15ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.6747967484520703, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_134 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 8s 16ms/step - loss: 0.6946 - acc: 0.5935\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5301 - acc: 0.7276\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4066 - acc: 0.8069\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2848 - acc: 0.8699\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2313 - acc: 0.9024\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1897 - acc: 0.9268\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1731 - acc: 0.9207\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1633 - acc: 0.9451\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1496 - acc: 0.9593\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1054 - acc: 0.9797\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1063 - acc: 0.9797\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1038 - acc: 0.9858\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0988 - acc: 0.9817\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0986 - acc: 0.9797\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0824 - acc: 0.9858\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0804 - acc: 0.9858\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0870 - acc: 0.9817\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0823 - acc: 0.9817\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0670 - acc: 0.9919\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0798 - acc: 0.9837\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0662 - acc: 0.9898\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0788 - acc: 0.9837\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0675 - acc: 0.9858\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0662 - acc: 0.9898\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0622 - acc: 0.9858\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0668 - acc: 0.9858\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0529 - acc: 0.9939\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0568 - acc: 0.9939\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0512 - acc: 0.9898\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0601 - acc: 0.9878\n",
      "123/123 [==============================] - 2s 15ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7235772362569484, total= 1.6min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_137 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 8s 16ms/step - loss: 0.6964 - acc: 0.5732\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5346 - acc: 0.7541\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3847 - acc: 0.8171\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2767 - acc: 0.8943\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2408 - acc: 0.9146\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2073 - acc: 0.9329\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0468 - acc: 0.9898\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0467 - acc: 0.9980\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0415 - acc: 0.9939\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0422 - acc: 0.9959\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0401 - acc: 0.9939\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0404 - acc: 0.9980\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0320 - acc: 0.9959\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0357 - acc: 0.9959\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0313 - acc: 0.9980\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0373 - acc: 0.9959\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 6s 13ms/step - loss: 0.0329 - acc: 0.9980\n",
      "123/123 [==============================] - 2s 19ms/step\n",
      "492/492 [==============================] - 1s 2ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6666666666666666, total= 3.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_171 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,290,913\n",
      "Trainable params: 1,290,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 8s 17ms/step - loss: 0.7197 - acc: 0.5488\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.6049 - acc: 0.7988\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.5132 - acc: 0.8252\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.4296 - acc: 0.8963\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.3567 - acc: 0.9106\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.3272 - acc: 0.9228\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2721 - acc: 0.9492\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.2397 - acc: 0.9695\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2267 - acc: 0.9695\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2004 - acc: 0.9858\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1810 - acc: 0.9858\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1860 - acc: 0.9736\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1643 - acc: 0.9878\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1454 - acc: 0.9898\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1500 - acc: 0.9898\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1376 - acc: 0.9939\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1342 - acc: 0.9939\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1286 - acc: 0.9898\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1246 - acc: 0.9919\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1105 - acc: 0.9959\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.3863 - acc: 0.9085\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.3448 - acc: 0.9289\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2911 - acc: 0.9593\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.2599 - acc: 0.9512\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.2477 - acc: 0.9654\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.2401 - acc: 0.9573\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.2143 - acc: 0.9756\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1883 - acc: 0.9858\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1869 - acc: 0.9736\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1696 - acc: 0.9858\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1623 - acc: 0.9837\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1540 - acc: 0.9878\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1469 - acc: 0.9776\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1338 - acc: 0.9939\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1385 - acc: 0.9939\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1189 - acc: 0.9919\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1125 - acc: 0.9919\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1222 - acc: 0.9898\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1152 - acc: 0.9959\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1081 - acc: 0.9919\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1018 - acc: 0.9878\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1102 - acc: 0.9919\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1045 - acc: 0.9858\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.0962 - acc: 0.9959\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1061 - acc: 0.9898\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.0912 - acc: 0.9980\n",
      "123/123 [==============================] - 3s 20ms/step\n",
      "492/492 [==============================] - 1s 2ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.772357723819531, total= 1.4min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_177 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,290,913\n",
      "Trainable params: 1,290,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.2960 - acc: 0.9106\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.1773 - acc: 0.9634\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.1198 - acc: 0.9797\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0942 - acc: 0.9776\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0736 - acc: 0.9878\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0661 - acc: 0.9939\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0546 - acc: 0.9939\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0442 - acc: 0.9980\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0516 - acc: 0.9919\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 5s 11ms/step - loss: 0.0492 - acc: 0.9959\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0483 - acc: 0.9898\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0410 - acc: 0.9898\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0312 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0397 - acc: 0.9980\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 5s 11ms/step - loss: 0.0371 - acc: 0.9959\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0386 - acc: 0.9959\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 5s 11ms/step - loss: 0.0350 - acc: 0.9939\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0380 - acc: 0.9939\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0252 - acc: 0.9939\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0561 - acc: 0.9980\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0652 - acc: 0.9837\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0494 - acc: 0.9898\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0550 - acc: 0.9837\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0414 - acc: 0.9919\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0470 - acc: 0.9898\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0523 - acc: 0.9878\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0378 - acc: 0.9919\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0361 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0397 - acc: 0.9919\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0341 - acc: 0.9878\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0435 - acc: 0.9919\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0459 - acc: 0.9878\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0308 - acc: 0.9959\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0316 - acc: 0.9939\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0362 - acc: 0.9919\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0264 - acc: 0.9959\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0380 - acc: 0.9878\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0301 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0299 - acc: 0.9939\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0291 - acc: 0.9919\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0327 - acc: 0.9919\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0263 - acc: 0.9959\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0224 - acc: 0.9980\n",
      "123/123 [==============================] - 3s 28ms/step\n",
      "492/492 [==============================] - 1s 2ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.7479674801593874, total= 3.1min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_190 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 12s 25ms/step - loss: 0.7105 - acc: 0.5488\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.5292 - acc: 0.7602\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.3335 - acc: 0.8760\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.2211 - acc: 0.9126\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.1542 - acc: 0.9675\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0992 - acc: 0.9858\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0972 - acc: 0.9736\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0747 - acc: 0.9817\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0720 - acc: 0.9878\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0567 - acc: 0.9919\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0517 - acc: 0.9878\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0434 - acc: 0.9939\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0466 - acc: 0.9919\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0454 - acc: 0.9898\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0347 - acc: 0.9898\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0364 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0257 - acc: 0.9939\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0217 - acc: 0.9959\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0225 - acc: 0.9959\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0177 - acc: 0.9980\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0210 - acc: 0.9939\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0211 - acc: 0.9980\n",
      "123/123 [==============================] - 3s 22ms/step\n",
      "492/492 [==============================] - 1s 2ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6747967479674797, total= 3.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_196 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 9s 18ms/step - loss: 0.7262 - acc: 0.4654\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.7133 - acc: 0.6280\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6942 - acc: 0.7297\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6638 - acc: 0.7744\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6202 - acc: 0.7967\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.5532 - acc: 0.8557\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.5018 - acc: 0.8557\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.4192 - acc: 0.9187\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.3511 - acc: 0.9289\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.3061 - acc: 0.9512\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2649 - acc: 0.9350\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2281 - acc: 0.9593\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1951 - acc: 0.9776\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1738 - acc: 0.9756\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1467 - acc: 0.9878\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1443 - acc: 0.9776\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1303 - acc: 0.9837\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1173 - acc: 0.9858\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1075 - acc: 0.9858\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1106 - acc: 0.9837\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1040 - acc: 0.9858\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0939 - acc: 0.9898\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1443 - acc: 0.9837\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1426 - acc: 0.9817\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1285 - acc: 0.9756\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1299 - acc: 0.9756\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1169 - acc: 0.9919\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1147 - acc: 0.9919\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1108 - acc: 0.9837\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1048 - acc: 0.9858\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1000 - acc: 0.9837\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0851 - acc: 0.9919\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0928 - acc: 0.9878\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0788 - acc: 0.9939\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0844 - acc: 0.9858\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.0882 - acc: 0.9837\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.0799 - acc: 0.9939\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0838 - acc: 0.9919\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.0758 - acc: 0.9898\n",
      "123/123 [==============================] - 2s 20ms/step\n",
      "492/492 [==============================] - 1s 2ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.7398373986162791, total= 1.4min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_205 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 9s 17ms/step - loss: 0.7212 - acc: 0.5142\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6764 - acc: 0.7236\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.6291 - acc: 0.7480\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.5697 - acc: 0.8211\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.4787 - acc: 0.8618\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.4388 - acc: 0.8638\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.3914 - acc: 0.8923\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.3174 - acc: 0.9329\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2779 - acc: 0.9411\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2404 - acc: 0.9654\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2162 - acc: 0.9736\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2118 - acc: 0.9654\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1903 - acc: 0.9695\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1643 - acc: 0.9837\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1457 - acc: 0.9797\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1447 - acc: 0.9898\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1176 - acc: 0.9939\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1230 - acc: 0.9919\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0734 - acc: 0.9776\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0567 - acc: 0.9919\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0468 - acc: 0.9898\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0406 - acc: 0.9898\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0388 - acc: 0.9939\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0496 - acc: 0.9898\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0440 - acc: 0.9837\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0358 - acc: 0.9939\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0424 - acc: 0.9939\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0294 - acc: 0.9939\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0355 - acc: 0.9919\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0249 - acc: 0.9980\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0313 - acc: 0.9959\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0353 - acc: 0.9939\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0289 - acc: 0.9919\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0217 - acc: 0.9959\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0289 - acc: 0.9919\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0285 - acc: 0.9939\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0283 - acc: 0.9980\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0335 - acc: 0.9858\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 13s 27ms/step - loss: 0.6936 - acc: 0.6098\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.4318 - acc: 0.8394\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.2654 - acc: 0.9146\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.1545 - acc: 0.9614\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 5s 11ms/step - loss: 0.1006 - acc: 0.9776\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0937 - acc: 0.9817\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0730 - acc: 0.9878\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0653 - acc: 0.9919\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0490 - acc: 0.9898\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0572 - acc: 0.9939\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0430 - acc: 0.9939\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0428 - acc: 0.9898\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0447 - acc: 0.9858\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0374 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0370 - acc: 0.9898\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0420 - acc: 0.9939\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0363 - acc: 0.9939\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0304 - acc: 0.9939\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0287 - acc: 0.9959\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0405 - acc: 0.9939\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 13s 25ms/step - loss: 0.7063 - acc: 0.5833\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.4815 - acc: 0.8049\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.2577 - acc: 0.9268\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.1626 - acc: 0.9553\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.1086 - acc: 0.9817\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0723 - acc: 0.9919\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0578 - acc: 0.9919\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0521 - acc: 0.9939\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0518 - acc: 0.9898\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0351 - acc: 0.9980\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0392 - acc: 0.9980\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0325 - acc: 0.9939\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 6s 12ms/step - loss: 0.0275 - acc: 0.9959\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0241 - acc: 0.9959\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0246 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0295 - acc: 0.9959\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0203 - acc: 0.9980\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 6s 11ms/step - loss: 0.0248 - acc: 0.9919\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0824 - acc: 0.9939\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0958 - acc: 0.9797\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0898 - acc: 0.9959\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0858 - acc: 0.9878\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0799 - acc: 0.9919\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0816 - acc: 0.9919\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0737 - acc: 0.9939\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0673 - acc: 0.9919\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0703 - acc: 0.9939\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0698 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0663 - acc: 0.9980\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0727 - acc: 0.9878\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0721 - acc: 0.9959\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0705 - acc: 0.9878\n",
      "123/123 [==============================] - 3s 25ms/step\n",
      "492/492 [==============================] - 1s 2ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.6747967484520703, total= 1.5min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=8, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_232 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 10s 20ms/step - loss: 0.7235 - acc: 0.5386\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.6654 - acc: 0.7297\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.5874 - acc: 0.8191\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.4965 - acc: 0.8740\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4168 - acc: 0.9045\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.3249 - acc: 0.9451\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2799 - acc: 0.9573\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2485 - acc: 0.9431\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.2127 - acc: 0.9715\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1884 - acc: 0.9654\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1617 - acc: 0.9776\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1498 - acc: 0.9776\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1451 - acc: 0.9776\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1149 - acc: 0.9878\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1077 - acc: 0.9939\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.1118 - acc: 0.9939\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1141 - acc: 0.9898\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1020 - acc: 0.9878\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.1005 - acc: 0.9878\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 5ms/step - loss: 0.0979 - acc: 0.9858\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0863 - acc: 0.9959\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 5ms/step - loss: 0.0893 - acc: 0.9939\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4632 - acc: 0.7561\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3574 - acc: 0.8293\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3268 - acc: 0.8435\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3110 - acc: 0.8150\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2603 - acc: 0.8577\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2571 - acc: 0.8476\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2188 - acc: 0.8618\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2234 - acc: 0.8455\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2138 - acc: 0.8496\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2219 - acc: 0.8476\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2161 - acc: 0.8476\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2255 - acc: 0.8293\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2098 - acc: 0.8557\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1899 - acc: 0.8902\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2250 - acc: 0.8557\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2035 - acc: 0.8476\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1851 - acc: 0.8618\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2138 - acc: 0.8455\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2087 - acc: 0.8496\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2258 - acc: 0.8069\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2227 - acc: 0.8313\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1725 - acc: 0.8760\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2073 - acc: 0.8537\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2166 - acc: 0.8252\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2138 - acc: 0.8313\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1857 - acc: 0.8679\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1817 - acc: 0.8699\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1815 - acc: 0.8740\n",
      "123/123 [==============================] - 3s 23ms/step\n",
      "492/492 [==============================] - 0s 691us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7073170755936847, total=  47.0s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_243 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 8s 17ms/step - loss: 0.6887 - acc: 0.5467\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6207 - acc: 0.6585\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5187 - acc: 0.7276\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4510 - acc: 0.7825\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3913 - acc: 0.8171\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3415 - acc: 0.8496\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3187 - acc: 0.8598\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2907 - acc: 0.8760\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2973 - acc: 0.8801\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2764 - acc: 0.8984\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2493 - acc: 0.9146\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2567 - acc: 0.9126\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2645 - acc: 0.9004\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2621 - acc: 0.9167\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2278 - acc: 0.9228\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2458 - acc: 0.9126\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2263 - acc: 0.9411\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2336 - acc: 0.9309\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2415 - acc: 0.9106\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2287 - acc: 0.9228\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2274 - acc: 0.9289\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2191 - acc: 0.9451\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2302 - acc: 0.9309\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2167 - acc: 0.9248\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2255 - acc: 0.9268\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2106 - acc: 0.9390\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2028 - acc: 0.9268\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2050 - acc: 0.9390\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1996 - acc: 0.9309\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1878 - acc: 0.9431\n",
      "123/123 [==============================] - 3s 24ms/step\n",
      "492/492 [==============================] - 0s 787us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6422764217950464, total=  47.5s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_245 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 8s 17ms/step - loss: 0.7037 - acc: 0.5508\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6349 - acc: 0.6301\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5356 - acc: 0.7276\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4507 - acc: 0.7866\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3959 - acc: 0.8089\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3777 - acc: 0.8028\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3477 - acc: 0.8516\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3281 - acc: 0.8516\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3055 - acc: 0.8841\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2836 - acc: 0.8984\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3010 - acc: 0.8882\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2736 - acc: 0.8984\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2712 - acc: 0.8862\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2502 - acc: 0.9045\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2654 - acc: 0.9045\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2654 - acc: 0.9126\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2472 - acc: 0.9167\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2420 - acc: 0.9167\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2528 - acc: 0.9085\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2407 - acc: 0.9289\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2261 - acc: 0.9472\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2105 - acc: 0.9329\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2290 - acc: 0.9167\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2101 - acc: 0.9309\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2438 - acc: 0.9106\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2347 - acc: 0.9167\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2438 - acc: 0.9106\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2014 - acc: 0.9411\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2129 - acc: 0.9390\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4147 - acc: 0.8232\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4141 - acc: 0.8191\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4324 - acc: 0.8191\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4008 - acc: 0.8313\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3939 - acc: 0.8272\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3693 - acc: 0.8618\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3812 - acc: 0.8455\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3644 - acc: 0.8516\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3647 - acc: 0.8537\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3546 - acc: 0.8415\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3605 - acc: 0.8394\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3218 - acc: 0.8760\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3399 - acc: 0.8638\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3286 - acc: 0.8699\n",
      "123/123 [==============================] - 3s 24ms/step\n",
      "492/492 [==============================] - 0s 784us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.6585365843966724, total=  37.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_255 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 9s 18ms/step - loss: 0.6938 - acc: 0.5346\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6244 - acc: 0.6606\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5664 - acc: 0.7073\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5034 - acc: 0.7663\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4414 - acc: 0.8211\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4273 - acc: 0.8089\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4119 - acc: 0.8089\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3699 - acc: 0.8293\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3605 - acc: 0.8415\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3477 - acc: 0.8252\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3200 - acc: 0.8537\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3329 - acc: 0.8232\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3154 - acc: 0.8537\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3014 - acc: 0.8415\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2914 - acc: 0.8476\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2817 - acc: 0.8455\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2947 - acc: 0.8496\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2652 - acc: 0.8638\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2885 - acc: 0.8435\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2521 - acc: 0.8720\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2535 - acc: 0.8537\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2775 - acc: 0.8272\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2545 - acc: 0.8598\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2367 - acc: 0.8557\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2366 - acc: 0.8720\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2425 - acc: 0.8821\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2345 - acc: 0.8740\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2438 - acc: 0.8801\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2450 - acc: 0.8598\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2465 - acc: 0.8720\n",
      "123/123 [==============================] - 3s 28ms/step\n",
      "492/492 [==============================] - 0s 820us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7560975600064286, total=  37.2s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_257 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 8s 17ms/step - loss: 0.7045 - acc: 0.4980\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6846 - acc: 0.6037\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6679 - acc: 0.6240\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6496 - acc: 0.6362\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6054 - acc: 0.7073\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5840 - acc: 0.7398\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5744 - acc: 0.7419\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5334 - acc: 0.8028\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5226 - acc: 0.8028\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5160 - acc: 0.8171\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5175 - acc: 0.8232\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4904 - acc: 0.8394\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4889 - acc: 0.8333\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4618 - acc: 0.8679\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4674 - acc: 0.8516\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4480 - acc: 0.8720\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4347 - acc: 0.8780\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4042 - acc: 0.9065\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4299 - acc: 0.8638\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4235 - acc: 0.8618\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3981 - acc: 0.8943\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4159 - acc: 0.8659\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3999 - acc: 0.8801\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3971 - acc: 0.8760\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3804 - acc: 0.8882\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3819 - acc: 0.8821\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3940 - acc: 0.8638\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3602 - acc: 0.8963\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3799 - acc: 0.8720\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3539 - acc: 0.8943\n",
      "123/123 [==============================] - 3s 27ms/step\n",
      "492/492 [==============================] - 0s 825us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.6504065055188125, total=  37.5s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_259 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 9s 17ms/step - loss: 0.7009 - acc: 0.5163\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6794 - acc: 0.5752\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6489 - acc: 0.6179\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6121 - acc: 0.6220\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5784 - acc: 0.6687\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5533 - acc: 0.6687\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5089 - acc: 0.6829\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4971 - acc: 0.6870\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4725 - acc: 0.6972\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4483 - acc: 0.7093\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4816 - acc: 0.6972\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4516 - acc: 0.7581\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1932 - acc: 0.8496\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1896 - acc: 0.8557\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2018 - acc: 0.8598\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1920 - acc: 0.8598\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1919 - acc: 0.8557\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1810 - acc: 0.8435\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1849 - acc: 0.8679\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1980 - acc: 0.8537\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1887 - acc: 0.8679\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1881 - acc: 0.8801\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1926 - acc: 0.8415\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1818 - acc: 0.8740\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2050 - acc: 0.8598\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1834 - acc: 0.8415\n",
      "123/123 [==============================] - 3s 26ms/step\n",
      "492/492 [==============================] - 0s 782us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.7479674791902061, total=  48.5s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_273 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 10s 20ms/step - loss: 0.6998 - acc: 0.5285\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6645 - acc: 0.6159\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5790 - acc: 0.7154\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4358 - acc: 0.7825\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3461 - acc: 0.8232\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2557 - acc: 0.8720\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2765 - acc: 0.8354\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2642 - acc: 0.8354\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2487 - acc: 0.8557\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2196 - acc: 0.8598\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2434 - acc: 0.8516\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2291 - acc: 0.8537\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2195 - acc: 0.8638\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2034 - acc: 0.8780\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1848 - acc: 0.8780\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1981 - acc: 0.8740\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2016 - acc: 0.8720\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2117 - acc: 0.8537\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2039 - acc: 0.8577\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1862 - acc: 0.8740\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2030 - acc: 0.8760\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1803 - acc: 0.8740\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1890 - acc: 0.8740\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1884 - acc: 0.8598\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2118 - acc: 0.8374\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2060 - acc: 0.8557\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1871 - acc: 0.8780\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1816 - acc: 0.8801\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1970 - acc: 0.8537\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1961 - acc: 0.8496\n",
      "123/123 [==============================] - 3s 27ms/step\n",
      "492/492 [==============================] - 0s 822us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6747967469982985, total=  49.5s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_276 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 11s 22ms/step - loss: 0.6988 - acc: 0.5508\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6933 - acc: 0.5752\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6823 - acc: 0.6260\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6730 - acc: 0.6220\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6620 - acc: 0.6789\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6409 - acc: 0.7093\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6210 - acc: 0.7297\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5876 - acc: 0.7500\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5698 - acc: 0.7622\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5404 - acc: 0.8069\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4979 - acc: 0.8150\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4761 - acc: 0.8171\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4564 - acc: 0.8333\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4176 - acc: 0.8638\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3754 - acc: 0.8659\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3794 - acc: 0.8638\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3611 - acc: 0.8821\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3416 - acc: 0.8801\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3289 - acc: 0.8963\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3128 - acc: 0.9065\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2827 - acc: 0.9411\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2792 - acc: 0.9289\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2948 - acc: 0.9268\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2633 - acc: 0.9228\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2721 - acc: 0.9289\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2463 - acc: 0.9370\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2340 - acc: 0.9492\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2544 - acc: 0.9187\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2284 - acc: 0.9390\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 10s 20ms/step - loss: 0.6963 - acc: 0.4939\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6670 - acc: 0.6118\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5768 - acc: 0.6951\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4889 - acc: 0.7358\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4167 - acc: 0.7846\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3520 - acc: 0.8374\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3118 - acc: 0.8801\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2766 - acc: 0.8882\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2657 - acc: 0.9024\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2563 - acc: 0.8984\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2546 - acc: 0.8984\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2232 - acc: 0.9289\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2278 - acc: 0.9065\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2054 - acc: 0.9228\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2220 - acc: 0.9085\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1906 - acc: 0.9370\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1766 - acc: 0.9411\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2073 - acc: 0.9126\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1920 - acc: 0.9350\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2115 - acc: 0.9146\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1790 - acc: 0.9411\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1886 - acc: 0.9289\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1969 - acc: 0.9167\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1997 - acc: 0.9207\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1678 - acc: 0.9411\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1934 - acc: 0.9207\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1895 - acc: 0.9248\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1896 - acc: 0.9309\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1926 - acc: 0.9268\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1317 - acc: 0.9634\n",
      "123/123 [==============================] - 4s 30ms/step\n",
      "492/492 [==============================] - 0s 859us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7154471539869541, total=  49.6s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_294 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 10s 21ms/step - loss: 0.6885 - acc: 0.5528\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5694 - acc: 0.6646\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4909 - acc: 0.7419\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4072 - acc: 0.8069\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3487 - acc: 0.8496\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3391 - acc: 0.8333\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3112 - acc: 0.8801\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2909 - acc: 0.8841\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2626 - acc: 0.9146\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2501 - acc: 0.9126\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2282 - acc: 0.9248\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2242 - acc: 0.9146\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2173 - acc: 0.9187\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2116 - acc: 0.9248\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1825 - acc: 0.9350\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1852 - acc: 0.9370\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1954 - acc: 0.9248\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1719 - acc: 0.9472\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2286 - acc: 0.8984\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2009 - acc: 0.9207\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 10s 20ms/step - loss: 0.6976 - acc: 0.5528\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6481 - acc: 0.6301\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6036 - acc: 0.6321\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5398 - acc: 0.7053\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4828 - acc: 0.7419\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4413 - acc: 0.7561\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3951 - acc: 0.8110\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3634 - acc: 0.7907\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3598 - acc: 0.8211\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3346 - acc: 0.8171\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3350 - acc: 0.8191\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2985 - acc: 0.8171\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3064 - acc: 0.8354\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2644 - acc: 0.8374\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2682 - acc: 0.8252\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2548 - acc: 0.8618\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2685 - acc: 0.8415\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2381 - acc: 0.8638\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2460 - acc: 0.8659\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2258 - acc: 0.8598\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2215 - acc: 0.8659\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2315 - acc: 0.8516\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2434 - acc: 0.8415\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2203 - acc: 0.8882\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2171 - acc: 0.8760\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2156 - acc: 0.8740\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2079 - acc: 0.8659\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2299 - acc: 0.8394\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2181 - acc: 0.8659\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2053 - acc: 0.8577\n",
      "123/123 [==============================] - 4s 30ms/step\n",
      "492/492 [==============================] - 0s 876us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.666666666182076, total=  43.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_312 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 10s 19ms/step - loss: 0.6992 - acc: 0.5467\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6786 - acc: 0.6382\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6421 - acc: 0.7012\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5967 - acc: 0.7439\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5541 - acc: 0.7764\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5292 - acc: 0.8049\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4808 - acc: 0.8333\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4495 - acc: 0.8374\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4227 - acc: 0.8618\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3917 - acc: 0.8740\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3825 - acc: 0.8679\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3452 - acc: 0.8943\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3245 - acc: 0.9004\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3021 - acc: 0.9268\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2802 - acc: 0.9289\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2897 - acc: 0.9309\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2791 - acc: 0.9248\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2720 - acc: 0.9167\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2686 - acc: 0.9289\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2616 - acc: 0.9228\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2359 - acc: 0.9329\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2483 - acc: 0.9248\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2384 - acc: 0.9309\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2250 - acc: 0.9289\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2138 - acc: 0.9370\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2220 - acc: 0.9309\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2053 - acc: 0.9411\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2167 - acc: 0.9268\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2189 - acc: 0.9268\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2064 - acc: 0.9268\n",
      "123/123 [==============================] - 4s 30ms/step\n",
      "492/492 [==============================] - 0s 816us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7317073161039895, total=  39.4s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_315 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 10s 20ms/step - loss: 0.7013 - acc: 0.4939\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6942 - acc: 0.5915\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1055 - acc: 0.9654\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0867 - acc: 0.9776\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0829 - acc: 0.9776\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0901 - acc: 0.9756\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0910 - acc: 0.9715\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0895 - acc: 0.9675\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0820 - acc: 0.9776\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0850 - acc: 0.9736\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0844 - acc: 0.9736\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0769 - acc: 0.9776\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0929 - acc: 0.9715\n",
      "123/123 [==============================] - 4s 32ms/step\n",
      "492/492 [==============================] - 0s 849us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7073170731707317, total= 1.1min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_323 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 11s 22ms/step - loss: 0.6974 - acc: 0.5691\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5544 - acc: 0.7642\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4089 - acc: 0.8455\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3141 - acc: 0.8963\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2516 - acc: 0.9126\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2098 - acc: 0.9187\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2023 - acc: 0.9248\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1710 - acc: 0.9451\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1538 - acc: 0.9512\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1497 - acc: 0.9593\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1453 - acc: 0.9533\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1376 - acc: 0.9614\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1166 - acc: 0.9553\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1136 - acc: 0.9553\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1147 - acc: 0.9553\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1185 - acc: 0.9593\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0978 - acc: 0.9675\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1078 - acc: 0.9533\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0971 - acc: 0.9654\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0897 - acc: 0.9776\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1040 - acc: 0.9695\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0839 - acc: 0.9776\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0884 - acc: 0.9675\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0888 - acc: 0.9756\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1003 - acc: 0.9654\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1093 - acc: 0.9634\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0970 - acc: 0.9715\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0744 - acc: 0.9756\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0772 - acc: 0.9878\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3396 - acc: 0.9045\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3228 - acc: 0.8882\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3130 - acc: 0.9268\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2884 - acc: 0.9248\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2946 - acc: 0.9187\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2828 - acc: 0.9350\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2758 - acc: 0.9146\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2440 - acc: 0.9512\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2517 - acc: 0.9533\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2410 - acc: 0.9451\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2575 - acc: 0.9553\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2193 - acc: 0.9512\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2266 - acc: 0.9593\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2223 - acc: 0.9553\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2253 - acc: 0.9593\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2199 - acc: 0.9533\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2081 - acc: 0.9533\n",
      "123/123 [==============================] - 4s 32ms/step\n",
      "492/492 [==============================] - 0s 720us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7073170726861411, total=  41.6s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_333 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 10s 21ms/step - loss: 0.7130 - acc: 0.4878\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6972 - acc: 0.5691\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6726 - acc: 0.6484\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6368 - acc: 0.7337\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6154 - acc: 0.7012\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5854 - acc: 0.7825\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5589 - acc: 0.7927\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5267 - acc: 0.8232\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5161 - acc: 0.8232\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4807 - acc: 0.8679\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4508 - acc: 0.8557\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4212 - acc: 0.8963\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4281 - acc: 0.8984\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4105 - acc: 0.9146\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3880 - acc: 0.9167\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3715 - acc: 0.9268\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3513 - acc: 0.9370\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3409 - acc: 0.9228\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3181 - acc: 0.9411\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3126 - acc: 0.9512\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3309 - acc: 0.9350\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2951 - acc: 0.9593\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2918 - acc: 0.9533\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2967 - acc: 0.9390\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2846 - acc: 0.9614\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2773 - acc: 0.9553\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2635 - acc: 0.9512\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2474 - acc: 0.9593\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2612 - acc: 0.9634\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2564 - acc: 0.9492\n",
      "123/123 [==============================] - 4s 33ms/step\n",
      "492/492 [==============================] - 0s 819us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.6910569125074681, total=  42.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_335 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 11s 21ms/step - loss: 0.7081 - acc: 0.5061\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6866 - acc: 0.6362\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6569 - acc: 0.6687\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6185 - acc: 0.7012\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5846 - acc: 0.7093\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5539 - acc: 0.7419\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5305 - acc: 0.7764\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5083 - acc: 0.7724\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4801 - acc: 0.8069\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4505 - acc: 0.8293\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4374 - acc: 0.8618\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4328 - acc: 0.8333\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4148 - acc: 0.8882\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3829 - acc: 0.9004\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3802 - acc: 0.8902\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3331 - acc: 0.9268\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3670 - acc: 0.8963\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3427 - acc: 0.9126\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3302 - acc: 0.9248\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3273 - acc: 0.9106\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3151 - acc: 0.9268\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3095 - acc: 0.9329\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3002 - acc: 0.9207\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2969 - acc: 0.9228\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2715 - acc: 0.9451\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2918 - acc: 0.9370\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2591 - acc: 0.9492\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2578 - acc: 0.9411\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2404 - acc: 0.9553\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2576 - acc: 0.9431\n",
      "123/123 [==============================] - 4s 34ms/step\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2157 - acc: 0.9187\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1627 - acc: 0.9593\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1440 - acc: 0.9492\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1244 - acc: 0.9573\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1111 - acc: 0.9654\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1100 - acc: 0.9573\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1097 - acc: 0.9654\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0846 - acc: 0.9695\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0895 - acc: 0.9634\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0985 - acc: 0.9675\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0878 - acc: 0.9695\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0990 - acc: 0.9695\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0885 - acc: 0.9736\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0763 - acc: 0.9797\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0885 - acc: 0.9736\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0772 - acc: 0.9756\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0669 - acc: 0.9817\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0637 - acc: 0.9797\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0523 - acc: 0.9919\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0770 - acc: 0.9695\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0660 - acc: 0.9817\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0579 - acc: 0.9837\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0684 - acc: 0.9817\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0709 - acc: 0.9695\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0618 - acc: 0.9776\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0586 - acc: 0.9837\n",
      "123/123 [==============================] - 5s 38ms/step\n",
      "492/492 [==============================] - 0s 834us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6910569129920587, total= 1.1min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_344 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_345 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 12s 24ms/step - loss: 0.6881 - acc: 0.5793\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5318 - acc: 0.7520\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3841 - acc: 0.8374\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2809 - acc: 0.8923\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2410 - acc: 0.9085\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.2108 - acc: 0.9411\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1531 - acc: 0.9472\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1560 - acc: 0.9593\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1444 - acc: 0.9736\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1240 - acc: 0.9776\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1268 - acc: 0.9837\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1040 - acc: 0.9817\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1003 - acc: 0.9817\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1108 - acc: 0.9756\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1019 - acc: 0.9797\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0903 - acc: 0.9837\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.1046 - acc: 0.9756\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0829 - acc: 0.9878\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0747 - acc: 0.9898\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0771 - acc: 0.9878\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0879 - acc: 0.9837\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0760 - acc: 0.9837\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0784 - acc: 0.9878\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0775 - acc: 0.9878\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0680 - acc: 0.9878\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.0577 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3412 - acc: 0.8679\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3234 - acc: 0.8638\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2729 - acc: 0.9024\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2459 - acc: 0.9065\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2692 - acc: 0.8862\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2417 - acc: 0.9024\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2135 - acc: 0.9268\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2159 - acc: 0.9146\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1942 - acc: 0.9187\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2042 - acc: 0.8984\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1720 - acc: 0.9309\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1711 - acc: 0.9451\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1827 - acc: 0.9268\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1755 - acc: 0.9350\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1767 - acc: 0.9289\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1620 - acc: 0.9207\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1443 - acc: 0.9492\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1530 - acc: 0.9390\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1416 - acc: 0.9390\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1506 - acc: 0.9492\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1490 - acc: 0.9309\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1275 - acc: 0.9573\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1481 - acc: 0.9309\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1319 - acc: 0.9329\n",
      "123/123 [==============================] - 4s 34ms/step\n",
      "492/492 [==============================] - 0s 933us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6341463434017771, total=  44.3s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_362 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_363 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_364 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 11s 23ms/step - loss: 0.7091 - acc: 0.5102\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6860 - acc: 0.6484\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6614 - acc: 0.7053\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6311 - acc: 0.7581\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5934 - acc: 0.7744\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5538 - acc: 0.8171\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5086 - acc: 0.8435\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4715 - acc: 0.8618\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4348 - acc: 0.8557\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4160 - acc: 0.8780\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3838 - acc: 0.8760\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3609 - acc: 0.9085\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3314 - acc: 0.9024\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2844 - acc: 0.9350\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2749 - acc: 0.9289\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2577 - acc: 0.9268\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2576 - acc: 0.9309\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2273 - acc: 0.9309\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2219 - acc: 0.9390\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1961 - acc: 0.9370\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2062 - acc: 0.9329\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1955 - acc: 0.9431\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1669 - acc: 0.9593\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1706 - acc: 0.9593\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1648 - acc: 0.9553\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1616 - acc: 0.9472\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1350 - acc: 0.9614\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1396 - acc: 0.9573\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1320 - acc: 0.9634\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1320 - acc: 0.9675\n",
      "123/123 [==============================] - 4s 32ms/step\n",
      "492/492 [==============================] - 0s 995us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.7642276442147852, total=  43.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_365 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_366 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_367 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 11s 23ms/step - loss: 0.7088 - acc: 0.5020\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7074 - acc: 0.5894\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7052 - acc: 0.6016\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7032 - acc: 0.6321\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6994 - acc: 0.6443\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6944 - acc: 0.6667\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6873 - acc: 0.6829\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6821 - acc: 0.6850\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6719 - acc: 0.6951\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6548 - acc: 0.7500\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6351 - acc: 0.7642\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6071 - acc: 0.7703\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5796 - acc: 0.7927\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5466 - acc: 0.8110\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4931 - acc: 0.8313\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4802 - acc: 0.8313\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4239 - acc: 0.8679\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4112 - acc: 0.8333\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3601 - acc: 0.8943\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3378 - acc: 0.8943\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1126 - acc: 0.9370\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1058 - acc: 0.9512\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0847 - acc: 0.9573\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0679 - acc: 0.9675\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0844 - acc: 0.9512\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0878 - acc: 0.9512\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0914 - acc: 0.9593\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0657 - acc: 0.9654\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0822 - acc: 0.9492\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0723 - acc: 0.9553\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0754 - acc: 0.9553\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0673 - acc: 0.9654\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0867 - acc: 0.9431\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0697 - acc: 0.9634\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0632 - acc: 0.9593\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0686 - acc: 0.9614\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0559 - acc: 0.9695\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0694 - acc: 0.9431\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0638 - acc: 0.9593\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0729 - acc: 0.9512\n",
      "123/123 [==============================] - 5s 39ms/step\n",
      "492/492 [==============================] - 0s 783us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7479674787056155, total= 1.1min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_380 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_381 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_382 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 13s 26ms/step - loss: 0.7005 - acc: 0.5346\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5902 - acc: 0.7073\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4341 - acc: 0.8293\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3118 - acc: 0.8821\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2119 - acc: 0.9248\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1921 - acc: 0.9248\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1557 - acc: 0.9370\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1346 - acc: 0.9390\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1157 - acc: 0.9573\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1269 - acc: 0.9370\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1209 - acc: 0.9390\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1108 - acc: 0.9451\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1000 - acc: 0.9553\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1061 - acc: 0.9492\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0899 - acc: 0.9573\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0870 - acc: 0.9573\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0976 - acc: 0.9492\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0780 - acc: 0.9553\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0900 - acc: 0.9492\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0785 - acc: 0.9553\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0690 - acc: 0.9695\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0736 - acc: 0.9593\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0918 - acc: 0.9431\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0503 - acc: 0.9736\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0633 - acc: 0.9593\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0795 - acc: 0.9390\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0671 - acc: 0.9614\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0652 - acc: 0.9573\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0725 - acc: 0.9533\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0706 - acc: 0.9634\n",
      "123/123 [==============================] - 4s 34ms/step\n",
      "492/492 [==============================] - 0s 856us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7560975604910192, total= 1.1min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_383 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_384 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_385 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 14s 28ms/step - loss: 0.6975 - acc: 0.5528\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5494 - acc: 0.7724\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4036 - acc: 0.8394\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - 5s 38ms/step\n",
      "492/492 [==============================] - 0s 841us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7723577230926452, total=  46.2s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_398 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_399 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_400 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 13s 26ms/step - loss: 0.7096 - acc: 0.4939\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6727 - acc: 0.6524\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6281 - acc: 0.7419\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5769 - acc: 0.8028\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5297 - acc: 0.8415\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4949 - acc: 0.8618\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4341 - acc: 0.8963\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4088 - acc: 0.9004\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3768 - acc: 0.9309\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3506 - acc: 0.9350\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3215 - acc: 0.9512\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3096 - acc: 0.9654\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3088 - acc: 0.9634\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2575 - acc: 0.9695\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2799 - acc: 0.9634\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2354 - acc: 0.9675\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2182 - acc: 0.9756\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2145 - acc: 0.9654\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1822 - acc: 0.9858\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1882 - acc: 0.9797\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1722 - acc: 0.9878\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1925 - acc: 0.9654\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1760 - acc: 0.9736\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1547 - acc: 0.9797\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1498 - acc: 0.9756\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1581 - acc: 0.9878\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1602 - acc: 0.9797\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1360 - acc: 0.9858\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1549 - acc: 0.9736\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1387 - acc: 0.9776\n",
      "123/123 [==============================] - 5s 38ms/step\n",
      "492/492 [==============================] - 0s 839us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7073170726861411, total=  45.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_401 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_402 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,290,913\n",
      "Trainable params: 1,290,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 14s 28ms/step - loss: 0.6963 - acc: 0.6057\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4753 - acc: 0.8211\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3213 - acc: 0.9167\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2189 - acc: 0.9573\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1743 - acc: 0.9593\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1332 - acc: 0.9858\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1226 - acc: 0.9756\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0952 - acc: 0.9898\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0898 - acc: 0.9919\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0769 - acc: 0.9919\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0664 - acc: 0.9919\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0741 - acc: 0.9878\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0582 - acc: 0.9959\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0538 - acc: 0.9959\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0593 - acc: 0.9898\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0570 - acc: 0.9898\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0571 - acc: 0.9898\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0520 - acc: 0.9959\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0497 - acc: 0.9919\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0487 - acc: 0.9878\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0443 - acc: 0.9919\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0383 - acc: 0.9980\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0488 - acc: 0.9898\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1096 - acc: 0.9878\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0926 - acc: 0.9878\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0844 - acc: 0.9939\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0795 - acc: 0.9898\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0745 - acc: 0.9919\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0670 - acc: 0.9919\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0642 - acc: 0.9919\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0606 - acc: 0.9919\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0595 - acc: 0.9898\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0571 - acc: 0.9959\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0573 - acc: 0.9959\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0628 - acc: 0.9878\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0594 - acc: 0.9837\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0440 - acc: 0.9980\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0499 - acc: 0.9919\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0471 - acc: 0.9959\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0412 - acc: 0.9959\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0405 - acc: 0.9980\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0362 - acc: 0.9980\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0471 - acc: 0.9939\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0446 - acc: 0.9919\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0450 - acc: 0.9939\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0399 - acc: 0.9959\n",
      "123/123 [==============================] - 5s 41ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7560975604910192, total= 1.7min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_409 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,290,913\n",
      "Trainable params: 1,290,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 15s 30ms/step - loss: 0.7020 - acc: 0.5915\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4923 - acc: 0.8272\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3163 - acc: 0.9085\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2085 - acc: 0.9654\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1533 - acc: 0.9695\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1412 - acc: 0.9715\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2497 - acc: 0.9553\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2254 - acc: 0.9736\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2318 - acc: 0.9736\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2280 - acc: 0.9695\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2246 - acc: 0.9776\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2129 - acc: 0.9715\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1892 - acc: 0.9837\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1921 - acc: 0.9736\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1794 - acc: 0.9776\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1802 - acc: 0.9898\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1765 - acc: 0.9837\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1815 - acc: 0.9797\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1583 - acc: 0.9837\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1534 - acc: 0.9919\n",
      "123/123 [==============================] - 6s 46ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7642276446993758, total= 1.1min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_419 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_420 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,290,913\n",
      "Trainable params: 1,290,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 13s 26ms/step - loss: 0.7239 - acc: 0.5203\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6754 - acc: 0.7337\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6083 - acc: 0.7886\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5736 - acc: 0.8252\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5254 - acc: 0.8679\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4899 - acc: 0.8902\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4310 - acc: 0.8882\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4036 - acc: 0.9248\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3746 - acc: 0.9472\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3594 - acc: 0.9431\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3176 - acc: 0.9472\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3029 - acc: 0.9736\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2981 - acc: 0.9614\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2756 - acc: 0.9634\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2921 - acc: 0.9593\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2444 - acc: 0.9756\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2389 - acc: 0.9817\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2245 - acc: 0.9797\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2172 - acc: 0.9776\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2069 - acc: 0.9817\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2078 - acc: 0.9776\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1927 - acc: 0.9837\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1944 - acc: 0.9756\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2011 - acc: 0.9919\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1695 - acc: 0.9837\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1625 - acc: 0.9919\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1704 - acc: 0.9776\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1605 - acc: 0.9980\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1537 - acc: 0.9858\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1516 - acc: 0.9939\n",
      "123/123 [==============================] - 5s 40ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.682926828783702, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_421 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_423 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 16s 33ms/step - loss: 0.7177 - acc: 0.6016\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5984 - acc: 0.7602\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3794 - acc: 0.8577\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2138 - acc: 0.9370\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1416 - acc: 0.9776\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1202 - acc: 0.9634\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0904 - acc: 0.9878\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0750 - acc: 0.9919\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0593 - acc: 0.9959\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0672 - acc: 0.9939\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0642 - acc: 0.9858\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0490 - acc: 0.9898\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0475 - acc: 0.9919\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0537 - acc: 0.9939\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0503 - acc: 0.9959\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0490 - acc: 0.9980\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0564 - acc: 0.9878\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0514 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0348 - acc: 0.9980\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0309 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0425 - acc: 0.9919\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0372 - acc: 0.9939\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0358 - acc: 0.9959\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0383 - acc: 0.9939\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0354 - acc: 0.9939\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0329 - acc: 0.9919\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0397 - acc: 0.9919\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0346 - acc: 0.9898\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0335 - acc: 0.9959\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0241 - acc: 0.9980\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0392 - acc: 0.9878\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0353 - acc: 0.9919\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0273 - acc: 0.9959\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0286 - acc: 0.9959\n",
      "123/123 [==============================] - 5s 43ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.65040650358045, total= 1.8min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_427 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_428 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_429 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 16s 32ms/step - loss: 0.6978 - acc: 0.5915\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4687 - acc: 0.7947\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3146 - acc: 0.9045\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 4s 7ms/step - loss: 0.2104 - acc: 0.9472\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1588 - acc: 0.9614\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1250 - acc: 0.9634\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1021 - acc: 0.9817\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0945 - acc: 0.9797\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0785 - acc: 0.9858\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0752 - acc: 0.9797\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0739 - acc: 0.9817\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0653 - acc: 0.9878\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0609 - acc: 0.9858\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0462 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0505 - acc: 0.9919\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0450 - acc: 0.9939\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0458 - acc: 0.9939\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0415 - acc: 0.9939\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0408 - acc: 0.9959\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2771 - acc: 0.9533\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2606 - acc: 0.9553\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2419 - acc: 0.9553\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2342 - acc: 0.9634\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2052 - acc: 0.9614\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2015 - acc: 0.9736\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1770 - acc: 0.9858\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1665 - acc: 0.9715\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1709 - acc: 0.9695\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1531 - acc: 0.9919\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1488 - acc: 0.9817\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1406 - acc: 0.9797\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1299 - acc: 0.9797\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1289 - acc: 0.9898\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1207 - acc: 0.9837\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1193 - acc: 0.9858\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1117 - acc: 0.9959\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1061 - acc: 0.9959\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1035 - acc: 0.9898\n",
      "123/123 [==============================] - 6s 46ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6666666686050291, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_442 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_444 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 14s 28ms/step - loss: 0.7130 - acc: 0.5386\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5945 - acc: 0.7663\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4980 - acc: 0.8435\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4270 - acc: 0.8841\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3697 - acc: 0.9045\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2991 - acc: 0.9593\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2805 - acc: 0.9492\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2631 - acc: 0.9614\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2353 - acc: 0.9654\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1980 - acc: 0.9797\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1788 - acc: 0.9898\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1866 - acc: 0.9715\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1677 - acc: 0.9878\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1509 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1461 - acc: 0.9919\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1375 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1259 - acc: 0.9939\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1318 - acc: 0.9919\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1271 - acc: 0.9878\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1092 - acc: 0.9919\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1212 - acc: 0.9878\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1185 - acc: 0.9898\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1115 - acc: 0.9898\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1117 - acc: 0.9959\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1072 - acc: 0.9898\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1026 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0913 - acc: 0.9980\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0983 - acc: 0.9919\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0900 - acc: 0.9980\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0982 - acc: 0.9898\n",
      "123/123 [==============================] - 5s 41ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.7479674787056155, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_445 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_446 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_447 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 14s 29ms/step - loss: 0.7226 - acc: 0.5366\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6688 - acc: 0.7012\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6008 - acc: 0.7663\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5279 - acc: 0.8516\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4540 - acc: 0.8821\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4134 - acc: 0.8902\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3602 - acc: 0.9207\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3295 - acc: 0.9350\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2924 - acc: 0.9309\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2500 - acc: 0.9715\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2503 - acc: 0.9614\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2280 - acc: 0.9675\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1953 - acc: 0.9715\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1875 - acc: 0.9797\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1754 - acc: 0.9797\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1594 - acc: 0.9837\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1562 - acc: 0.9776\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1551 - acc: 0.9878\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0253 - acc: 0.9939\n",
      "123/123 [==============================] - 6s 47ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7235772357723578, total= 1.8min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_454 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_455 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_456 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 17s 34ms/step - loss: 0.7050 - acc: 0.5346\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.5264 - acc: 0.8008\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.3061 - acc: 0.8984\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2049 - acc: 0.9492\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1432 - acc: 0.9776\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1228 - acc: 0.9776\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1118 - acc: 0.9776\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0856 - acc: 0.9858\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0685 - acc: 0.9878\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0725 - acc: 0.9837\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0617 - acc: 0.9878\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0592 - acc: 0.9898\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0630 - acc: 0.9919\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0471 - acc: 0.9959\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0345 - acc: 0.9959\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0480 - acc: 0.9939\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0371 - acc: 0.9980\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0501 - acc: 0.9898\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0355 - acc: 0.9980\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0321 - acc: 0.9959\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0368 - acc: 0.9959\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0349 - acc: 0.9939\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0368 - acc: 0.9939\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0334 - acc: 0.9959\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0287 - acc: 0.9980\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0341 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0327 - acc: 0.9980\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0280 - acc: 0.9980\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.0349 - acc: 0.9898\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 3s 7ms/step - loss: 0.0328 - acc: 0.9939\n",
      "123/123 [==============================] - 8s 63ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.658536587304216, total= 1.9min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_457 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_458 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_459 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 25s 50ms/step - loss: 0.7051 - acc: 0.6037\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.4565 - acc: 0.8191\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.2827 - acc: 0.9085\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1820 - acc: 0.9634\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1499 - acc: 0.9573\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1114 - acc: 0.9776\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 3s 6ms/step - loss: 0.1017 - acc: 0.9736\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3022 - acc: 0.9228\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2889 - acc: 0.9411\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2554 - acc: 0.9675\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2522 - acc: 0.9614\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2284 - acc: 0.9573\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2261 - acc: 0.9472\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1973 - acc: 0.9736\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1872 - acc: 0.9736\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1691 - acc: 0.9817\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1685 - acc: 0.9776\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1576 - acc: 0.9756\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1582 - acc: 0.9776\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1539 - acc: 0.9858\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1426 - acc: 0.9858\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1345 - acc: 0.9797\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1405 - acc: 0.9715\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1185 - acc: 0.9858\n",
      "123/123 [==============================] - 6s 46ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7317073194961238, total= 1.1min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_469 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_470 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_471 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 14s 29ms/step - loss: 0.7203 - acc: 0.5366\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6141 - acc: 0.7256\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.5128 - acc: 0.8150\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4227 - acc: 0.8780\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3602 - acc: 0.8984\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3000 - acc: 0.9329\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2637 - acc: 0.9451\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2152 - acc: 0.9736\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2202 - acc: 0.9533\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2102 - acc: 0.9675\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1824 - acc: 0.9715\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1719 - acc: 0.9695\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1513 - acc: 0.9776\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1511 - acc: 0.9695\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1321 - acc: 0.9878\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1360 - acc: 0.9797\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1364 - acc: 0.9817\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1279 - acc: 0.9878\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1194 - acc: 0.9837\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1117 - acc: 0.9858\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1111 - acc: 0.9858\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1011 - acc: 0.9919\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1125 - acc: 0.9837\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0945 - acc: 0.9898\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0887 - acc: 0.9898\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0919 - acc: 0.9878\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1007 - acc: 0.9858\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0994 - acc: 0.9878\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.0985 - acc: 0.9898\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0821 - acc: 0.9959\n",
      "123/123 [==============================] - 6s 46ms/step\n",
      "492/492 [==============================] - 1s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.6829268312066551, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=16, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_472 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_473 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_474 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 15s 31ms/step - loss: 0.7159 - acc: 0.5874\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.6330 - acc: 0.7236\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5478 - acc: 0.8028\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4628 - acc: 0.8699\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.4446 - acc: 0.8659\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3689 - acc: 0.9146\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3533 - acc: 0.9187\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.3212 - acc: 0.9268\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2816 - acc: 0.9207\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2608 - acc: 0.9492\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2368 - acc: 0.9533\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2198 - acc: 0.9512\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.2039 - acc: 0.9634\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1914 - acc: 0.9756\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1858 - acc: 0.9776\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1773 - acc: 0.9736\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1699 - acc: 0.9675\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1608 - acc: 0.9817\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1479 - acc: 0.9817\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 3ms/step - loss: 0.1363 - acc: 0.9939\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3690 - acc: 0.8191\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3523 - acc: 0.7988\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3098 - acc: 0.8313\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2830 - acc: 0.8435\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2736 - acc: 0.8293\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2773 - acc: 0.8171\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2558 - acc: 0.8394\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2454 - acc: 0.8374\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2331 - acc: 0.8435\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2278 - acc: 0.8333\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2389 - acc: 0.8618\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2038 - acc: 0.8618\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2264 - acc: 0.8476\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1953 - acc: 0.8679\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1994 - acc: 0.8638\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1986 - acc: 0.8516\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2237 - acc: 0.8618\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2091 - acc: 0.8659\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2005 - acc: 0.8496\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2091 - acc: 0.8516\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2191 - acc: 0.8537\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2005 - acc: 0.8374\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2015 - acc: 0.8720\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2090 - acc: 0.8577\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2049 - acc: 0.8354\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2047 - acc: 0.8415\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1957 - acc: 0.8557\n",
      "123/123 [==============================] - 6s 46ms/step\n",
      "492/492 [==============================] - 0s 758us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6747967474828891, total=  48.8s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_485 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_486 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 16s 32ms/step - loss: 0.6932 - acc: 0.5630\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6199 - acc: 0.6463\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5124 - acc: 0.7419\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4585 - acc: 0.7581\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3955 - acc: 0.8333\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3540 - acc: 0.8618\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3413 - acc: 0.8557\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3410 - acc: 0.8679\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2844 - acc: 0.9024\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2729 - acc: 0.9167\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2810 - acc: 0.8923\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2492 - acc: 0.9167\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2741 - acc: 0.9187\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2374 - acc: 0.9329\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2514 - acc: 0.9309\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2358 - acc: 0.9370\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2543 - acc: 0.9248\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2514 - acc: 0.9248\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2448 - acc: 0.9309\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2224 - acc: 0.9390\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2399 - acc: 0.9350\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2292 - acc: 0.9390\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2268 - acc: 0.9228\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2486 - acc: 0.9146\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2194 - acc: 0.9350\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2434 - acc: 0.9187\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2156 - acc: 0.9390\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2115 - acc: 0.9370\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2108 - acc: 0.9289\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2103 - acc: 0.9350\n",
      "123/123 [==============================] - 6s 48ms/step\n",
      "492/492 [==============================] - 0s 724us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7398373944972588, total=  53.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_487 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_488 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 15s 31ms/step - loss: 0.6987 - acc: 0.5386\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5983 - acc: 0.6890\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5527 - acc: 0.6829\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4728 - acc: 0.7581\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4003 - acc: 0.7866\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3466 - acc: 0.8252\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3536 - acc: 0.8496\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3303 - acc: 0.8679\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3113 - acc: 0.8496\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2921 - acc: 0.9004\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2965 - acc: 0.8882\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2513 - acc: 0.9106\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2480 - acc: 0.9126\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2367 - acc: 0.9248\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2406 - acc: 0.9126\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2463 - acc: 0.9106\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2656 - acc: 0.9045\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2554 - acc: 0.9024\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2494 - acc: 0.9289\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2365 - acc: 0.9187\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2528 - acc: 0.9350\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2399 - acc: 0.9207\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2524 - acc: 0.9167\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2184 - acc: 0.9350\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2115 - acc: 0.9411\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2438 - acc: 0.9146\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2092 - acc: 0.9533\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 15s 30ms/step - loss: 0.7055 - acc: 0.4614\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6824 - acc: 0.5650\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6680 - acc: 0.6057\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6387 - acc: 0.6626\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6270 - acc: 0.6199\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5951 - acc: 0.6728\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5875 - acc: 0.6850\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5578 - acc: 0.7195\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5418 - acc: 0.7541\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5313 - acc: 0.7419\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4947 - acc: 0.7724\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4675 - acc: 0.8089\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4753 - acc: 0.7846\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4746 - acc: 0.7947\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4634 - acc: 0.7947\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4338 - acc: 0.8049\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4691 - acc: 0.7683\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4204 - acc: 0.8171\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4332 - acc: 0.7927\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4273 - acc: 0.7805\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4312 - acc: 0.7825\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3844 - acc: 0.8272\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4008 - acc: 0.7988\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3748 - acc: 0.8272\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3868 - acc: 0.7886\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3756 - acc: 0.8354\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3697 - acc: 0.8211\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3672 - acc: 0.8293\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3730 - acc: 0.8130\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3453 - acc: 0.8171\n",
      "123/123 [==============================] - 6s 47ms/step\n",
      "492/492 [==============================] - 0s 725us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.658536580035357, total=  41.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_501 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_191 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_502 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_503 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 16s 32ms/step - loss: 0.6934 - acc: 0.5508\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5874 - acc: 0.6890\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4782 - acc: 0.7358\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4201 - acc: 0.7683\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3392 - acc: 0.8476\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3000 - acc: 0.8232\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3027 - acc: 0.8069\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2858 - acc: 0.8232\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2713 - acc: 0.8252\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2194 - acc: 0.8394\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2268 - acc: 0.8496\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2218 - acc: 0.8435\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2103 - acc: 0.8618\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2124 - acc: 0.8516\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2068 - acc: 0.8435\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2190 - acc: 0.8476\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2112 - acc: 0.8333\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1960 - acc: 0.8679\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2117 - acc: 0.8435\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1955 - acc: 0.8638\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1719 - acc: 0.8801\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1799 - acc: 0.8699\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1836 - acc: 0.8496\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2305 - acc: 0.8333\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2087 - acc: 0.8394\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1908 - acc: 0.8699\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2177 - acc: 0.8191\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1692 - acc: 0.9004\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1884 - acc: 0.8557\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1723 - acc: 0.8659\n",
      "123/123 [==============================] - 7s 54ms/step\n",
      "492/492 [==============================] - 0s 980us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6991869962312341, total=  49.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_504 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_192 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_505 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_506 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 16s 33ms/step - loss: 0.7007 - acc: 0.5407\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6920 - acc: 0.6565\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6447 - acc: 0.6707\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5395 - acc: 0.7297\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4505 - acc: 0.7805\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3862 - acc: 0.8150\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3337 - acc: 0.8740\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2904 - acc: 0.9126\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2658 - acc: 0.9167\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2573 - acc: 0.9126\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2266 - acc: 0.9370\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2446 - acc: 0.9187\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2392 - acc: 0.9187\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2328 - acc: 0.9085\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2321 - acc: 0.9248\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2142 - acc: 0.9187\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2100 - acc: 0.9350\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1989 - acc: 0.9309\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1808 - acc: 0.9472\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2307 - acc: 0.9085\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1994 - acc: 0.9309\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1652 - acc: 0.9492\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1874 - acc: 0.9289\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1863 - acc: 0.9309\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1759 - acc: 0.9370\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1815 - acc: 0.9370\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1822 - acc: 0.9390\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1465 - acc: 0.9614\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1998 - acc: 0.9187\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1638 - acc: 0.9431\n",
      "123/123 [==============================] - 6s 48ms/step\n",
      "492/492 [==============================] - 0s 739us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.6747967474828891, total=  50.0s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_507 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_193 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_508 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_509 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 16s 32ms/step - loss: 0.6978 - acc: 0.4919\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6621 - acc: 0.5955\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6041 - acc: 0.6972\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5245 - acc: 0.7886\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4592 - acc: 0.8598\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4361 - acc: 0.8902\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4433 - acc: 0.8537\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4277 - acc: 0.8720\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4117 - acc: 0.8780\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4129 - acc: 0.8801\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3791 - acc: 0.8943\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3811 - acc: 0.8882\n",
      "123/123 [==============================] - 6s 52ms/step\n",
      "492/492 [==============================] - 0s 865us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6829268316912457, total=  43.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_519 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_197 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_520 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_521 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 15s 31ms/step - loss: 0.7014 - acc: 0.4959\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6996 - acc: 0.5142\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6987 - acc: 0.5447\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6970 - acc: 0.5549\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6974 - acc: 0.5346\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6947 - acc: 0.5854\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6928 - acc: 0.5976\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6927 - acc: 0.5915\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6898 - acc: 0.6179\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6893 - acc: 0.5854\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6881 - acc: 0.5976\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6834 - acc: 0.6321\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6824 - acc: 0.6301\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6786 - acc: 0.6565\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6780 - acc: 0.6301\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6745 - acc: 0.6687\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6726 - acc: 0.6463\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6669 - acc: 0.6423\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6582 - acc: 0.6565\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6562 - acc: 0.6626\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6538 - acc: 0.6524\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6408 - acc: 0.6850\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6386 - acc: 0.6850\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6301 - acc: 0.6992\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6223 - acc: 0.6850\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6210 - acc: 0.6870\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6147 - acc: 0.6768\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6034 - acc: 0.7134\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6034 - acc: 0.6850\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5840 - acc: 0.7297\n",
      "123/123 [==============================] - 7s 53ms/step\n",
      "492/492 [==============================] - 0s 738us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6585365848812631, total=  43.4s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_522 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_198 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_523 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_524 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 15s 31ms/step - loss: 0.7045 - acc: 0.4776\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6870 - acc: 0.5203\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6679 - acc: 0.5589\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6359 - acc: 0.6728\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6078 - acc: 0.7236\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5863 - acc: 0.7805\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5657 - acc: 0.7866\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5324 - acc: 0.8618\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5349 - acc: 0.8313\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4920 - acc: 0.9004\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4884 - acc: 0.8923\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4740 - acc: 0.8943\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4610 - acc: 0.8841\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4304 - acc: 0.9106\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4250 - acc: 0.9187\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4224 - acc: 0.9024\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3807 - acc: 0.9451\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3859 - acc: 0.9207\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3769 - acc: 0.9146\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3766 - acc: 0.9228\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3600 - acc: 0.9085\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3422 - acc: 0.9248\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3466 - acc: 0.9248\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3379 - acc: 0.9248\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3450 - acc: 0.9024\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3189 - acc: 0.9167\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2983 - acc: 0.9350\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2889 - acc: 0.9492\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3090 - acc: 0.9146\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2759 - acc: 0.9411\n",
      "123/123 [==============================] - 7s 54ms/step\n",
      "492/492 [==============================] - 0s 734us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.593495934474759, total=  42.8s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_525 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_526 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_527 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 15s 30ms/step - loss: 0.6989 - acc: 0.5285\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6909 - acc: 0.5325\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6809 - acc: 0.5589\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6691 - acc: 0.5833\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6613 - acc: 0.6362\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6513 - acc: 0.6565\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6482 - acc: 0.6524\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6304 - acc: 0.6829\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6225 - acc: 0.6992\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6203 - acc: 0.7358\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5991 - acc: 0.7337\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5871 - acc: 0.7886\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5790 - acc: 0.8008\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5708 - acc: 0.7988\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5680 - acc: 0.8028\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5700 - acc: 0.7967\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5381 - acc: 0.8455\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5364 - acc: 0.8313\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5299 - acc: 0.8211\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5128 - acc: 0.8435\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5033 - acc: 0.8333\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4942 - acc: 0.8415\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4984 - acc: 0.8455\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4764 - acc: 0.8516\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4820 - acc: 0.8476\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4566 - acc: 0.8618\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4430 - acc: 0.8760\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4462 - acc: 0.8516\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4338 - acc: 0.8659\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4290 - acc: 0.8760\n",
      "123/123 [==============================] - 7s 54ms/step\n",
      "492/492 [==============================] - 0s 919us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6341463361329179, total=  42.5s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_528 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_529 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_530 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 16s 32ms/step - loss: 0.7019 - acc: 0.4959\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6969 - acc: 0.5244\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6902 - acc: 0.5081\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6813 - acc: 0.5122\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6722 - acc: 0.5122\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6664 - acc: 0.5508\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6548 - acc: 0.6138\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6468 - acc: 0.6423\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6292 - acc: 0.7154\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6231 - acc: 0.6870\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6172 - acc: 0.7459\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6120 - acc: 0.7602\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5939 - acc: 0.8171\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5942 - acc: 0.7825\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5992 - acc: 0.7846\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5680 - acc: 0.8110\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5694 - acc: 0.8130\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5575 - acc: 0.8252\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5486 - acc: 0.8354\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5424 - acc: 0.8313\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5414 - acc: 0.8211\n",
      "Epoch 22/30\n",
      "123/123 [==============================] - 7s 58ms/step\n",
      "492/492 [==============================] - 0s 754us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7479674757980719, total=  52.4s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_540 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_204 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_541 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_542 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 17s 35ms/step - loss: 0.7000 - acc: 0.5020\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6379 - acc: 0.5915\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5350 - acc: 0.6728\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4532 - acc: 0.7520\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3829 - acc: 0.8150\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3335 - acc: 0.8557\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2942 - acc: 0.8821\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2647 - acc: 0.8862\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2778 - acc: 0.8923\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2614 - acc: 0.9146\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2432 - acc: 0.9228\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2433 - acc: 0.9146\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2207 - acc: 0.9248\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2141 - acc: 0.9289\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2131 - acc: 0.9248\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1907 - acc: 0.9472\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2035 - acc: 0.9289\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2140 - acc: 0.9167\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2174 - acc: 0.9228\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1848 - acc: 0.9411\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2212 - acc: 0.9085\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1840 - acc: 0.9309\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2038 - acc: 0.9207\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1718 - acc: 0.9411\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1861 - acc: 0.9268\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1842 - acc: 0.9289\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1954 - acc: 0.9228\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1896 - acc: 0.9268\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1621 - acc: 0.9431\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1784 - acc: 0.9329\n",
      "123/123 [==============================] - 6s 53ms/step\n",
      "492/492 [==============================] - 0s 705us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7479674743443001, total=  52.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=4, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_543 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_205 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_544 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_545 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 17s 34ms/step - loss: 0.7001 - acc: 0.5122\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6598 - acc: 0.6463\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5774 - acc: 0.7093\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4820 - acc: 0.7642\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3780 - acc: 0.7967\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3231 - acc: 0.8110\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2691 - acc: 0.8496\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2552 - acc: 0.8659\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2420 - acc: 0.8557\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2188 - acc: 0.8557\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2196 - acc: 0.8618\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2292 - acc: 0.8516\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2150 - acc: 0.8496\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2056 - acc: 0.8577\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2077 - acc: 0.8598\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2285 - acc: 0.8638\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1932 - acc: 0.8760\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1727 - acc: 0.8943\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1875 - acc: 0.8923\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1686 - acc: 0.8841\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1964 - acc: 0.8638\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1802 - acc: 0.8882\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1944 - acc: 0.8841\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1741 - acc: 0.8780\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2197 - acc: 0.8557\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2015 - acc: 0.8821\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1928 - acc: 0.8760\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1888 - acc: 0.8841\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1726 - acc: 0.8882\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 18s 36ms/step - loss: 0.7060 - acc: 0.5549\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6252 - acc: 0.6585\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5648 - acc: 0.7154\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4799 - acc: 0.8252\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3970 - acc: 0.8699\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3536 - acc: 0.8780\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3145 - acc: 0.9126\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2839 - acc: 0.9390\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2819 - acc: 0.9593\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2351 - acc: 0.9736\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2280 - acc: 0.9858\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2095 - acc: 0.9858\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2139 - acc: 0.9898\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2104 - acc: 0.9797\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1941 - acc: 0.9919\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1890 - acc: 0.9919\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2000 - acc: 0.9898\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1663 - acc: 0.9980\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1753 - acc: 0.9959\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1636 - acc: 0.9898\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1540 - acc: 0.9939\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1639 - acc: 0.9898\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1597 - acc: 0.9959\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1543 - acc: 0.9939\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1506 - acc: 0.9919\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1573 - acc: 0.9898\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1571 - acc: 0.9919\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1467 - acc: 0.9919\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1427 - acc: 0.9878\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1292 - acc: 0.9980\n",
      "123/123 [==============================] - 7s 57ms/step\n",
      "492/492 [==============================] - 0s 859us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.707317078985819, total=  54.1s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_563 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_212 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_564 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 18s 36ms/step - loss: 0.6983 - acc: 0.5691\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5442 - acc: 0.7724\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4343 - acc: 0.8333\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3385 - acc: 0.8720\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2618 - acc: 0.9309\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2457 - acc: 0.8984\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1974 - acc: 0.9553\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1748 - acc: 0.9593\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1595 - acc: 0.9533\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1540 - acc: 0.9472\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1249 - acc: 0.9593\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1241 - acc: 0.9654\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1336 - acc: 0.9451\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1306 - acc: 0.9472\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1135 - acc: 0.9533\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0995 - acc: 0.9593\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1046 - acc: 0.9533\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0960 - acc: 0.9634\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1123 - acc: 0.9472\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0958 - acc: 0.9533\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0963 - acc: 0.9573\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0966 - acc: 0.9593\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0921 - acc: 0.9593\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1052 - acc: 0.9512\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0949 - acc: 0.9512\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0768 - acc: 0.9695\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0777 - acc: 0.9715\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0874 - acc: 0.9553\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0868 - acc: 0.9593\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0836 - acc: 0.9654\n",
      "123/123 [==============================] - 7s 55ms/step\n",
      "492/492 [==============================] - 0s 634us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6666666710279822, total=  54.7s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_565 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_213 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_566 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 18s 36ms/step - loss: 0.7018 - acc: 0.5711\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5455 - acc: 0.7581\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4253 - acc: 0.8313\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3274 - acc: 0.8984\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2821 - acc: 0.9126\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2347 - acc: 0.9289\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1979 - acc: 0.9431\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1862 - acc: 0.9390\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1757 - acc: 0.9533\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1834 - acc: 0.9268\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1547 - acc: 0.9553\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1370 - acc: 0.9593\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1366 - acc: 0.9573\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1299 - acc: 0.9614\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1284 - acc: 0.9614\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1108 - acc: 0.9695\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1159 - acc: 0.9736\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4380 - acc: 0.8598\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4166 - acc: 0.9106\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4063 - acc: 0.8841\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3976 - acc: 0.8862\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3920 - acc: 0.9024\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3793 - acc: 0.9167\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3703 - acc: 0.8984\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3664 - acc: 0.9167\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3426 - acc: 0.9207\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3535 - acc: 0.9228\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3097 - acc: 0.9451\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3021 - acc: 0.9411\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3201 - acc: 0.9411\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2847 - acc: 0.9553\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2898 - acc: 0.9533\n",
      "123/123 [==============================] - 8s 61ms/step\n",
      "492/492 [==============================] - 0s 625us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7560975604910192, total=  43.8s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_573 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_217 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_574 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 17s 35ms/step - loss: 0.7089 - acc: 0.5061\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6803 - acc: 0.6341\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6483 - acc: 0.6972\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6092 - acc: 0.7439\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5702 - acc: 0.7927\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5358 - acc: 0.8028\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5148 - acc: 0.8028\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4745 - acc: 0.8435\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4581 - acc: 0.8577\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4399 - acc: 0.8821\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4318 - acc: 0.8415\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3969 - acc: 0.9045\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3855 - acc: 0.8821\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3701 - acc: 0.9085\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3577 - acc: 0.9146\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3778 - acc: 0.8882\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3428 - acc: 0.9004\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3240 - acc: 0.9350\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3157 - acc: 0.9431\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3188 - acc: 0.9411\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2951 - acc: 0.9431\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2853 - acc: 0.9553\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2782 - acc: 0.9472\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2653 - acc: 0.9675\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2731 - acc: 0.9492\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2936 - acc: 0.9451\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2536 - acc: 0.9695\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2521 - acc: 0.9573\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2639 - acc: 0.9492\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2521 - acc: 0.9573\n",
      "123/123 [==============================] - 8s 61ms/step\n",
      "492/492 [==============================] - 0s 824us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.6910569100845151, total=  44.6s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_575 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_218 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_576 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 18s 37ms/step - loss: 0.7085 - acc: 0.5264\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6800 - acc: 0.6382\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6489 - acc: 0.6931\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6082 - acc: 0.7419\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5780 - acc: 0.7805\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5509 - acc: 0.7988\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5296 - acc: 0.8191\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4981 - acc: 0.8496\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4630 - acc: 0.8679\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4442 - acc: 0.8659\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4204 - acc: 0.8943\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4188 - acc: 0.8720\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3930 - acc: 0.9045\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3706 - acc: 0.9004\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3722 - acc: 0.8984\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3617 - acc: 0.8923\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3600 - acc: 0.9045\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3470 - acc: 0.9106\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3237 - acc: 0.9289\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3075 - acc: 0.9350\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3145 - acc: 0.9187\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2966 - acc: 0.9329\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2869 - acc: 0.9268\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2929 - acc: 0.9309\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2673 - acc: 0.9431\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2768 - acc: 0.9370\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2617 - acc: 0.9451\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2735 - acc: 0.9309\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2627 - acc: 0.9492\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2485 - acc: 0.9553\n",
      "123/123 [==============================] - 9s 69ms/step\n",
      "492/492 [==============================] - 0s 760us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.7804877995475521, total=  47.6s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_577 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_219 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_578 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 18s 37ms/step - loss: 0.7087 - acc: 0.4980\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6752 - acc: 0.6402\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6406 - acc: 0.6667\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5896 - acc: 0.7500\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5688 - acc: 0.7602\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5237 - acc: 0.8049\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4946 - acc: 0.8069\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4700 - acc: 0.8293\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4563 - acc: 0.8333\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4356 - acc: 0.8455\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4049 - acc: 0.8720\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3942 - acc: 0.8801\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3866 - acc: 0.8862\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3740 - acc: 0.8699\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3692 - acc: 0.9004\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3451 - acc: 0.9065\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3443 - acc: 0.8902\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3499 - acc: 0.9126\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3075 - acc: 0.9268\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3308 - acc: 0.9207\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3083 - acc: 0.9289\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3106 - acc: 0.9146\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2985 - acc: 0.9248\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2886 - acc: 0.9207\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2695 - acc: 0.9472\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2851 - acc: 0.9228\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2700 - acc: 0.9451\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2590 - acc: 0.9573\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2525 - acc: 0.9512\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2514 - acc: 0.9411\n",
      "123/123 [==============================] - 8s 63ms/step\n",
      "492/492 [==============================] - 0s 780us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.772357718246739, total=  45.8s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_579 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_220 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_580 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 17s 34ms/step - loss: 0.7099 - acc: 0.5000\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6762 - acc: 0.6280\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6473 - acc: 0.6728\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6251 - acc: 0.7134\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5917 - acc: 0.7744\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5697 - acc: 0.7947\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5468 - acc: 0.8333\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5269 - acc: 0.8780\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5027 - acc: 0.8740\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4785 - acc: 0.9106\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4666 - acc: 0.9167\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4580 - acc: 0.9126\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4211 - acc: 0.9329\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4183 - acc: 0.9309\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3984 - acc: 0.9370\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3941 - acc: 0.9146\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3822 - acc: 0.9451\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3739 - acc: 0.9431\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3619 - acc: 0.9411\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3672 - acc: 0.9268\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3362 - acc: 0.9431\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3412 - acc: 0.9431\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 20s 40ms/step - loss: 0.7010 - acc: 0.5610\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6054 - acc: 0.6972\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4988 - acc: 0.7866\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3461 - acc: 0.9024\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2999 - acc: 0.8862\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2223 - acc: 0.9268\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1921 - acc: 0.9411\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1726 - acc: 0.9411\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1669 - acc: 0.9329\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1307 - acc: 0.9492\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1199 - acc: 0.9492\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1010 - acc: 0.9573\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0987 - acc: 0.9593\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1015 - acc: 0.9512\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0900 - acc: 0.9675\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1001 - acc: 0.9411\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0881 - acc: 0.9512\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0923 - acc: 0.9675\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0858 - acc: 0.9553\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0829 - acc: 0.9736\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0885 - acc: 0.9370\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0924 - acc: 0.9451\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0855 - acc: 0.9472\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0670 - acc: 0.9593\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0773 - acc: 0.9533\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0812 - acc: 0.9451\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0663 - acc: 0.9654\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0700 - acc: 0.9715\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0764 - acc: 0.9614\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0857 - acc: 0.9411\n",
      "123/123 [==============================] - 7s 56ms/step\n",
      "492/492 [==============================] - 0s 688us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.7723577264847794, total=  57.0s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_593 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_225 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_594 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_595 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 18s 37ms/step - loss: 0.6953 - acc: 0.5894\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5898 - acc: 0.7073\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4586 - acc: 0.7988\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3485 - acc: 0.8780\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2861 - acc: 0.8943\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2433 - acc: 0.9207\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1777 - acc: 0.9634\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1865 - acc: 0.9370\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1802 - acc: 0.9533\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1576 - acc: 0.9756\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1825 - acc: 0.9573\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1216 - acc: 0.9776\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1273 - acc: 0.9776\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1295 - acc: 0.9634\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1360 - acc: 0.9715\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1115 - acc: 0.9858\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1252 - acc: 0.9837\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1095 - acc: 0.9817\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0974 - acc: 0.9858\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1035 - acc: 0.9776\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1056 - acc: 0.9837\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0914 - acc: 0.9878\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0920 - acc: 0.9837\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0923 - acc: 0.9919\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0844 - acc: 0.9898\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0877 - acc: 0.9858\n",
      "Epoch 27/30\n",
      "123/123 [==============================] - 10s 80ms/step\n",
      "492/492 [==============================] - 0s 669us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7317073131964459, total= 1.0min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_614 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_232 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_615 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_616 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 20s 41ms/step - loss: 0.7007 - acc: 0.5671\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6142 - acc: 0.7297\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4744 - acc: 0.8455\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3333 - acc: 0.9126\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2583 - acc: 0.9350\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2009 - acc: 0.9512\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1982 - acc: 0.9472\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1507 - acc: 0.9573\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1273 - acc: 0.9675\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1082 - acc: 0.9797\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1089 - acc: 0.9736\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1100 - acc: 0.9756\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0961 - acc: 0.9756\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0885 - acc: 0.9878\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0796 - acc: 0.9797\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0801 - acc: 0.9817\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0951 - acc: 0.9756\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0839 - acc: 0.9817\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0847 - acc: 0.9756\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0869 - acc: 0.9736\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0856 - acc: 0.9776\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0732 - acc: 0.9898\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0826 - acc: 0.9797\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0914 - acc: 0.9715\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0610 - acc: 0.9878\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0776 - acc: 0.9776\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0721 - acc: 0.9817\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0722 - acc: 0.9797\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0761 - acc: 0.9776\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0852 - acc: 0.9776\n",
      "123/123 [==============================] - 8s 63ms/step\n",
      "492/492 [==============================] - 0s 743us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.6341463375866898, total=  58.5s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_617 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_233 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_618 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_619 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 18s 38ms/step - loss: 0.7046 - acc: 0.5285\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5788 - acc: 0.7297\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4445 - acc: 0.8171\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3383 - acc: 0.8659\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2471 - acc: 0.9228\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1989 - acc: 0.9329\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1802 - acc: 0.9472\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1606 - acc: 0.9451\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1436 - acc: 0.9492\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1610 - acc: 0.9512\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1119 - acc: 0.9776\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1071 - acc: 0.9715\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1078 - acc: 0.9695\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0959 - acc: 0.9654\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0886 - acc: 0.9837\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0970 - acc: 0.9695\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0914 - acc: 0.9817\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0773 - acc: 0.9776\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0761 - acc: 0.9837\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0676 - acc: 0.9898\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0814 - acc: 0.9776\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0876 - acc: 0.9756\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0906 - acc: 0.9654\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0652 - acc: 0.9898\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0716 - acc: 0.9817\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0621 - acc: 0.9817\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0683 - acc: 0.9817\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0821 - acc: 0.9695\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0715 - acc: 0.9797\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0673 - acc: 0.9797\n",
      "123/123 [==============================] - 8s 61ms/step\n",
      "492/492 [==============================] - 0s 769us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7398374046736617, total=  56.2s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_620 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_234 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_621 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_622 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 20s 40ms/step - loss: 0.6834 - acc: 0.5691\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4936 - acc: 0.7642\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3760 - acc: 0.8354\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2947 - acc: 0.8923\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2574 - acc: 0.8943\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1958 - acc: 0.9329\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1547 - acc: 0.9512\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1550 - acc: 0.9390\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1230 - acc: 0.9573\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1238 - acc: 0.9553\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1189 - acc: 0.9695\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0984 - acc: 0.9695\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0942 - acc: 0.9756\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1032 - acc: 0.9736\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.0923 - acc: 0.9715\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1147 - acc: 0.9593\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4015 - acc: 0.8882\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3927 - acc: 0.8862\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3655 - acc: 0.8841\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3512 - acc: 0.9126\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3704 - acc: 0.8659\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3283 - acc: 0.8984\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3226 - acc: 0.9106\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2967 - acc: 0.9329\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2843 - acc: 0.9146\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3220 - acc: 0.8862\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2838 - acc: 0.9268\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2453 - acc: 0.9431\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2730 - acc: 0.9228\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2512 - acc: 0.9370\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2312 - acc: 0.9451\n",
      "123/123 [==============================] - 8s 62ms/step\n",
      "492/492 [==============================] - 0s 674us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.6585365897271691, total=  45.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_632 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_238 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_633 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_634 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 19s 38ms/step - loss: 0.7110 - acc: 0.4837\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6908 - acc: 0.5711\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6772 - acc: 0.6179\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6509 - acc: 0.6809\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6292 - acc: 0.7154\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6138 - acc: 0.7561\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5841 - acc: 0.8089\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5613 - acc: 0.8455\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5429 - acc: 0.8293\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5150 - acc: 0.8760\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4865 - acc: 0.8801\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4695 - acc: 0.8984\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4514 - acc: 0.9065\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4509 - acc: 0.8943\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4073 - acc: 0.9207\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4127 - acc: 0.9045\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4015 - acc: 0.9370\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3669 - acc: 0.9553\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3629 - acc: 0.9492\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3538 - acc: 0.9370\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3469 - acc: 0.9451\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3270 - acc: 0.9492\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3231 - acc: 0.9654\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3083 - acc: 0.9593\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3138 - acc: 0.9512\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3051 - acc: 0.9492\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2718 - acc: 0.9512\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2583 - acc: 0.9512\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2622 - acc: 0.9654\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2410 - acc: 0.9634\n",
      "123/123 [==============================] - 8s 63ms/step\n",
      "492/492 [==============================] - 0s 712us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7560975570988849, total=  46.3s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_635 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_239 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_636 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_637 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 19s 38ms/step - loss: 0.7089 - acc: 0.5163\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.7008 - acc: 0.5549\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6920 - acc: 0.6098\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6732 - acc: 0.6585\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6651 - acc: 0.6809\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6388 - acc: 0.7419\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6260 - acc: 0.7317\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6106 - acc: 0.7378\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5847 - acc: 0.7927\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5668 - acc: 0.8110\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5631 - acc: 0.8232\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5385 - acc: 0.8313\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5303 - acc: 0.8171\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4928 - acc: 0.8577\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5096 - acc: 0.8272\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4923 - acc: 0.8455\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4455 - acc: 0.8882\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4304 - acc: 0.8963\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4310 - acc: 0.8801\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4146 - acc: 0.8862\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3896 - acc: 0.9004\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3818 - acc: 0.8943\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3648 - acc: 0.9126\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3366 - acc: 0.9085\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3337 - acc: 0.9228\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3269 - acc: 0.9146\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2993 - acc: 0.9350\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.3139 - acc: 0.9085\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2753 - acc: 0.9350\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.2743 - acc: 0.9207\n",
      "123/123 [==============================] - 8s 68ms/step\n",
      "492/492 [==============================] - 0s 663us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7317073199807144, total=  47.5s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=8, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_638 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_240 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_639 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_640 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 26s 52ms/step - loss: 0.7117 - acc: 0.4715\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7013 - acc: 0.5772\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6946 - acc: 0.6260\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6849 - acc: 0.6626\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6770 - acc: 0.6687\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6566 - acc: 0.7764\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6474 - acc: 0.7154\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6214 - acc: 0.7907\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.6020 - acc: 0.8130\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5848 - acc: 0.8110\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5550 - acc: 0.8130\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5512 - acc: 0.8252\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.5275 - acc: 0.8354\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 1ms/step - loss: 0.4984 - acc: 0.8333\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4844 - acc: 0.8374\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4567 - acc: 0.8516\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4330 - acc: 0.8638\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 21s 42ms/step - loss: 0.7166 - acc: 0.5488\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5578 - acc: 0.7866\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.3917 - acc: 0.8902\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2931 - acc: 0.9248\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2379 - acc: 0.9431\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1903 - acc: 0.9654\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1518 - acc: 0.9898\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1326 - acc: 0.9878\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1141 - acc: 0.9837\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1065 - acc: 0.9919\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0966 - acc: 0.9878\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0931 - acc: 0.9837\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0807 - acc: 0.9919\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0735 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0792 - acc: 0.9858\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0702 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0641 - acc: 0.9959\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0671 - acc: 0.9939\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0601 - acc: 0.9898\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0582 - acc: 0.9939\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0600 - acc: 0.9919\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0544 - acc: 0.9939\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0583 - acc: 0.9980\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0580 - acc: 0.9939\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0602 - acc: 0.9939\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0555 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0538 - acc: 0.9939\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0489 - acc: 0.9939\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0449 - acc: 0.9980\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0507 - acc: 0.9939\n",
      "123/123 [==============================] - 8s 69ms/step\n",
      "492/492 [==============================] - 0s 837us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.7642276451839665, total= 1.3min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_649 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_245 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_650 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,290,913\n",
      "Trainable params: 1,290,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 22s 44ms/step - loss: 0.6999 - acc: 0.6220\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4929 - acc: 0.8354\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3352 - acc: 0.9106\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2381 - acc: 0.9614\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1796 - acc: 0.9736\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1515 - acc: 0.9776\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1202 - acc: 0.9878\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1039 - acc: 0.9959\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1004 - acc: 0.9878\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0887 - acc: 0.9959\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0739 - acc: 0.9980\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0698 - acc: 0.9959\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0668 - acc: 0.9980\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0648 - acc: 0.9959\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0612 - acc: 0.9980\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0640 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0507 - acc: 0.9980\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0509 - acc: 0.9959\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0474 - acc: 0.9980\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0485 - acc: 0.9959\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0503 - acc: 0.9939\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0471 - acc: 0.9959\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0413 - acc: 0.9939\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0432 - acc: 0.9959\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0443 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0417 - acc: 0.9959\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0378 - acc: 0.9939\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0403 - acc: 0.9980\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0361 - acc: 0.9980\n",
      "123/123 [==============================] - 8s 64ms/step\n",
      "492/492 [==============================] - 0s 885us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=Adadelta, shuffle=True, score=0.6829268355679706, total= 1.3min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_651 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_246 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_652 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,290,913\n",
      "Trainable params: 1,290,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 20s 41ms/step - loss: 0.7257 - acc: 0.5183\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6908 - acc: 0.6463\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6560 - acc: 0.7500\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6124 - acc: 0.7967\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5729 - acc: 0.8333\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5333 - acc: 0.8679\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4997 - acc: 0.8821\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4797 - acc: 0.8740\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4576 - acc: 0.9024\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4276 - acc: 0.9207\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3962 - acc: 0.9126\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3817 - acc: 0.9146\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3675 - acc: 0.9370\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3515 - acc: 0.9289\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3309 - acc: 0.9512\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3201 - acc: 0.9614\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3177 - acc: 0.9492\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 21s 43ms/step - loss: 0.7265 - acc: 0.5285\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6867 - acc: 0.6748\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6503 - acc: 0.7419\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6050 - acc: 0.8069\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5702 - acc: 0.8435\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5282 - acc: 0.8760\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4962 - acc: 0.8780\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4679 - acc: 0.8821\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4498 - acc: 0.8943\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4225 - acc: 0.9126\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3927 - acc: 0.9268\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3932 - acc: 0.9207\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3665 - acc: 0.9350\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3617 - acc: 0.9350\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3251 - acc: 0.9492\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3253 - acc: 0.9451\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3047 - acc: 0.9654\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2941 - acc: 0.9553\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2968 - acc: 0.9512\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2757 - acc: 0.9695\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2661 - acc: 0.9756\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2648 - acc: 0.9553\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2487 - acc: 0.9736\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2570 - acc: 0.9715\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2485 - acc: 0.9736\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2316 - acc: 0.9837\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2236 - acc: 0.9858\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2266 - acc: 0.9837\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2092 - acc: 0.9776\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2182 - acc: 0.9837\n",
      "123/123 [==============================] - 8s 65ms/step\n",
      "492/492 [==============================] - 0s 794us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[0], optim_methods=SGD, shuffle=True, score=0.6910569086307432, total=  56.0s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_661 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_251 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_662 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_663 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 22s 45ms/step - loss: 0.7084 - acc: 0.5935\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 4ms/step - loss: 0.5748 - acc: 0.7947\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3976 - acc: 0.8780\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2729 - acc: 0.9268\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1854 - acc: 0.9715\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1281 - acc: 0.9817\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0960 - acc: 0.9919\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0946 - acc: 0.9919\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0732 - acc: 0.9959\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0709 - acc: 0.9919\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0704 - acc: 0.9919\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0651 - acc: 0.9858\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0627 - acc: 0.9939\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0535 - acc: 0.9898\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0554 - acc: 0.9939\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0534 - acc: 0.9959\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0591 - acc: 0.9837\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0439 - acc: 0.9959\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0448 - acc: 0.9980\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0500 - acc: 0.9919\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0465 - acc: 0.9858\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0461 - acc: 0.9878\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0391 - acc: 0.9919\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0410 - acc: 0.9878\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0457 - acc: 0.9919\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0365 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0391 - acc: 0.9878\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0343 - acc: 0.9939\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0298 - acc: 0.9980\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0320 - acc: 0.9980\n",
      "123/123 [==============================] - 8s 69ms/step\n",
      "492/492 [==============================] - 0s 1ms/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.7073170726861411, total= 1.3min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_664 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_252 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_665 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_666 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 22s 45ms/step - loss: 0.7124 - acc: 0.5488\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.6132 - acc: 0.7846\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4536 - acc: 0.8537\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3200 - acc: 0.9126\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2180 - acc: 0.9512\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1699 - acc: 0.9654\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1345 - acc: 0.9776\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1067 - acc: 0.9878\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1046 - acc: 0.9776\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0919 - acc: 0.9817\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0836 - acc: 0.9776\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0795 - acc: 0.9898\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0596 - acc: 0.9939\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0750 - acc: 0.9898\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0620 - acc: 0.9959\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0538 - acc: 0.9939\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0563 - acc: 0.9878\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0655 - acc: 0.9858\n",
      "Epoch 19/30\n",
      "123/123 [==============================] - 9s 70ms/step\n",
      "492/492 [==============================] - 0s 860us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=Adadelta, shuffle=True, score=0.642276417433731, total= 1.3min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_676 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_256 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_677 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_678 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 21s 42ms/step - loss: 0.7256 - acc: 0.5000\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7035 - acc: 0.6138\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6847 - acc: 0.7033\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6555 - acc: 0.7805\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6296 - acc: 0.7947\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5980 - acc: 0.8191\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5841 - acc: 0.8272\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5522 - acc: 0.8577\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5132 - acc: 0.9024\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4948 - acc: 0.8801\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4716 - acc: 0.8984\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4544 - acc: 0.8862\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4216 - acc: 0.9126\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4043 - acc: 0.9289\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3764 - acc: 0.9370\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3619 - acc: 0.9451\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3376 - acc: 0.9451\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3330 - acc: 0.9451\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3151 - acc: 0.9533\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2947 - acc: 0.9593\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2909 - acc: 0.9593\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2650 - acc: 0.9675\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2460 - acc: 0.9634\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2558 - acc: 0.9614\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2533 - acc: 0.9654\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2190 - acc: 0.9776\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2371 - acc: 0.9675\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2066 - acc: 0.9858\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1988 - acc: 0.9878\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2075 - acc: 0.9736\n",
      "123/123 [==============================] - 9s 74ms/step\n",
      "492/492 [==============================] - 0s 737us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.6829268336296082, total=  57.3s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_679 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_257 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_680 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_681 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 21s 43ms/step - loss: 0.7252 - acc: 0.5061\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7252 - acc: 0.4675\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7250 - acc: 0.4898\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7251 - acc: 0.4858\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7248 - acc: 0.5508\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7246 - acc: 0.5305\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7247 - acc: 0.5467\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7246 - acc: 0.5244\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7244 - acc: 0.5407\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7241 - acc: 0.5488\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7237 - acc: 0.5447\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7236 - acc: 0.5630\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7237 - acc: 0.5386\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7232 - acc: 0.5630\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7232 - acc: 0.5671\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7228 - acc: 0.5894\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7226 - acc: 0.5671\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7221 - acc: 0.5752\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7211 - acc: 0.5813\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7208 - acc: 0.5833\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7202 - acc: 0.6138\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7189 - acc: 0.6016\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7192 - acc: 0.6077\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7182 - acc: 0.6260\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7164 - acc: 0.6484\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7152 - acc: 0.6463\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7130 - acc: 0.6463\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7109 - acc: 0.6951\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7098 - acc: 0.6972\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7062 - acc: 0.7154\n",
      "123/123 [==============================] - 8s 69ms/step\n",
      "492/492 [==============================] - 0s 871us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True, score=0.5691056934798636, total=  57.4s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[1], optim_methods=SGD, shuffle=True \n",
      "123/123 [==============================] - 9s 73ms/step\n",
      "492/492 [==============================] - 0s 893us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.6422764188875028, total= 1.3min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_697 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_263 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_698 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_699 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 23s 47ms/step - loss: 0.7053 - acc: 0.5772\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.4889 - acc: 0.8191\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3210 - acc: 0.9024\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2232 - acc: 0.9553\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1604 - acc: 0.9675\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1300 - acc: 0.9776\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1153 - acc: 0.9837\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0912 - acc: 0.9898\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0674 - acc: 0.9959\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0821 - acc: 0.9878\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0624 - acc: 0.9959\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0638 - acc: 0.9919\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0561 - acc: 0.9959\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0526 - acc: 0.9898\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0487 - acc: 0.9980\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0469 - acc: 0.9919\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0460 - acc: 0.9939\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0464 - acc: 0.9898\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0450 - acc: 0.9919\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0400 - acc: 0.9980\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0383 - acc: 0.9959\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0417 - acc: 0.9939\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0384 - acc: 0.9919\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0363 - acc: 0.9959\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0387 - acc: 0.9939\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0368 - acc: 0.9939\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0479 - acc: 0.9919\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0319 - acc: 0.9959\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0389 - acc: 0.9959\n",
      "123/123 [==============================] - 8s 68ms/step\n",
      "492/492 [==============================] - 0s 762us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7560975653369252, total= 1.3min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_700 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_264 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_701 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_702 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 22s 46ms/step - loss: 0.7020 - acc: 0.5976\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5344 - acc: 0.7825\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3408 - acc: 0.9106\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2398 - acc: 0.9431\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1694 - acc: 0.9634\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1208 - acc: 0.9837\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1077 - acc: 0.9858\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0986 - acc: 0.9878\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0812 - acc: 0.9919\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0722 - acc: 0.9898\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0676 - acc: 0.9878\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0588 - acc: 0.9919\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0687 - acc: 0.9858\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0522 - acc: 0.9939\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0495 - acc: 0.9980\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0567 - acc: 0.9898\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0491 - acc: 0.9959\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0505 - acc: 0.9980\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0448 - acc: 0.9939\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0430 - acc: 0.9959\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0403 - acc: 0.9959\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0424 - acc: 0.9898\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0339 - acc: 0.9980\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0405 - acc: 0.9939\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0401 - acc: 0.9919\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0311 - acc: 0.9980\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0350 - acc: 0.9980\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0388 - acc: 0.9959\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0338 - acc: 0.9939\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0408 - acc: 0.9919\n",
      "123/123 [==============================] - 9s 72ms/step\n",
      "492/492 [==============================] - 0s 839us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True, score=0.7804878029396863, total= 1.3min\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=Adadelta, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_703 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_265 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_704 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_705 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 22s 44ms/step - loss: 0.7151 - acc: 0.5610\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.5506 - acc: 0.8130\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.3515 - acc: 0.8984\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.2438 - acc: 0.9370\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1729 - acc: 0.9675\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.1372 - acc: 0.9817\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0990 - acc: 0.9939\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0852 - acc: 0.9878\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0825 - acc: 0.9858\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0639 - acc: 0.9959\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0622 - acc: 0.9919\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 2s 3ms/step - loss: 0.0545 - acc: 0.9959\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 22s 45ms/step - loss: 0.7240 - acc: 0.5285\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6923 - acc: 0.6809\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6597 - acc: 0.7520\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6211 - acc: 0.8028\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5900 - acc: 0.8333\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5375 - acc: 0.8659\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4982 - acc: 0.8882\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4682 - acc: 0.8984\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4397 - acc: 0.8984\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4182 - acc: 0.9085\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3802 - acc: 0.9329\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3482 - acc: 0.9390\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3347 - acc: 0.9411\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3187 - acc: 0.9472\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2907 - acc: 0.9614\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2698 - acc: 0.9573\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2511 - acc: 0.9817\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2614 - acc: 0.9472\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2409 - acc: 0.9715\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2276 - acc: 0.9634\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2130 - acc: 0.9654\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2180 - acc: 0.9756\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2062 - acc: 0.9736\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1822 - acc: 0.9837\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1737 - acc: 0.9776\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1792 - acc: 0.9817\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1553 - acc: 0.9898\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1551 - acc: 0.9878\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1665 - acc: 0.9736\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.1477 - acc: 0.9898\n",
      "123/123 [==============================] - 9s 70ms/step\n",
      "492/492 [==============================] - 0s 774us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7642276403380603, total=  58.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_715 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_269 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_716 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_717 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 22s 45ms/step - loss: 0.7254 - acc: 0.4817\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7197 - acc: 0.5894\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7108 - acc: 0.6402\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7037 - acc: 0.6931\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6921 - acc: 0.7317\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6833 - acc: 0.7317\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6743 - acc: 0.7398\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6572 - acc: 0.7866\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6412 - acc: 0.8191\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6351 - acc: 0.8333\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6119 - acc: 0.8293\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5915 - acc: 0.8415\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5721 - acc: 0.8720\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5636 - acc: 0.8780\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5368 - acc: 0.8902\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5114 - acc: 0.8923\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4900 - acc: 0.9167\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4572 - acc: 0.9187\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4442 - acc: 0.9207\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4135 - acc: 0.9268\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3881 - acc: 0.9248\n",
      "Epoch 22/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3770 - acc: 0.9370\n",
      "Epoch 23/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3608 - acc: 0.9350\n",
      "Epoch 24/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3458 - acc: 0.9472\n",
      "Epoch 25/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3291 - acc: 0.9431\n",
      "Epoch 26/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.3123 - acc: 0.9573\n",
      "Epoch 27/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2955 - acc: 0.9614\n",
      "Epoch 28/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2711 - acc: 0.9695\n",
      "Epoch 29/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2704 - acc: 0.9593\n",
      "Epoch 30/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.2622 - acc: 0.9654\n",
      "123/123 [==============================] - 9s 71ms/step\n",
      "492/492 [==============================] - 0s 767us/step\n",
      "[CV]  activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True, score=0.7479674825823404, total=  57.9s\n",
      "[CV] activation_function=relu, batch_norm=no, batch_size=32, dropout_rates=0.5, epochs=30, input_dropout_rates=0.5, input_num_hidden_units=16, l2_rate=0.001, num_hidden_layers=[2], optim_methods=SGD, shuffle=True \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_718 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_270 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_719 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_720 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "492/492 [==============================] - 22s 45ms/step - loss: 0.7258 - acc: 0.5041\n",
      "Epoch 2/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7208 - acc: 0.5488\n",
      "Epoch 3/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7143 - acc: 0.6321\n",
      "Epoch 4/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7062 - acc: 0.7175\n",
      "Epoch 5/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.7018 - acc: 0.7236\n",
      "Epoch 6/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6925 - acc: 0.7378\n",
      "Epoch 7/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6864 - acc: 0.7561\n",
      "Epoch 8/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6715 - acc: 0.7988\n",
      "Epoch 9/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6656 - acc: 0.7988\n",
      "Epoch 10/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6475 - acc: 0.8354\n",
      "Epoch 11/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6362 - acc: 0.8150\n",
      "Epoch 12/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6247 - acc: 0.8455\n",
      "Epoch 13/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.6125 - acc: 0.8618\n",
      "Epoch 14/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5888 - acc: 0.8659\n",
      "Epoch 15/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5757 - acc: 0.8862\n",
      "Epoch 16/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5517 - acc: 0.8943\n",
      "Epoch 17/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5359 - acc: 0.8943\n",
      "Epoch 18/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.5126 - acc: 0.9004\n",
      "Epoch 19/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4921 - acc: 0.9085\n",
      "Epoch 20/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4857 - acc: 0.9024\n",
      "Epoch 21/30\n",
      "492/492 [==============================] - 1s 2ms/step - loss: 0.4644 - acc: 0.9207\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 25s 40ms/step - loss: 0.6828 - acc: 0.5463\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.5801 - acc: 0.7138\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.4398 - acc: 0.7951\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.3689 - acc: 0.8228\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.3258 - acc: 0.8667\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 3s 4ms/step - loss: 0.2957 - acc: 0.8813\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.2515 - acc: 0.9057\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 3s 4ms/step - loss: 0.2482 - acc: 0.8829\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.2503 - acc: 0.8943\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 3s 4ms/step - loss: 0.2299 - acc: 0.9171\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.2238 - acc: 0.9236\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 3s 4ms/step - loss: 0.2261 - acc: 0.9154\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.2241 - acc: 0.9138\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.1899 - acc: 0.9398\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.2255 - acc: 0.9057\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 3s 4ms/step - loss: 0.1925 - acc: 0.9301\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.1923 - acc: 0.9268\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.1677 - acc: 0.9480\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.2187 - acc: 0.9138\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 3s 5ms/step - loss: 0.2055 - acc: 0.9220\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 3s 4ms/step - loss: 0.2086 - acc: 0.9138\n",
      "Epoch 22/30\n",
      "576/615 [===========================>..] - ETA: 0s - loss: 0.1681 - acc: 0.9444_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_739 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_278 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_740 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 26s 42ms/step - loss: 0.6933 - acc: 0.5724\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.5623 - acc: 0.7057\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.4171 - acc: 0.8049\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.3446 - acc: 0.8374\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.3013 - acc: 0.8976\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.2583 - acc: 0.9220\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.2373 - acc: 0.9463\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.2089 - acc: 0.9593\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1960 - acc: 0.9707\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1895 - acc: 0.9789\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1706 - acc: 0.9854\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1650 - acc: 0.9886\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1616 - acc: 0.9870\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1378 - acc: 0.9902\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1491 - acc: 0.9886\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1344 - acc: 0.9951\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1392 - acc: 0.9902\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1369 - acc: 0.9870\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1242 - acc: 0.9919\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1325 - acc: 0.9854\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1183 - acc: 0.9870\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1125 - acc: 0.9919\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1153 - acc: 0.9805\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1059 - acc: 0.9805\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0915 - acc: 0.9740\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1148 - acc: 0.9724\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1003 - acc: 0.9805\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0865 - acc: 0.9821\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.1020 - acc: 0.9772\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0863 - acc: 0.9789\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0781 - acc: 0.9854\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0759 - acc: 0.9837\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0836 - acc: 0.9772\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0905 - acc: 0.9724\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0668 - acc: 0.9870\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0752 - acc: 0.9821\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0632 - acc: 0.9902\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0557 - acc: 0.9902\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0676 - acc: 0.9837\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0823 - acc: 0.9772\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0691 - acc: 0.9837\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 4s 7ms/step - loss: 0.0654 - acc: 0.9870\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0571 - acc: 0.9870\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_746 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_281 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_747 (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_748 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 645,459\n",
      "Trainable params: 645,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.7042 - acc: 0.5382\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.6634 - acc: 0.6732\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 35s 58ms/step - loss: 0.6996 - acc: 0.5902\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 8s 12ms/step - loss: 0.4851 - acc: 0.7984\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 8s 12ms/step - loss: 0.2744 - acc: 0.9220\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 7s 11ms/step - loss: 0.1733 - acc: 0.9577\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.1415 - acc: 0.9740\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.1129 - acc: 0.9854\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0893 - acc: 0.9854\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0860 - acc: 0.9886\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0765 - acc: 0.9870\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0585 - acc: 0.9935\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0609 - acc: 0.9919\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0592 - acc: 0.9870\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0378 - acc: 0.9919\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 8s 13ms/step - loss: 0.0390 - acc: 0.9870\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0326 - acc: 0.9967\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0352 - acc: 0.9935\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0385 - acc: 0.9886\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0358 - acc: 0.9935\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0283 - acc: 0.9935\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 8s 12ms/step - loss: 0.0282 - acc: 0.9951\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 10s 15ms/step - loss: 0.0299 - acc: 0.9935\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0265 - acc: 0.9967\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0230 - acc: 0.9984\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0230 - acc: 0.9967\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0352 - acc: 0.9902\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 8s 12ms/step - loss: 0.0249 - acc: 0.9967\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0210 - acc: 0.9984\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0265 - acc: 0.9935\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 7s 11ms/step - loss: 0.0279 - acc: 0.9967\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0261 - acc: 0.9984\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0282 - acc: 0.9935\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0237 - acc: 0.9951\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 7s 12ms/step - loss: 0.0278 - acc: 0.9919\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_768 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_289 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_769 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_770 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,290,933\n",
      "Trainable params: 1,290,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 29s 47ms/step - loss: 0.7184 - acc: 0.5236\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.6582 - acc: 0.7122\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.5672 - acc: 0.7821\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 3s 6ms/step - loss: 0.4738 - acc: 0.8520\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.3808 - acc: 0.8764\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.3063 - acc: 0.9203\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.2701 - acc: 0.9252\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.2303 - acc: 0.9480\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1860 - acc: 0.9610\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1673 - acc: 0.9610\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1623 - acc: 0.9740\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1333 - acc: 0.9740\n",
      "Epoch 13/30\n",
      "144/615 [======>.......................] - ETA: 2s - loss: 0.1488 - acc: 0.9722_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_775 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_292 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_776 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_777 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 25s 41ms/step - loss: 0.6917 - acc: 0.5480\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.5967 - acc: 0.7024\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.5337 - acc: 0.7480\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.4501 - acc: 0.8098\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.4127 - acc: 0.8049\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.3499 - acc: 0.8585\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.3161 - acc: 0.8683\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.3143 - acc: 0.8683\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2786 - acc: 0.8911\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2624 - acc: 0.8992\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2291 - acc: 0.9350\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2442 - acc: 0.9236\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2636 - acc: 0.9106\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2425 - acc: 0.9122\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2271 - acc: 0.9187\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2025 - acc: 0.9333\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1872 - acc: 0.9366\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1959 - acc: 0.9285\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2008 - acc: 0.9203\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2087 - acc: 0.9236\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1832 - acc: 0.9350\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1933 - acc: 0.9285\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1953 - acc: 0.9252\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1914 - acc: 0.9301\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1805 - acc: 0.9382\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1761 - acc: 0.9382\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1947 - acc: 0.9171\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1662 - acc: 0.9431\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1709 - acc: 0.9431\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2034 - acc: 0.9187\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_778 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_293 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_779 (Dense)            (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "dense_780 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 322,731\n",
      "Trainable params: 322,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.6996 - acc: 0.4959\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6808 - acc: 0.6098\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6569 - acc: 0.6537\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6309 - acc: 0.7041\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5939 - acc: 0.7431\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5593 - acc: 0.7789\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5159 - acc: 0.8098\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4841 - acc: 0.8244\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4598 - acc: 0.8390\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4078 - acc: 0.8602\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4004 - acc: 0.8650\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3727 - acc: 0.8878\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3531 - acc: 0.8943\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3306 - acc: 0.9073\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3194 - acc: 0.8943\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3164 - acc: 0.8943\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2857 - acc: 0.9106\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2892 - acc: 0.8992\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2792 - acc: 0.9171\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2589 - acc: 0.9350\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2489 - acc: 0.9252\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2403 - acc: 0.9285\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2518 - acc: 0.9301\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2359 - acc: 0.9285\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2385 - acc: 0.9154\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2195 - acc: 0.9398\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2318 - acc: 0.9236\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2236 - acc: 0.9350\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.1280 - acc: 0.9821\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1224 - acc: 0.9805\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.1273 - acc: 0.9854\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1242 - acc: 0.9805\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1151 - acc: 0.9870\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1145 - acc: 0.9854\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.1128 - acc: 0.9837\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.1058 - acc: 0.9870\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.1188 - acc: 0.9837\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1163 - acc: 0.9789\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.1013 - acc: 0.9854\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.0902 - acc: 0.9919\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1062 - acc: 0.9902\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.1019 - acc: 0.9902\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.0920 - acc: 0.9919\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_789 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_297 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_790 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 24s 39ms/step - loss: 0.7019 - acc: 0.5415\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6446 - acc: 0.6569\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5829 - acc: 0.7593\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5358 - acc: 0.7951\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4850 - acc: 0.8585\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4598 - acc: 0.8797\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4294 - acc: 0.9008\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3939 - acc: 0.9187\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3773 - acc: 0.9285\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3597 - acc: 0.9301\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3301 - acc: 0.9350\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3267 - acc: 0.9285\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3184 - acc: 0.9463\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2836 - acc: 0.9593\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2678 - acc: 0.9610\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2725 - acc: 0.9545\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2493 - acc: 0.9545\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2398 - acc: 0.9610\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2341 - acc: 0.9626\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2261 - acc: 0.9675\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2124 - acc: 0.9756\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 27s 43ms/step - loss: 0.7074 - acc: 0.5024\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6732 - acc: 0.6472\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6094 - acc: 0.6959\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5413 - acc: 0.7642\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5104 - acc: 0.7642\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4262 - acc: 0.8520\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.4092 - acc: 0.8602\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3726 - acc: 0.8959\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3532 - acc: 0.8976\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3266 - acc: 0.9203\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3165 - acc: 0.9187\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2958 - acc: 0.9301\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2592 - acc: 0.9463\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2662 - acc: 0.9382\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2431 - acc: 0.9431\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2344 - acc: 0.9463\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 2s 2ms/step - loss: 0.2107 - acc: 0.9577\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2112 - acc: 0.9626\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2061 - acc: 0.9480\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1750 - acc: 0.9724\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1800 - acc: 0.9675\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1815 - acc: 0.9593\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1704 - acc: 0.9691\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1746 - acc: 0.9593\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1735 - acc: 0.9577\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1489 - acc: 0.9626\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1456 - acc: 0.9691\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 2s 2ms/step - loss: 0.1390 - acc: 0.9772\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1599 - acc: 0.9577\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1394 - acc: 0.9675\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_803 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_302 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_804 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,290,913\n",
      "Trainable params: 1,290,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 28s 46ms/step - loss: 0.7018 - acc: 0.5967\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.5067 - acc: 0.7854\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.3346 - acc: 0.9138\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.2154 - acc: 0.9561\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1671 - acc: 0.9642\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.1299 - acc: 0.9805\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0497 - acc: 0.9967\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0458 - acc: 0.9886\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0400 - acc: 0.9919\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0416 - acc: 0.9902\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0348 - acc: 0.9967\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0403 - acc: 0.9902\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0317 - acc: 0.9967\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0401 - acc: 0.9919\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0304 - acc: 0.9951\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0373 - acc: 0.9951\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0329 - acc: 0.9967\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0334 - acc: 0.9935\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0338 - acc: 0.9967\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0301 - acc: 0.9984\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0287 - acc: 0.9967\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0268 - acc: 0.9951\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0296 - acc: 0.9967\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0321 - acc: 0.9967\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 4s 6ms/step - loss: 0.0214 - acc: 0.9984\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_810 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_305 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_811 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_812 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 27s 44ms/step - loss: 0.7209 - acc: 0.5398\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.6721 - acc: 0.7106\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.6097 - acc: 0.7610\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.5501 - acc: 0.8081\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.4821 - acc: 0.8650\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.4139 - acc: 0.9008\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.3689 - acc: 0.9220\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.3269 - acc: 0.9366\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2915 - acc: 0.9610\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2572 - acc: 0.9642\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2259 - acc: 0.9789\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2012 - acc: 0.9821\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1741 - acc: 0.9919\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1738 - acc: 0.9837\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1647 - acc: 0.9870\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1506 - acc: 0.9821\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1356 - acc: 0.9951\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1288 - acc: 0.9935\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1277 - acc: 0.9886\n",
      "Epoch 20/30\n",
      "192/615 [========>.....................] - ETA: 1s - loss: 0.1352 - acc: 0.9844_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_819 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_308 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_820 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 28s 45ms/step - loss: 0.6916 - acc: 0.5415\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6016 - acc: 0.6911\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5221 - acc: 0.7512\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4737 - acc: 0.7951\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4170 - acc: 0.8049\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3968 - acc: 0.8130\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3548 - acc: 0.8114\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3192 - acc: 0.8293\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2960 - acc: 0.8455\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2822 - acc: 0.8488\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2644 - acc: 0.8585\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2353 - acc: 0.8732\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2722 - acc: 0.8407\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2473 - acc: 0.8504\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2265 - acc: 0.8618\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2332 - acc: 0.8520\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2153 - acc: 0.8488\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2350 - acc: 0.8569\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2042 - acc: 0.8764\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2194 - acc: 0.8667\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2100 - acc: 0.8553\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1963 - acc: 0.8780\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2293 - acc: 0.8390\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2012 - acc: 0.8748\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1999 - acc: 0.8732\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2075 - acc: 0.8667\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2042 - acc: 0.8683\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2304 - acc: 0.8423\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1956 - acc: 0.8569\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2058 - acc: 0.8439\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_821 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_309 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_822 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 322,729\n",
      "Trainable params: 322,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 27s 43ms/step - loss: 0.6997 - acc: 0.5073\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6643 - acc: 0.5967\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6455 - acc: 0.6293\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6149 - acc: 0.7041\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5965 - acc: 0.7285\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5774 - acc: 0.7642\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5602 - acc: 0.8033\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5463 - acc: 0.8179\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5365 - acc: 0.8179\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5375 - acc: 0.8358\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5085 - acc: 0.8829\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5081 - acc: 0.8667\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4956 - acc: 0.8715\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4913 - acc: 0.8732\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4831 - acc: 0.8911\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4800 - acc: 0.8846\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4790 - acc: 0.8748\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4737 - acc: 0.8732\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4669 - acc: 0.8813\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4590 - acc: 0.8959\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4300 - acc: 0.9122\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.4435 - acc: 0.8862\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4384 - acc: 0.9073\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4318 - acc: 0.8959\n",
      "Epoch 25/30\n",
      "352/615 [================>.............] - ETA: 0s - loss: 0.4247 - acc: 0.8949_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_832 (Dense)            (None, 4)                 322724    \n",
      "_________________________________________________________________\n",
      "dropout_313 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_833 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_834 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 322,737\n",
      "Trainable params: 322,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 28s 46ms/step - loss: 0.7001 - acc: 0.4911\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6808 - acc: 0.5837\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6689 - acc: 0.5935\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.6563 - acc: 0.6358\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6445 - acc: 0.6846\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6229 - acc: 0.7268\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6034 - acc: 0.7447\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5865 - acc: 0.7610\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5922 - acc: 0.7577\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5629 - acc: 0.8065\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5561 - acc: 0.8114\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5275 - acc: 0.8699\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5251 - acc: 0.8780\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5095 - acc: 0.8699\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4917 - acc: 0.8683\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4876 - acc: 0.8780\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4804 - acc: 0.8699\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4570 - acc: 0.8976\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4422 - acc: 0.8976\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4168 - acc: 0.9138\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4181 - acc: 0.9171\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4010 - acc: 0.9236\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4098 - acc: 0.9008\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3774 - acc: 0.9171\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3882 - acc: 0.9008\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3736 - acc: 0.9171\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3500 - acc: 0.9317\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3571 - acc: 0.9106\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3429 - acc: 0.9171\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3400 - acc: 0.9122\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_835 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_314 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_836 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 645,457\n",
      "Trainable params: 645,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 30s 49ms/step - loss: 0.6868 - acc: 0.5724\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5095 - acc: 0.7593\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3689 - acc: 0.8715\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2911 - acc: 0.8894\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2567 - acc: 0.9089\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2076 - acc: 0.9431\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1952 - acc: 0.9350\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1746 - acc: 0.9431\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1521 - acc: 0.9480\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1333 - acc: 0.9512\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1439 - acc: 0.9366\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1270 - acc: 0.9496\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1197 - acc: 0.9496\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1076 - acc: 0.9593\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1123 - acc: 0.9496\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1077 - acc: 0.9528\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1180 - acc: 0.9463\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0976 - acc: 0.9577\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1119 - acc: 0.9480\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1032 - acc: 0.9398\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0994 - acc: 0.9528\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0900 - acc: 0.9561\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0818 - acc: 0.9610\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0955 - acc: 0.9528\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0787 - acc: 0.9707\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 29s 47ms/step - loss: 0.7077 - acc: 0.5220\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6940 - acc: 0.6049\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.6794 - acc: 0.6325\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6544 - acc: 0.6764\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6333 - acc: 0.7154\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.6098 - acc: 0.7171\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.5971 - acc: 0.7301\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.5783 - acc: 0.7203\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5532 - acc: 0.7919\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.5354 - acc: 0.8049\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5148 - acc: 0.8000\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.4861 - acc: 0.8439\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.4629 - acc: 0.8374\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4495 - acc: 0.8715\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4369 - acc: 0.8650\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4080 - acc: 0.8780\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3967 - acc: 0.8894\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.3776 - acc: 0.9122\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.3679 - acc: 0.9268\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3780 - acc: 0.9024\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.3228 - acc: 0.9203\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3326 - acc: 0.9285\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.3099 - acc: 0.9431\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.3143 - acc: 0.9301\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.2894 - acc: 0.9366\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2853 - acc: 0.9382\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2698 - acc: 0.9480\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2730 - acc: 0.9431\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2556 - acc: 0.9447\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 1s 1ms/step - loss: 0.2401 - acc: 0.9577\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_845 (Dense)            (None, 8)                 645448    \n",
      "_________________________________________________________________\n",
      "dropout_318 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_846 (Dense)            (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_847 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 645,469\n",
      "Trainable params: 645,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 28s 46ms/step - loss: 0.7043 - acc: 0.5528\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6188 - acc: 0.7268\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4715 - acc: 0.8179\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3239 - acc: 0.8878\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2405 - acc: 0.9203\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1930 - acc: 0.9350\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1552 - acc: 0.9333\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1247 - acc: 0.9577\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1288 - acc: 0.9350\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1307 - acc: 0.9236\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1102 - acc: 0.9398\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1070 - acc: 0.9463\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0944 - acc: 0.9610\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0929 - acc: 0.9480\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0801 - acc: 0.9593\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0855 - acc: 0.9626\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0871 - acc: 0.9577\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0951 - acc: 0.9528\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0840 - acc: 0.9545\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0913 - acc: 0.9447\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0752 - acc: 0.9659\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0882 - acc: 0.9480\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0774 - acc: 0.9577\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0704 - acc: 0.9707\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.0717 - acc: 0.9642\n",
      "Epoch 26/30\n",
      "544/615 [=========================>....] - ETA: 0s - loss: 0.0775 - acc: 0.9522Epoch 1/30\n",
      "615/615 [==============================] - 29s 47ms/step - loss: 0.7281 - acc: 0.5154\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6925 - acc: 0.6325\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6551 - acc: 0.7236\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6166 - acc: 0.7821\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5817 - acc: 0.7886\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5451 - acc: 0.8358\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5134 - acc: 0.8699\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4869 - acc: 0.8797\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4538 - acc: 0.8878\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4398 - acc: 0.8992\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4091 - acc: 0.9154\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3978 - acc: 0.9203\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3641 - acc: 0.9268\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3686 - acc: 0.9252\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3389 - acc: 0.9350\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3287 - acc: 0.9512\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3201 - acc: 0.9350\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2944 - acc: 0.9610\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2882 - acc: 0.9545\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2876 - acc: 0.9496\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2799 - acc: 0.9642\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2743 - acc: 0.9545\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2546 - acc: 0.9610\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2510 - acc: 0.9691\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2506 - acc: 0.9675\n",
      "Epoch 26/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2152 - acc: 0.9837\n",
      "Epoch 27/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2148 - acc: 0.9789\n",
      "Epoch 28/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2281 - acc: 0.9675\n",
      "Epoch 29/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2158 - acc: 0.9821\n",
      "Epoch 30/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2118 - acc: 0.9707\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_855 (Dense)            (None, 16)                1290896   \n",
      "_________________________________________________________________\n",
      "dropout_322 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_856 (Dense)            (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "dense_857 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 1,290,915\n",
      "Trainable params: 1,290,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "615/615 [==============================] - 30s 49ms/step - loss: 0.7027 - acc: 0.6065\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.5087 - acc: 0.7967\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.3155 - acc: 0.9187\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.2301 - acc: 0.9382\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1718 - acc: 0.9659\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1273 - acc: 0.9805\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.1148 - acc: 0.9772\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.0890 - acc: 0.9886\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.0806 - acc: 0.9902\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.0742 - acc: 0.9935\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.0665 - acc: 0.9935\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.0691 - acc: 0.9870\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 2s 4ms/step - loss: 0.0630 - acc: 0.9902\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.0519 - acc: 0.9902\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 2s 3ms/step - loss: 0.0455 - acc: 0.9967\n",
      "Epoch 16/30\n",
      "352/615 [================>.............] - ETA: 0s - loss: 0.0498 - acc: 0.9943Epoch 1/30\n",
      "615/615 [==============================] - 27s 44ms/step - loss: 0.7278 - acc: 0.5171\n",
      "Epoch 2/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.6507 - acc: 0.6683\n",
      "Epoch 3/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5802 - acc: 0.7707\n",
      "Epoch 4/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.5203 - acc: 0.8325\n",
      "Epoch 5/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4565 - acc: 0.8764\n",
      "Epoch 6/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.4316 - acc: 0.8748\n",
      "Epoch 7/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3867 - acc: 0.9106\n",
      "Epoch 8/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3531 - acc: 0.9171\n",
      "Epoch 9/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.3248 - acc: 0.9350\n",
      "Epoch 10/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2986 - acc: 0.9366\n",
      "Epoch 11/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2850 - acc: 0.9415\n",
      "Epoch 12/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2678 - acc: 0.9382\n",
      "Epoch 13/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2437 - acc: 0.9626\n",
      "Epoch 14/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2400 - acc: 0.9659\n",
      "Epoch 15/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2058 - acc: 0.9675\n",
      "Epoch 16/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.2151 - acc: 0.9577\n",
      "Epoch 17/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1905 - acc: 0.9691\n",
      "Epoch 18/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1878 - acc: 0.9756\n",
      "Epoch 19/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1733 - acc: 0.9756\n",
      "Epoch 20/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1687 - acc: 0.9740\n",
      "Epoch 21/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1628 - acc: 0.9789\n",
      "Epoch 22/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1522 - acc: 0.9772\n",
      "Epoch 23/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1458 - acc: 0.9821\n",
      "Epoch 24/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1528 - acc: 0.9789\n",
      "Epoch 25/30\n",
      "615/615 [==============================] - 1s 2ms/step - loss: 0.1399 - acc: 0.9821\n",
      "Epoch 26/30\n",
      "608/615 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9868"
     ]
    }
   ],
   "source": [
    "# Pass the model design to KerasClassifier() wrapper -------------------------------\n",
    "\n",
    "model = KerasClassifier(build_fn = build_fc_model,\n",
    "\t                         verbose = 1)\n",
    "\n",
    "# Define the parameters that will be tuned randomly\n",
    "keras_param_options = {\n",
    "                       # Hyperparameters as parts of model designs (building blocks)\n",
    "                       'input_num_hidden_units': [4, 8, 16],\n",
    "                       'num_hidden_layers': [[0], [1], [2]],\n",
    "                       'activation_function': ['relu'],\n",
    "                       # Hyperparameters as part of optimization and regularization of the models\n",
    "                       'optim_methods' : ['Adadelta', 'SGD'],\n",
    "                       'l2_rate':[0.001],\n",
    "                       'input_dropout_rates': [0.5],\n",
    "                       'dropout_rates': [0.5],\n",
    "                       'batch_norm' : ['no'],\n",
    "                       # Fitting parameters\n",
    "                       'batch_size': [8, 16, 32],\n",
    "                       'epochs': [30],\n",
    "                       'shuffle': [True]\n",
    "                      }\n",
    "\n",
    "# Using RandomizedSearchCV to find the best model randomly\n",
    "random_search = GridSearchCV(model,\n",
    "                            param_grid = keras_param_options,\n",
    "                            n_jobs = 1,\n",
    "                            cv = 5,\n",
    "                            verbose = 10)\n",
    "\n",
    "# Fit to the training data\n",
    "random_search.fit(x_train, y_train)\n",
    "df_result_hyper_tuned = pd.DataFrame.from_dict(random_search.cv_results_)\n",
    "df_result_hyper_tuned.to_csv('result_hyper_tuned_model4_gridsearch.csv')\n",
    "param_best_model_dict = dict(df_result_hyper_tuned['params'])\n",
    "params = list(param_best_model_dict.values())\n",
    "\n",
    "# Define function to fit the model\n",
    "def train_fc_model(batch_sizes = None, num_epochs = None):\n",
    "      model.fit(x = x_train,\n",
    "                y = y_train,\n",
    "                batch_size = batch_sizes,\n",
    "                epochs = num_epochs,\n",
    "                verbose = 1,\n",
    "                shuffle = 1)\n",
    "\n",
    "# Define the function to calculate sensitivity and specificity\n",
    "def sensitivity_specificity(predictions, y_test, mode='binary'):\n",
    "    if mode == 'binary':\n",
    "        # Determine positive class predictions\n",
    "        index = predictions > 0.5\n",
    "        predictions = np.zeros(predictions.shape)\n",
    "        predictions[index] = 1\n",
    "        # No need to modify y_test since it consists of zeros and ones already\n",
    "    else:\n",
    "        y_test = y_test\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    # In the binary classification case as we create, we can extract tn, fp, fn, tp as follows\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions, labels = [0, 1]).ravel()\n",
    "\n",
    "    # Sensitivity = TP / (TP + FN)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "\n",
    "    # Specificity = TN / (TN + FP)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Precision = TP / (TP + FP)\n",
    "    precision = tp / (tp + fp)\n",
    "\n",
    "    # Return sensitivity, specificity, precision\n",
    "    return(sensitivity, specificity, precision)\n",
    "\n",
    "\n",
    "# Define function to evaluate and predict\n",
    "def evaluate_predict_fc_model():\n",
    "  loss, acc = model.evaluate(x_test, y_test, verbose = 0)\n",
    "  prediction = model.predict(x_test)\n",
    "  sensitivity, specificity, precision = sensitivity_specificity(prediction, y_test, mode='binary')\n",
    "  return acc, sensitivity, specificity, precision\n",
    "\n",
    "# make prediction\n",
    "result_list = []\n",
    "columns_names = ['Parameters',\n",
    "                'Accuracy',\n",
    "                'Sensitivity',\n",
    "                'Specifity']\n",
    "\n",
    "\n",
    "for i in range(len(params)):\n",
    "    list_par = list(params[i].values())\n",
    "    model = build_fc_model(input_num_hidden_units = list_par[6],\n",
    "                           num_hidden_layers = list_par[8],\n",
    "                           activation_function = list_par[0],\n",
    "                           l2_rate = list_par[7],\n",
    "                           input_dropout_rates = list_par[5],\n",
    "                           dropout_rates = list_par[3],\n",
    "                           optim_methods = list_par[9],\n",
    "                           batch_norm = list_par[1])\n",
    "    train_fc_model(batch_sizes = list_par[2], num_epochs = list_par[4])\n",
    "    acc, sensitivity, specifity, precision = evaluate_predict_fc_model()\n",
    "    result_line = np.array((params[i],\n",
    "                            acc,\n",
    "                            sensitivity,\n",
    "                            specifity))\n",
    "    result_list.append(result_line[:])\n",
    "    result_array = np.asarray(result_list)\n",
    "\n",
    "    df_results = pd.DataFrame(result_array,\n",
    "                         columns = columns_names)\n",
    "\n",
    "df_results.to_csv('df_result_prediction_model4_gridsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
