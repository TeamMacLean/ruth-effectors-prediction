{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras.models import load_model\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterate(model, layer):\n",
    "    # Get the output of the layer and the data\n",
    "    data_output = model.output[:, 0]\n",
    "\n",
    "    # Get layer output\n",
    "    get_layer = model.get_layer(layer)\n",
    "    layer_output = get_layer.output\n",
    "\n",
    "    # Calculate the gradients\n",
    "    grads = K.gradients(data_output, layer_output)[0]\n",
    "\n",
    "    pooled_grads = K.mean(grads, axis = (0, 1))\n",
    "\n",
    "    iterate = K.function([model.input], [pooled_grads, layer_output[0]])\n",
    "    \n",
    "    return(iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap_matrix(dataset, nth_data, iterate):\n",
    "\n",
    "    # Get the data\n",
    "    data = dataset[nth_data:nth_data+1, :, :]\n",
    "    \n",
    "    pooled_grads_value, layer_output_value = iterate([data])\n",
    "\n",
    "    layer_output_value[:, ] *= pooled_grads_value\n",
    "        \n",
    "    # Get the heatmap matrix\n",
    "    heatmap = np.copy(layer_output_value)\n",
    "    heatmap = np.mean(heatmap, axis = -1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    # Expand the dimensionality of heatmap so that it can be plot\n",
    "    heatmap = np.expand_dims(heatmap, axis=0)\n",
    "    \n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original function\n",
    "# def load_npy_data(filename):\n",
    "#     # Define pattern of the npy data\n",
    "#     data_loading_pattern = \"data-sets/\" + filename + \".npy\"\n",
    "#     data_loading_path = glob.glob(data_loading_pattern)\n",
    "\n",
    "#     # Load the data\n",
    "#     print(\"Loading data:\", str(filename), \"from \" + data_loading_path[0])\n",
    "#     data = np.load(data_loading_path[0])\n",
    "    \n",
    "#     return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for secreted data\n",
    "def load_npy_data(filename):\n",
    "    # Define pattern of the npy data\n",
    "    data_loading_pattern = \"../../../data/secreted_data/ready_to_process/encoded_files/\" + filename + \".npy\"\n",
    "    data_loading_path = glob.glob(data_loading_pattern)\n",
    "\n",
    "    # Load the data\n",
    "    print(\"Loading data:\", str(filename), \"from \" + data_loading_path[0])\n",
    "    data = np.load(data_loading_path[0])\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_heatmap(class_name, data_name, model, layer, from_sample, sample_length):\n",
    "    \n",
    "    file_name = class_name + \"/\" + data_name\n",
    "    data = load_npy_data(file_name)\n",
    "    print(\"Data shape: \" + str(data.shape[0]))\n",
    "    \n",
    "    iterate = get_iterate(model, layer)\n",
    "    result = []\n",
    "\n",
    "    min_sample = from_sample\n",
    "    max_sample = np.min([from_sample + sample_length, data.shape[0]])\n",
    "    \n",
    "    print(\"\")\n",
    "    # For loop to get the heatmap for each matrix\n",
    "    for nth_sample in range(min_sample, max_sample):\n",
    "        print(\"Getting the heatmap for the data: sample \" + str(nth_sample) + \"/\" + str(max_sample-1))\n",
    "        heatmap = get_heatmap_matrix(data, nth_sample, iterate)\n",
    "\n",
    "        # Put all of the results together\n",
    "        result.append(heatmap)\n",
    "        \n",
    "        # Free memory (useless)\n",
    "        gc.collect()\n",
    "\n",
    "    # Change the list to numpy array\n",
    "    all_matrices = np.array(result)\n",
    "\n",
    "    # Save all matrices\n",
    "    saving_path = \"results_secreted/all_matrices_\" + class_name + \"_\" + data_name + \"_\" + layer + \"_samples_\" + str(min_sample).zfill(4) + \"_\" + str(max_sample-1).zfill(4) + \".npy\"\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Saving results in\", saving_path)\n",
    "    np.save(saving_path, all_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run functions in steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Loading data: fungi/x_train from ../../../data/secreted_data/ready_to_process/encoded_files/fungi/x_train.npy\n",
      "Data shape: 118\n",
      "\n",
      "Getting the heatmap for the data: sample 100/117\n",
      "Getting the heatmap for the data: sample 101/117\n",
      "Getting the heatmap for the data: sample 102/117\n",
      "Getting the heatmap for the data: sample 103/117\n",
      "Getting the heatmap for the data: sample 104/117\n",
      "Getting the heatmap for the data: sample 105/117\n",
      "Getting the heatmap for the data: sample 106/117\n",
      "Getting the heatmap for the data: sample 107/117\n",
      "Getting the heatmap for the data: sample 108/117\n",
      "Getting the heatmap for the data: sample 109/117\n",
      "Getting the heatmap for the data: sample 110/117\n",
      "Getting the heatmap for the data: sample 111/117\n",
      "Getting the heatmap for the data: sample 112/117\n",
      "Getting the heatmap for the data: sample 113/117\n",
      "Getting the heatmap for the data: sample 114/117\n",
      "Getting the heatmap for the data: sample 115/117\n",
      "Getting the heatmap for the data: sample 116/117\n",
      "Getting the heatmap for the data: sample 117/117\n",
      "\n",
      "Saving results in results_secreted/all_matrices_fungi_x_train_conv1d_1_samples_0100_0117.npy\n"
     ]
    }
   ],
   "source": [
    "get_sum_heatmap(\n",
    "    class_name =    str(os.getenv('CLASS_NAME')),\n",
    "    data_name =     str(os.getenv('DATA_NAME')),\n",
    "    model =         load_model(str(os.getenv('MODEL_PATH'))),\n",
    "    layer =         str(os.getenv('LAYER')),\n",
    "    from_sample =   int(os.getenv('FROM_SAMPLE')),\n",
    "    sample_length = int(os.getenv('SAMPLE_LENGTH'))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
